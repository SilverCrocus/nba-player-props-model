{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "from nba_api.stats.endpoints import playergamelog, commonplayerinfo, leaguegamefinder, leaguedashteamstats, leaguedashplayerstats\n",
    "from nba_api.stats.static import players, teams\n",
    "import time \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit # Added TimeSeriesSplit\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error # Added MAPE\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb # Added LightGBM\n",
    "import joblib # Added for saving models\n",
    "import traceback # Added for detailed error printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total players found: 5024\n"
     ]
    }
   ],
   "source": [
    "# Get all players\n",
    "nba_players = players.get_players()\n",
    "players_df = pd.DataFrame(nba_players)\n",
    "print(f\"Total players found: {len(players_df)}\")\n",
    "# players_df.head() # Optionally display head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total teams found: 30\n"
     ]
    }
   ],
   "source": [
    "# Get all teams\n",
    "nba_teams = teams.get_teams()\n",
    "teams_df = pd.DataFrame(nba_teams)\n",
    "print(f\"Total teams found: {len(teams_df)}\")\n",
    "# teams_df.head() # Optionally display head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for SEASON: 2024-25\n",
      "Model output directory: models/2024-25\n",
      "Fetching team stats (Defense & Pace) for 2024-25...\n",
      "Available columns in team stats:\n",
      "Index(['TEAM_ID', 'TEAM_NAME', 'GP', 'W', 'L', 'W_PCT', 'MIN', 'DEF_RATING',\n",
      "       'DREB', 'DREB_PCT', 'STL', 'BLK', 'OPP_PTS_OFF_TOV',\n",
      "       'OPP_PTS_2ND_CHANCE', 'OPP_PTS_FB', 'OPP_PTS_PAINT', 'GP_RANK',\n",
      "       'W_RANK', 'L_RANK', 'W_PCT_RANK', 'MIN_RANK', 'DEF_RATING_RANK',\n",
      "       'DREB_RANK', 'DREB_PCT_RANK', 'STL_RANK', 'BLK_RANK',\n",
      "       'OPP_PTS_OFF_TOV_RANK', 'OPP_PTS_2ND_CHANCE_RANK', 'OPP_PTS_FB_RANK',\n",
      "       'OPP_PTS_PAINT_RANK'],\n",
      "      dtype='object')\n",
      "Using 'TEAM_NAME' as identifier.\n",
      "Merging team stats to get TEAM_ABBREVIATION using 'TEAM_NAME'...\n",
      "Merged successfully, using TEAM_ABBREVIATION.\n",
      "\n",
      "Team stats (Defense & Pace) processed.\n",
      "  TEAM_ABBREVIATION  DEF_RATING\n",
      "0               ATL       114.8\n",
      "1               BOS       110.1\n",
      "2               BKN       115.4\n",
      "3               CHA       115.7\n",
      "4               CHI       114.8\n"
     ]
    }
   ],
   "source": [
    "# --- Define Season --- \n",
    "SEASON = '2024-25' # <<< CORRECTED SEASON HERE\n",
    "print(f\"Processing data for SEASON: {SEASON}\")\n",
    "\n",
    "# --- Create directories for outputs ---\n",
    "MODEL_DIR = f'models/{SEASON}'\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "print(f\"Model output directory: {MODEL_DIR}\")\n",
    "\n",
    "# --- Fetch Team Defensive Stats and Pace for the season ---\n",
    "print(f\"Fetching team stats (Defense & Pace) for {SEASON}...\")\n",
    "team_stats_df = pd.DataFrame() \n",
    "try:\n",
    "    # Fetch stats, including Pace\n",
    "    team_stats = leaguedashteamstats.LeagueDashTeamStats(\n",
    "        season=SEASON, # Uses the SEASON variable\n",
    "        measure_type_detailed_defense='Defense' # This measure type includes Pace in the result\n",
    "    )\n",
    "    temp_df = team_stats.get_data_frames()[0]\n",
    "    time.sleep(0.6) # Add delay after API call\n",
    "    \n",
    "    print(\"Available columns in team stats:\")\n",
    "    print(temp_df.columns) \n",
    "\n",
    "    # Identify the team column (prefer TEAM_ABBREVIATION for merging later)\n",
    "    identifier_column = None\n",
    "    if 'TEAM_ABBREVIATION' in temp_df.columns:\n",
    "        identifier_column = 'TEAM_ABBREVIATION'\n",
    "        print(f\"Using '{identifier_column}' as identifier.\")\n",
    "    elif 'TEAM_NAME' in temp_df.columns:\n",
    "        identifier_column = 'TEAM_NAME'\n",
    "        print(f\"Using '{identifier_column}' as identifier.\")\n",
    "    elif 'TEAM_ID' in temp_df.columns:\n",
    "        identifier_column = 'TEAM_ID'\n",
    "        print(f\"Using '{identifier_column}' as identifier.\")\n",
    "    else:\n",
    "        raise KeyError(f\"Could not find a suitable team identifier column. Available: {temp_df.columns}\")\n",
    "\n",
    "    # Select relevant columns (identifier, DEF_RATING, PACE)\n",
    "    required_team_cols = [identifier_column, 'DEF_RATING', 'PACE']\n",
    "    available_team_cols = [col for col in required_team_cols if col in temp_df.columns]\n",
    "    \n",
    "    if len(available_team_cols) < 2: # Need at least identifier and one stat\n",
    "         print(f\"Warning: Not enough required team columns found. Found: {available_team_cols}\")\n",
    "         team_stats_df = pd.DataFrame() # Ensure it's empty\n",
    "    else:\n",
    "        team_stats_df = temp_df[available_team_cols].copy()\n",
    "        \n",
    "        # If identifier is not abbreviation, try to merge to get abbreviation\n",
    "        if identifier_column != 'TEAM_ABBREVIATION' and 'teams_df' in locals() and not teams_df.empty:\n",
    "             print(f\"Merging team stats to get TEAM_ABBREVIATION using '{identifier_column}'...\")\n",
    "             merge_left_col = identifier_column\n",
    "             merge_right_col = 'full_name' if identifier_column == 'TEAM_NAME' else 'id'\n",
    "             \n",
    "             if identifier_column == 'TEAM_ID':\n",
    "                 team_stats_df[identifier_column] = team_stats_df[identifier_column].astype(int)\n",
    "                 teams_df['id'] = teams_df['id'].astype(int)\n",
    "\n",
    "             merged_temp_df = pd.merge(team_stats_df, teams_df[['id', 'full_name', 'abbreviation']], left_on=merge_left_col, right_on=merge_right_col, how='left')\n",
    "             \n",
    "             if 'abbreviation' in merged_temp_df.columns:\n",
    "                 # Keep abbreviation and the stats, drop the original identifier\n",
    "                 cols_to_keep = ['abbreviation'] + [col for col in available_team_cols if col != identifier_column]\n",
    "                 team_stats_df = merged_temp_df[cols_to_keep].rename(columns={'abbreviation': 'TEAM_ABBREVIATION'})\n",
    "                 print(\"Merged successfully, using TEAM_ABBREVIATION.\")\n",
    "             else:\n",
    "                  print(f\"Warning: Could not find 'abbreviation' after merging with teams_df based on '{identifier_column}'. Using original identifier column.\")\n",
    "                  team_stats_df = team_stats_df.rename(columns={identifier_column: 'TEAM_ABBREVIATION'}) # Rename for consistency if we couldn't merge\n",
    "        else: # If identifier was already abbreviation or teams_df not available\n",
    "             team_stats_df = team_stats_df.rename(columns={identifier_column: 'TEAM_ABBREVIATION'})\n",
    "\n",
    "    if not team_stats_df.empty and 'TEAM_ABBREVIATION' in team_stats_df.columns:\n",
    "        print(\"\\nTeam stats (Defense & Pace) processed.\")\n",
    "        print(team_stats_df.head())\n",
    "    else:\n",
    "         print(\"\\nCould not process team stats correctly after renaming/merging.\")\n",
    "         team_stats_df = pd.DataFrame() # Ensure empty on failure\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nError fetching or processing team stats: {e}\")\n",
    "    traceback.print_exc()\n",
    "    team_stats_df = pd.DataFrame() # Ensure it's empty on error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw game log file 'nba_gamelogs_raw_2024-25.csv' not found. Fetching data...\n",
      "Fetching player stats for 2024-25 to filter...\n",
      "Found 553 players averaging >= 15 MPG for 2024-25.\n",
      "Limiting fetch to 150 players for speed.\n",
      "Fetching game logs for 150 players for season 2024-25...\n",
      "Progress: 1/150\n",
      "Fetching logs for player 1630639 for season 2024-25...\n",
      "Progress: 2/150\n",
      "Fetching logs for player 1631260 for season 2024-25...\n",
      "Progress: 3/150\n",
      "Fetching logs for player 1642358 for season 2024-25...\n",
      "Progress: 4/150\n",
      "Fetching logs for player 203932 for season 2024-25...\n",
      "Progress: 5/150\n",
      "Fetching logs for player 1628988 for season 2024-25...\n",
      "Progress: 6/150\n",
      "Fetching logs for player 1630174 for season 2024-25...\n",
      "Progress: 7/150\n",
      "Fetching logs for player 1630598 for season 2024-25...\n",
      "Progress: 8/150\n",
      "Fetching logs for player 1641745 for season 2024-25...\n",
      "Progress: 9/150\n",
      "Fetching logs for player 1641766 for season 2024-25...\n",
      "Progress: 10/150\n",
      "Fetching logs for player 1641737 for season 2024-25...\n",
      "Progress: 11/150\n",
      "Fetching logs for player 1642349 for season 2024-25...\n",
      "Progress: 12/150\n",
      "Fetching logs for player 201143 for season 2024-25...\n",
      "Progress: 13/150\n",
      "Fetching logs for player 202692 for season 2024-25...\n",
      "Progress: 14/150\n",
      "Fetching logs for player 1627936 for season 2024-25...\n",
      "Progress: 15/150\n",
      "Fetching logs for player 1642505 for season 2024-25...\n",
      "Progress: 16/150\n",
      "Fetching logs for player 203458 for season 2024-25...\n",
      "Progress: 17/150\n",
      "Fetching logs for player 1642024 for season 2024-25...\n",
      "Progress: 18/150\n",
      "Fetching logs for player 1642259 for season 2024-25...\n",
      "Progress: 19/150\n",
      "Fetching logs for player 1630578 for season 2024-25...\n",
      "Progress: 20/150\n",
      "Fetching logs for player 1641708 for season 2024-25...\n",
      "Progress: 21/150\n",
      "Fetching logs for player 1629599 for season 2024-25...\n",
      "Progress: 22/150\n",
      "Fetching logs for player 203083 for season 2024-25...\n",
      "Progress: 23/150\n",
      "Fetching logs for player 1641748 for season 2024-25...\n",
      "Progress: 24/150\n",
      "Fetching logs for player 1629614 for season 2024-25...\n",
      "Progress: 25/150\n",
      "Fetching logs for player 203952 for season 2024-25...\n",
      "Progress: 26/150\n",
      "Fetching logs for player 1629014 for season 2024-25...\n",
      "Progress: 27/150\n",
      "Fetching logs for player 1641710 for season 2024-25...\n",
      "Progress: 28/150\n",
      "Fetching logs for player 203076 for season 2024-25...\n",
      "Progress: 29/150\n",
      "Fetching logs for player 1630162 for season 2024-25...\n",
      "Progress: 30/150\n",
      "Fetching logs for player 1630264 for season 2024-25...\n",
      "Progress: 31/150\n",
      "Fetching logs for player 1641817 for season 2024-25...\n",
      "Progress: 32/150\n",
      "Fetching logs for player 1641810 for season 2024-25...\n",
      "Progress: 33/150\n",
      "Fetching logs for player 1630574 for season 2024-25...\n",
      "Progress: 34/150\n",
      "Fetching logs for player 1642422 for season 2024-25...\n",
      "Progress: 35/150\n",
      "Fetching logs for player 1641709 for season 2024-25...\n",
      "Progress: 36/150\n",
      "Fetching logs for player 1630559 for season 2024-25...\n",
      "Progress: 37/150\n",
      "Fetching logs for player 1630245 for season 2024-25...\n",
      "Progress: 38/150\n",
      "Fetching logs for player 1628389 for season 2024-25...\n",
      "Progress: 39/150\n",
      "Fetching logs for player 1631248 for season 2024-25...\n",
      "Progress: 40/150\n",
      "Fetching logs for player 1641767 for season 2024-25...\n",
      "Progress: 41/150\n",
      "Fetching logs for player 1627732 for season 2024-25...\n",
      "Progress: 42/150\n",
      "Fetching logs for player 1631097 for season 2024-25...\n",
      "Progress: 43/150\n",
      "Fetching logs for player 1641731 for season 2024-25...\n",
      "Progress: 44/150\n",
      "Fetching logs for player 202687 for season 2024-25...\n",
      "Progress: 45/150\n",
      "Fetching logs for player 1631104 for season 2024-25...\n",
      "Progress: 46/150\n",
      "Fetching logs for player 1626171 for season 2024-25...\n",
      "Progress: 47/150\n",
      "Fetching logs for player 1641752 for season 2024-25...\n",
      "Progress: 48/150\n",
      "Fetching logs for player 203992 for season 2024-25...\n",
      "Progress: 49/150\n",
      "Fetching logs for player 1629626 for season 2024-25...\n",
      "Progress: 50/150\n",
      "Fetching logs for player 1630538 for season 2024-25...\n",
      "Progress: 51/150\n",
      "Fetching logs for player 203078 for season 2024-25...\n",
      "Progress: 52/150\n",
      "Fetching logs for player 1642382 for season 2024-25...\n",
      "Progress: 53/150\n",
      "Fetching logs for player 1641764 for season 2024-25...\n",
      "Progress: 54/150\n",
      "Fetching logs for player 1630527 for season 2024-25...\n",
      "Progress: 55/150\n",
      "Fetching logs for player 1629634 for season 2024-25...\n",
      "Progress: 56/150\n",
      "Fetching logs for player 1627742 for season 2024-25...\n",
      "Progress: 57/150\n",
      "Fetching logs for player 1641706 for season 2024-25...\n",
      "Progress: 58/150\n",
      "Fetching logs for player 1630314 for season 2024-25...\n",
      "Progress: 59/150\n",
      "Fetching logs for player 1641729 for season 2024-25...\n",
      "Progress: 60/150\n",
      "Fetching logs for player 1642355 for season 2024-25...\n",
      "Progress: 61/150\n",
      "Fetching logs for player 201572 for season 2024-25...\n",
      "Progress: 62/150\n",
      "Fetching logs for player 1628971 for season 2024-25...\n",
      "Progress: 63/150\n",
      "Fetching logs for player 1628981 for season 2024-25...\n",
      "Progress: 64/150\n",
      "Fetching logs for player 1631121 for season 2024-25...\n",
      "Progress: 65/150\n",
      "Fetching logs for player 1642267 for season 2024-25...\n",
      "Progress: 66/150\n",
      "Fetching logs for player 1627741 for season 2024-25...\n",
      "Progress: 67/150\n",
      "Fetching logs for player 203468 for season 2024-25...\n",
      "Progress: 68/150\n",
      "Fetching logs for player 1630595 for season 2024-25...\n",
      "Progress: 69/150\n",
      "Fetching logs for player 1631216 for season 2024-25...\n",
      "Progress: 70/150\n",
      "Fetching logs for player 1628997 for season 2024-25...\n",
      "Progress: 71/150\n",
      "Fetching logs for player 1642353 for season 2024-25...\n",
      "Progress: 72/150\n",
      "Fetching logs for player 1629629 for season 2024-25...\n",
      "Progress: 73/150\n",
      "Fetching logs for player 1642285 for season 2024-25...\n",
      "Progress: 74/150\n",
      "Fetching logs for player 1630560 for season 2024-25...\n",
      "Progress: 75/150\n",
      "Fetching logs for player 1641715 for season 2024-25...\n",
      "Progress: 76/150\n",
      "Fetching logs for player 1629661 for season 2024-25...\n",
      "Progress: 77/150\n",
      "Fetching logs for player 1626166 for season 2024-25...\n",
      "Progress: 78/150\n",
      "Fetching logs for player 1627747 for season 2024-25...\n",
      "Progress: 79/150\n",
      "Fetching logs for player 1641717 for season 2024-25...\n",
      "Progress: 80/150\n",
      "Fetching logs for player 1629646 for season 2024-25...\n",
      "Progress: 81/150\n",
      "Fetching logs for player 1631096 for season 2024-25...\n",
      "Progress: 82/150\n",
      "Fetching logs for player 1628449 for season 2024-25...\n",
      "Progress: 83/150\n",
      "Fetching logs for player 1630537 for season 2024-25...\n",
      "Progress: 84/150\n",
      "Fetching logs for player 1641753 for season 2024-25...\n",
      "Progress: 85/150\n",
      "Fetching logs for player 101108 for season 2024-25...\n",
      "Progress: 86/150\n",
      "Fetching logs for player 1631128 for season 2024-25...\n",
      "Progress: 87/150\n",
      "Fetching logs for player 1631132 for season 2024-25...\n",
      "Progress: 88/150\n",
      "Fetching logs for player 1629643 for season 2024-25...\n",
      "Progress: 89/150\n",
      "Fetching logs for player 203991 for season 2024-25...\n",
      "Progress: 90/150\n",
      "Fetching logs for player 1629632 for season 2024-25...\n",
      "Progress: 91/150\n",
      "Fetching logs for player 1628998 for season 2024-25...\n",
      "Progress: 92/150\n",
      "Fetching logs for player 1642262 for season 2024-25...\n",
      "Progress: 93/150\n",
      "Fetching logs for player 1641732 for season 2024-25...\n",
      "Progress: 94/150\n",
      "Fetching logs for player 1630175 for season 2024-25...\n",
      "Progress: 95/150\n",
      "Fetching logs for player 1631306 for season 2024-25...\n",
      "Progress: 96/150\n",
      "Fetching logs for player 1630658 for season 2024-25...\n",
      "Progress: 97/150\n",
      "Fetching logs for player 1631221 for season 2024-25...\n",
      "Progress: 98/150\n",
      "Fetching logs for player 1629012 for season 2024-25...\n",
      "Progress: 99/150\n",
      "Fetching logs for player 1630557 for season 2024-25...\n",
      "Progress: 100/150\n",
      "Fetching logs for player 202709 for season 2024-25...\n",
      "Progress: 101/150\n",
      "Fetching logs for player 1641854 for season 2024-25...\n",
      "Progress: 102/150\n",
      "Fetching logs for player 1626156 for season 2024-25...\n",
      "Progress: 103/150\n",
      "Fetching logs for player 1630618 for season 2024-25...\n",
      "Progress: 104/150\n",
      "Fetching logs for player 1629610 for season 2024-25...\n",
      "Progress: 105/150\n",
      "Fetching logs for player 1631342 for season 2024-25...\n",
      "Progress: 106/150\n",
      "Fetching logs for player 1630625 for season 2024-25...\n",
      "Progress: 107/150\n",
      "Fetching logs for player 1631207 for season 2024-25...\n",
      "Progress: 108/150\n",
      "Fetching logs for player 1642261 for season 2024-25...\n",
      "Progress: 109/150\n",
      "Fetching logs for player 203081 for season 2024-25...\n",
      "Progress: 110/150\n",
      "Fetching logs for player 1641878 for season 2024-25...\n",
      "Progress: 111/150\n",
      "Fetching logs for player 1627814 for season 2024-25...\n",
      "Progress: 112/150\n",
      "Fetching logs for player 1629655 for season 2024-25...\n",
      "Progress: 113/150\n",
      "Fetching logs for player 1628464 for season 2024-25...\n",
      "Progress: 114/150\n",
      "Fetching logs for player 1642450 for season 2024-25...\n",
      "Progress: 115/150\n",
      "Fetching logs for player 203957 for season 2024-25...\n",
      "Progress: 116/150\n",
      "Fetching logs for player 203967 for season 2024-25...\n",
      "Progress: 117/150\n",
      "Fetching logs for player 1641727 for season 2024-25...\n",
      "Progress: 118/150\n",
      "Fetching logs for player 1629636 for season 2024-25...\n",
      "Progress: 119/150\n",
      "Fetching logs for player 1630561 for season 2024-25...\n",
      "Progress: 120/150\n",
      "Fetching logs for player 1631223 for season 2024-25...\n",
      "Progress: 121/150\n",
      "Fetching logs for player 1630558 for season 2024-25...\n",
      "Progress: 122/150\n",
      "Fetching logs for player 1630549 for season 2024-25...\n",
      "Progress: 123/150\n",
      "Fetching logs for player 1628368 for season 2024-25...\n",
      "Progress: 124/150\n",
      "Fetching logs for player 1629631 for season 2024-25...\n",
      "Progress: 125/150\n",
      "Fetching logs for player 1629001 for season 2024-25...\n",
      "Progress: 126/150\n",
      "Fetching logs for player 201599 for season 2024-25...\n",
      "Progress: 127/150\n",
      "Fetching logs for player 201942 for season 2024-25...\n",
      "Progress: 128/150\n",
      "Fetching logs for player 1629731 for season 2024-25...\n",
      "Progress: 129/150\n",
      "Fetching logs for player 1629028 for season 2024-25...\n",
      "Progress: 130/150\n",
      "Fetching logs for player 1627749 for season 2024-25...\n",
      "Progress: 131/150\n",
      "Fetching logs for player 1626153 for season 2024-25...\n",
      "Progress: 132/150\n",
      "Fetching logs for player 1630166 for season 2024-25...\n",
      "Progress: 133/150\n",
      "Fetching logs for player 203471 for season 2024-25...\n",
      "Progress: 134/150\n",
      "Fetching logs for player 1641726 for season 2024-25...\n",
      "Progress: 135/150\n",
      "Fetching logs for player 1627884 for season 2024-25...\n",
      "Progress: 136/150\n",
      "Fetching logs for player 1628401 for season 2024-25...\n",
      "Progress: 137/150\n",
      "Fetching logs for player 1630217 for season 2024-25...\n",
      "Progress: 138/150\n",
      "Fetching logs for player 1626164 for season 2024-25...\n",
      "Progress: 139/150\n",
      "Fetching logs for player 1642269 for season 2024-25...\n",
      "Progress: 140/150\n",
      "Fetching logs for player 1630170 for season 2024-25...\n",
      "Progress: 141/150\n",
      "Fetching logs for player 1628415 for season 2024-25...\n",
      "Progress: 142/150\n",
      "Fetching logs for player 1641794 for season 2024-25...\n",
      "Progress: 143/150\n",
      "Fetching logs for player 1627734 for season 2024-25...\n",
      "Progress: 144/150\n",
      "Fetching logs for player 1631230 for season 2024-25...\n",
      "Progress: 145/150\n",
      "Fetching logs for player 1642270 for season 2024-25...\n",
      "Progress: 146/150\n",
      "Fetching logs for player 1628378 for season 2024-25...\n",
      "Progress: 147/150\n",
      "Fetching logs for player 1628978 for season 2024-25...\n",
      "Progress: 148/150\n",
      "Fetching logs for player 1627827 for season 2024-25...\n",
      "Progress: 149/150\n",
      "Fetching logs for player 203926 for season 2024-25...\n",
      "Progress: 150/150\n",
      "Fetching logs for player 203110 for season 2024-25...\n",
      "\n",
      "Saving 7290 game logs to nba_gamelogs_raw_2024-25.csv...\n",
      "Save complete.\n",
      "\n",
      "Total game logs available for 2024-25: 7290\n",
      "Unique players in logs: 150\n",
      "'FTA' column successfully included.\n",
      "'TOV' column successfully included.\n",
      "'FGA' column successfully included.\n",
      "'PTS' column successfully included.\n",
      "'MIN' column successfully included.\n",
      "'GAME_DATE' column successfully included.\n",
      "'MATCHUP' column successfully included.\n",
      "  SEASON_ID  Player_ID     Game_ID     GAME_DATE      MATCHUP WL  MIN  FGM  \\\n",
      "0     22024    1630639  0022401197  APR 13, 2025    TOR @ SAS  L   21    3   \n",
      "1     22024    1630639  0022401178  APR 11, 2025    TOR @ DAL  L   32    3   \n",
      "2     22024    1630639  0022401158  APR 09, 2025  TOR vs. CHA  W   28    5   \n",
      "3     22024    1630639  0022401134  APR 06, 2025    TOR @ BKN  W   22    5   \n",
      "4     22024    1630639  0022401121  APR 04, 2025  TOR vs. DET  L   23    2   \n",
      "\n",
      "   FGA  FG_PCT  ...  DREB  REB  AST  STL  BLK  TOV  PF  PTS  PLUS_MINUS  \\\n",
      "0    7   0.429  ...     0    0    0    0    0    1   1   14          -5   \n",
      "1   10   0.300  ...     8   10    2    1    0    0   3   12         -10   \n",
      "2    9   0.556  ...     4    6    7    1    0    0   1   14          18   \n",
      "3    9   0.556  ...     1    1    0    2    0    2   2   13          -6   \n",
      "4    7   0.286  ...     2    3    1    1    2    1   2    9          -2   \n",
      "\n",
      "   VIDEO_AVAILABLE  \n",
      "0                1  \n",
      "1                1  \n",
      "2                1  \n",
      "3                1  \n",
      "4                1  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function to get game logs for a player and season with delay\n",
    "def get_player_log(player_id, season='2024-25'): #<<< DEFAULT SEASON CORRECTED HERE\n",
    "    print(f\"Fetching logs for player {player_id} for season {season}...\")\n",
    "    try:\n",
    "        # Note: PlayerGameLog endpoint provides FGA, PTS, FTA, and TOV\n",
    "        log = playergamelog.PlayerGameLog(player_id=player_id, season=season)\n",
    "        df = log.get_data_frames()[0]\n",
    "        time.sleep(0.6) # NBA API rate limit\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching logs for player {player_id} (season {season}): {e}\")\n",
    "        time.sleep(0.6)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# --- Define Season-Specific Output File ---\n",
    "# SEASON variable is defined in the previous cell\n",
    "RAW_GAMELOG_FILE = f'nba_gamelogs_raw_{SEASON}.csv' #<<< FILENAME NOW INCLUDES CORRECT SEASON\n",
    "MIN_MINUTES_THRESHOLD = 15 # Minimum average minutes per game to be included\n",
    "MAX_PLAYERS_TO_FETCH = 150 # Limit players for faster fetching if needed - Increased slightly\n",
    "\n",
    "# --- Check if Processed Data Exists for THIS Season ---\n",
    "FETCH_REQUIRED = False\n",
    "if os.path.exists(RAW_GAMELOG_FILE):\n",
    "    print(f\"Loading existing raw game logs from {RAW_GAMELOG_FILE}...\")\n",
    "    try:\n",
    "        all_gamelogs_df = pd.read_csv(RAW_GAMELOG_FILE)\n",
    "        # Ensure Player_ID is integer if loaded from CSV\n",
    "        if 'Player_ID' in all_gamelogs_df.columns:\n",
    "            all_gamelogs_df['Player_ID'] = all_gamelogs_df['Player_ID'].astype(int)\n",
    "        # Check if essential columns are present (including TOV, FGA, FTA)\n",
    "        essential_cols_check = ['TOV', 'FGA', 'FTA', 'PTS', 'MIN']\n",
    "        missing_essential = [col for col in essential_cols_check if col not in all_gamelogs_df.columns]\n",
    "        if missing_essential:\n",
    "            print(f\"Warning: Missing essential columns ({missing_essential}) from existing CSV '{RAW_GAMELOG_FILE}'. Re-fetching required.\")\n",
    "            FETCH_REQUIRED = True\n",
    "        else:\n",
    "            print(f\"Essential columns found in existing CSV '{RAW_GAMELOG_FILE}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or checking CSV file {RAW_GAMELOG_FILE}: {e}. Re-fetching required.\")\n",
    "        FETCH_REQUIRED = True\n",
    "        all_gamelogs_df = pd.DataFrame() # Ensure it's empty if loading failed\n",
    "else:\n",
    "    print(f\"Raw game log file '{RAW_GAMELOG_FILE}' not found. Fetching data...\")\n",
    "    FETCH_REQUIRED = True\n",
    "    all_gamelogs_df = pd.DataFrame()\n",
    "\n",
    "# --- Fetch Data if Required ---\n",
    "if FETCH_REQUIRED:\n",
    "    # Remove old file if it exists but is incomplete\n",
    "    if os.path.exists(RAW_GAMELOG_FILE):\n",
    "        print(f\"Removing potentially incomplete file: {RAW_GAMELOG_FILE}\")\n",
    "        try:\n",
    "            os.remove(RAW_GAMELOG_FILE)\n",
    "        except OSError as e:\n",
    "            print(f\"Error removing file: {e}\")\n",
    "            \n",
    "    # --- Filter Players Based on Season Stats (e.g., Minutes Played) ---\n",
    "    print(f\"Fetching player stats for {SEASON} to filter...\")\n",
    "    player_ids_to_fetch = []\n",
    "    try:\n",
    "        player_stats = leaguedashplayerstats.LeagueDashPlayerStats(season=SEASON) # Uses SEASON variable\n",
    "        player_stats_df = player_stats.get_data_frames()[0]\n",
    "        time.sleep(0.6)\n",
    "        \n",
    "        # Filter players playing significant minutes\n",
    "        # Ensure MIN is numeric before filtering\n",
    "        player_stats_df['MIN'] = pd.to_numeric(player_stats_df['MIN'], errors='coerce')\n",
    "        relevant_players_df = player_stats_df[player_stats_df['MIN'] >= MIN_MINUTES_THRESHOLD].copy()\n",
    "        player_ids_to_fetch = relevant_players_df['PLAYER_ID'].unique().tolist()\n",
    "        print(f\"Found {len(player_ids_to_fetch)} players averaging >= {MIN_MINUTES_THRESHOLD} MPG for {SEASON}.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching player stats for {SEASON} filtering: {e}. Falling back to all active players.\")\n",
    "        traceback.print_exc()\n",
    "        # Fallback: Get all active players if stats fetch fails\n",
    "        active_players_df = players_df[players_df['is_active'] == True]\n",
    "        player_ids_to_fetch = active_players_df['id'].tolist()\n",
    "        print(f\"Fetching for all {len(player_ids_to_fetch)} currently active players (fallback).\")\n",
    "        \n",
    "    # --- Limit players if needed ---\n",
    "    if len(player_ids_to_fetch) > MAX_PLAYERS_TO_FETCH:\n",
    "        print(f\"Limiting fetch to {MAX_PLAYERS_TO_FETCH} players for speed.\")\n",
    "        player_ids_to_fetch = player_ids_to_fetch[:MAX_PLAYERS_TO_FETCH]\n",
    "        \n",
    "    # --- Fetching game logs for filtered players ---\n",
    "    if player_ids_to_fetch:\n",
    "        print(f\"Fetching game logs for {len(player_ids_to_fetch)} players for season {SEASON}...\")\n",
    "        fetched_logs = [] # Collect dataframes in a list first\n",
    "        for i, p_id in enumerate(player_ids_to_fetch):\n",
    "            print(f\"Progress: {i+1}/{len(player_ids_to_fetch)}\")\n",
    "            player_log_df = get_player_log(p_id, season=SEASON) # <<< PASS SEASON HERE\n",
    "            if not player_log_df.empty:\n",
    "                # Add Player_ID if it's missing (sometimes happens)\n",
    "                if 'Player_ID' not in player_log_df.columns:\n",
    "                     player_log_df['Player_ID'] = p_id\n",
    "                fetched_logs.append(player_log_df)\n",
    "                \n",
    "        # --- Concatenate and Save the fetched data ---\n",
    "        if fetched_logs:\n",
    "            all_gamelogs_df = pd.concat(fetched_logs, ignore_index=True)\n",
    "            print(f\"\\nSaving {len(all_gamelogs_df)} game logs to {RAW_GAMELOG_FILE}...\")\n",
    "            all_gamelogs_df.to_csv(RAW_GAMELOG_FILE, index=False)\n",
    "            print(\"Save complete.\")\n",
    "        else:\n",
    "            print(\"\\nNo game logs were fetched or concatenated.\")\n",
    "            all_gamelogs_df = pd.DataFrame() # Ensure it's an empty DF if nothing was fetched\n",
    "    else:\n",
    "        print(\"\\nNo player IDs identified for fetching.\")\n",
    "        all_gamelogs_df = pd.DataFrame()\n",
    "\n",
    "# --- Display results ---\n",
    "if 'all_gamelogs_df' in locals() and not all_gamelogs_df.empty:\n",
    "    print(f\"\\nTotal game logs available for {SEASON}: {len(all_gamelogs_df)}\")\n",
    "    print(f\"Unique players in logs: {all_gamelogs_df['Player_ID'].nunique()}\")\n",
    "    # Check essential columns after loading/fetching\n",
    "    essential_cols_check = ['FTA', 'TOV', 'FGA', 'PTS', 'MIN', 'GAME_DATE', 'MATCHUP']\n",
    "    for col in essential_cols_check:\n",
    "        if col in all_gamelogs_df.columns:\n",
    "            print(f\"'{col}' column successfully included.\")\n",
    "        else:\n",
    "            print(f\"Warning: '{col}' column is missing from the loaded/fetched data!\")\n",
    "    print(all_gamelogs_df.head())\n",
    "else:\n",
    "    print(f\"\\nall_gamelogs_df is empty for season {SEASON}. Cannot proceed with preprocessing/modeling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2much\\AppData\\Local\\Temp\\ipykernel_58584\\2850380591.py:9: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  processed_df['GAME_DATE'] = pd.to_datetime(processed_df['GAME_DATE'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing complete.\n",
      "      Player_ID     Game_ID  GAME_DATE      MATCHUP WL  MIN  PTS  REB  AST  \\\n",
      "4083     101108  0022400074 2024-10-24    SAS @ DAL  L   29    3    7    8   \n",
      "4082     101108  0022400094 2024-10-26  SAS vs. HOU  W   27    3    0    9   \n",
      "4081     101108  0022400109 2024-10-28  SAS vs. HOU  L   29   16    1    3   \n",
      "4080     101108  0022400125 2024-10-30    SAS @ OKC  L   26   14    5    9   \n",
      "4079     101108  0022400130 2024-10-31    SAS @ UTA  W   32   19    7   10   \n",
      "\n",
      "      FG3M  STL  BLK  TOV  FGA  FTA Opponent Home_Away  \n",
      "4083     1    1    0    2    6    0      DAL      Away  \n",
      "4082     1    1    0    4    3    0      HOU      Home  \n",
      "4081     3    1    0    2   10    3      HOU      Home  \n",
      "4080     3    1    1    3    9    1      OKC      Away  \n",
      "4079     3    2    0    1   13    0      UTA      Away  \n"
     ]
    }
   ],
   "source": [
    "# --- Data Preprocessing ---\n",
    "\n",
    "# Check if all_gamelogs_df exists and is not empty before proceeding\n",
    "if 'all_gamelogs_df' in locals() and not all_gamelogs_df.empty:\n",
    "    processed_df = all_gamelogs_df.copy()\n",
    "    \n",
    "    # Ensure GAME_DATE is datetime and sort for time-based features\n",
    "    if 'GAME_DATE' in processed_df.columns:\n",
    "        processed_df['GAME_DATE'] = pd.to_datetime(processed_df['GAME_DATE'])\n",
    "    else:\n",
    "        print(\"Error: 'GAME_DATE' column missing! Cannot proceed with time-based processing.\")\n",
    "        processed_df = pd.DataFrame() # Empty the df to prevent further errors\n",
    "\n",
    "    if not processed_df.empty:\n",
    "        processed_df = processed_df.sort_values(by=['Player_ID', 'GAME_DATE'])\n",
    "\n",
    "        # Select relevant columns (including FGA, FTA, and TOV)\n",
    "        # Ensure all expected columns exist, handle missing ones if necessary\n",
    "        expected_cols = ['Player_ID', 'Game_ID', 'GAME_DATE', 'MATCHUP', 'WL', \n",
    "                         'MIN', 'PTS', 'REB', 'AST', 'FG3M', 'STL', 'BLK', 'TOV', 'FGA', 'FTA'] # Added TOV\n",
    "        available_cols = [col for col in expected_cols if col in processed_df.columns]\n",
    "        missing_cols = [col for col in expected_cols if col not in processed_df.columns]\n",
    "        if missing_cols:\n",
    "            print(f\"Warning: Missing expected columns for initial selection: {missing_cols}. Proceeding with available columns.\")\n",
    "        processed_df = processed_df[available_cols]\n",
    "\n",
    "        # Ensure necessary columns for calculations are numeric, coercing errors\n",
    "        numeric_cols_check = ['PTS', 'FGA', 'FTA', 'MIN', 'TOV', 'REB', 'AST', 'FG3M', 'STL', 'BLK'] # Expanded numeric checks\n",
    "        for col in numeric_cols_check:\n",
    "            if col in processed_df.columns:\n",
    "                processed_df[col] = pd.to_numeric(processed_df[col], errors='coerce')\n",
    "            else:\n",
    "                 print(f\"Warning: Column {col} needed for processing is missing.\")\n",
    "                 \n",
    "        # Drop rows where essential numeric columns became NaN after coercion\n",
    "        # Important: Check if columns exist before adding to subset\n",
    "        dropna_subset = ['PTS', 'FGA', 'FTA', 'MIN']\n",
    "        if 'TOV' in processed_df.columns: dropna_subset.append('TOV')\n",
    "        if 'FGA' in processed_df.columns: dropna_subset.append('FGA')\n",
    "        if 'FTA' in processed_df.columns: dropna_subset.append('FTA')\n",
    "        \n",
    "        # Only drop if the columns actually exist in the DataFrame\n",
    "        actual_dropna_subset = [col for col in dropna_subset if col in processed_df.columns]\n",
    "        processed_df.dropna(subset=actual_dropna_subset, inplace=True)\n",
    "\n",
    "        # Parse Matchup to get Opponent and Home/Away\n",
    "        def parse_matchup(matchup_str):\n",
    "            if pd.isna(matchup_str):\n",
    "                 return 'Unknown', 'Unknown'\n",
    "            if '@' in matchup_str:\n",
    "                parts = matchup_str.split(' @ ')\n",
    "                opponent = parts[1] if len(parts) > 1 else 'Unknown'\n",
    "                home_away = 'Away'\n",
    "            elif 'vs.' in matchup_str:\n",
    "                parts = matchup_str.split(' vs. ')\n",
    "                opponent = parts[1] if len(parts) > 1 else 'Unknown'\n",
    "                home_away = 'Home'\n",
    "            else: \n",
    "                opponent = 'Unknown'\n",
    "                home_away = 'Unknown'\n",
    "            return opponent, home_away\n",
    "\n",
    "        if 'MATCHUP' in processed_df.columns:\n",
    "            # Apply the function and assign results back as new columns\n",
    "            parsed_matchup = processed_df['MATCHUP'].apply(lambda x: pd.Series(parse_matchup(x), index=['Opponent', 'Home_Away']))\n",
    "            processed_df = pd.concat([processed_df, parsed_matchup], axis=1)\n",
    "            # Handle potential empty results from apply if all MATCHUP were NaN\n",
    "            if 'Opponent' not in processed_df.columns:\n",
    "                 processed_df['Opponent'] = 'Unknown'\n",
    "            if 'Home_Away' not in processed_df.columns:\n",
    "                 processed_df['Home_Away'] = 'Unknown'\n",
    "        else:\n",
    "            print(\"Warning: 'MATCHUP' column not found. Cannot determine Opponent or Home/Away.\")\n",
    "            processed_df['Opponent'] = 'Unknown'\n",
    "            processed_df['Home_Away'] = 'Unknown'\n",
    "\n",
    "        print(\"Data preprocessing complete.\")\n",
    "        print(processed_df.head())\n",
    "    \n",
    "else:\n",
    "    print(\"Skipping Data Preprocessing because 'all_gamelogs_df' is not available or empty.\")\n",
    "    processed_df = pd.DataFrame() # Ensure processed_df exists even if empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Feature Engineering...\n",
      "Calculated Rest Days.\n",
      "Calculated Is_B2B_Second_Night.\n",
      "Calculated Player Usage Rate Proxy.\n",
      "Calculated TS%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2much\\AppData\\Local\\Temp\\ipykernel_58584\\3023094102.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  processed_df['Rest_Days'].fillna(processed_df['Rest_Days'].mode()[0], inplace=True)\n",
      "C:\\Users\\2much\\AppData\\Local\\Temp\\ipykernel_58584\\3023094102.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  processed_df['Player_USG_Proxy'].fillna(0, inplace=True)\n",
      "C:\\Users\\2much\\AppData\\Local\\Temp\\ipykernel_58584\\3023094102.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  processed_df['Player_USG_Proxy'].replace([np.inf, -np.inf], 0, inplace=True)\n",
      "C:\\Users\\2much\\AppData\\Local\\Temp\\ipykernel_58584\\3023094102.py:49: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  processed_df['TS%'].fillna(0, inplace=True)\n",
      "C:\\Users\\2much\\AppData\\Local\\Temp\\ipykernel_58584\\3023094102.py:50: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  processed_df['TS%'].replace([np.inf, -np.inf], 0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated EWMA features.\n",
      "Calculated base cumulative averages.\n",
      "Calculated cumulative averages for TS% and USG% Proxy.\n",
      "Merging fetched team defensive stats and pace...\n",
      "Opponent DEF_RATING merged. Filled NaNs with 113.8.\n",
      "Warning: 'Opponent_PACE' column not created after merge. Using default.\n",
      "Filled NaNs in engineered features: ['Rest_Days', 'Is_B2B_Second_Night', 'PTS_EWMA_3', 'PTS_EWMA_5', 'MIN_EWMA_3', 'MIN_EWMA_5', 'FGA_EWMA_3', 'FGA_EWMA_5', 'FTA_EWMA_3', 'FTA_EWMA_5', 'TS%_EWMA_3', 'TS%_EWMA_5', 'Player_USG_Proxy_EWMA_3', 'Player_USG_Proxy_EWMA_5', 'Avg_PTS_Season', 'PTS_Per36_Season', 'Avg_TS%_Season', 'Avg_USG%_Proxy_Season', 'Is_Home', 'Opponent_DEF_RATING', 'Opponent_PACE']\n",
      "Feature Engineering complete.\n",
      "   Player_ID     Game_ID  GAME_DATE      MATCHUP WL  MIN  PTS  REB  AST  FG3M  \\\n",
      "0     101108  0022400074 2024-10-24    SAS @ DAL  L   29    3    7    8     1   \n",
      "1     101108  0022400094 2024-10-26  SAS vs. HOU  W   27    3    0    9     1   \n",
      "2     101108  0022400109 2024-10-28  SAS vs. HOU  L   29   16    1    3     3   \n",
      "3     101108  0022400125 2024-10-30    SAS @ OKC  L   26   14    5    9     3   \n",
      "4     101108  0022400130 2024-10-31    SAS @ UTA  W   32   19    7   10     3   \n",
      "5     101108  0022400146 2024-11-02  SAS vs. MIN  W   33   15    4   13     3   \n",
      "6     101108  0022400168 2024-11-04    SAS @ LAC  L   33   14    6   10     2   \n",
      "7     101108  0022400173 2024-11-06    SAS @ HOU  L   20   10    2    4     3   \n",
      "8     101108  0022400183 2024-11-07  SAS vs. POR  W   27    6    2    6     1   \n",
      "9     101108  0022400197 2024-11-09  SAS vs. UTA  L   28    3    2    9     0   \n",
      "\n",
      "   ...  Avg_PTS_Season  PTS_Per36_Season  Cum_FGA  Cum_FTA  Cum_TOV  \\\n",
      "0  ...        0.000000          0.000000      0.0      0.0      0.0   \n",
      "1  ...        3.000000          3.724138      6.0      0.0      2.0   \n",
      "2  ...        3.000000          3.857143      9.0      0.0      6.0   \n",
      "3  ...        7.333333          9.317647     19.0      3.0      8.0   \n",
      "4  ...        9.000000         11.675676     28.0      4.0     11.0   \n",
      "5  ...       11.000000         13.846154     41.0      4.0     12.0   \n",
      "6  ...       11.666667         14.318182     50.0      6.0     13.0   \n",
      "7  ...       12.000000         14.468900     61.0      6.0     17.0   \n",
      "8  ...       11.750000         14.777293     68.0      7.0     19.0   \n",
      "9  ...       11.111111         14.062500     74.0      8.0     20.0   \n",
      "\n",
      "  Avg_TS%_Season Avg_USG%_Proxy_Season  Is_Home  Opponent_DEF_RATING  \\\n",
      "0       0.000000              0.000000        0           115.000000   \n",
      "1       0.250000              0.275862        1           110.300000   \n",
      "2       0.333333              0.267857        1           110.300000   \n",
      "3       0.541339              0.333176        0           106.600000   \n",
      "4       0.604839              0.367207        0           119.400000   \n",
      "5       0.643124              0.382937        1           110.800000   \n",
      "6       0.664894              0.372955        0           113.840321   \n",
      "7       0.659962              0.385837        0           110.300000   \n",
      "8       0.661227              0.393362        1           113.700000   \n",
      "9       0.644995              0.380937        1           119.400000   \n",
      "\n",
      "   Opponent_PACE  \n",
      "0          100.0  \n",
      "1          100.0  \n",
      "2          100.0  \n",
      "3          100.0  \n",
      "4          100.0  \n",
      "5          100.0  \n",
      "6          100.0  \n",
      "7          100.0  \n",
      "8          100.0  \n",
      "9          100.0  \n",
      "\n",
      "[10 rows x 46 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2much\\AppData\\Local\\Temp\\ipykernel_58584\\3023094102.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  processed_df['Avg_TS%_Season'].fillna(0, inplace=True)\n",
      "C:\\Users\\2much\\AppData\\Local\\Temp\\ipykernel_58584\\3023094102.py:111: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  processed_df['Avg_TS%_Season'].replace([np.inf, -np.inf], 0, inplace=True)\n",
      "C:\\Users\\2much\\AppData\\Local\\Temp\\ipykernel_58584\\3023094102.py:118: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  processed_df['Avg_USG%_Proxy_Season'].fillna(0, inplace=True)\n",
      "C:\\Users\\2much\\AppData\\Local\\Temp\\ipykernel_58584\\3023094102.py:119: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  processed_df['Avg_USG%_Proxy_Season'].replace([np.inf, -np.inf], 0, inplace=True)\n",
      "C:\\Users\\2much\\AppData\\Local\\Temp\\ipykernel_58584\\3023094102.py:164: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  processed_df['Opponent_DEF_RATING'].fillna(fill_value_def, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# --- Feature Engineering ---\n",
    "\n",
    "# Check if processed_df exists and is not empty\n",
    "if 'processed_df' in locals() and not processed_df.empty:\n",
    "    print(\"Starting Feature Engineering...\")\n",
    "    \n",
    "    # Calculate Rest Days\n",
    "    processed_df['Rest_Days'] = processed_df.groupby('Player_ID')['GAME_DATE'].diff().dt.days\n",
    "    # Fill first game NaN with a reasonable value (e.g., mode, average, or specific indicator)\n",
    "    # Using mode is better than a fixed value like 2 if the typical rest isn't 2 days\n",
    "    if not processed_df['Rest_Days'].mode().empty:\n",
    "        processed_df['Rest_Days'].fillna(processed_df['Rest_Days'].mode()[0], inplace=True)\n",
    "    else:\n",
    "        processed_df['Rest_Days'].fillna(2, inplace=True) # Fallback if mode is empty\n",
    "    print(\"Calculated Rest Days.\")\n",
    "\n",
    "    # Add Is_B2B_Second_Night feature\n",
    "    # B2B is when Rest_Days is exactly 1\n",
    "    processed_df['Is_B2B_Second_Night'] = processed_df['Rest_Days'].apply(lambda x: 1 if x == 1 else 0)\n",
    "    print(\"Calculated Is_B2B_Second_Night.\")\n",
    "    \n",
    "    # Calculate Player Usage Rate Proxy (Requires FGA, FTA, TOV, MIN)\n",
    "    # Using the simplified player-level proxy, but will use EWMA on this.\n",
    "    if all(col in processed_df.columns for col in ['FGA', 'FTA', 'TOV', 'MIN']):\n",
    "        processed_df['TOV'] = pd.to_numeric(processed_df['TOV'], errors='coerce').fillna(0)\n",
    "        processed_df['FGA'] = pd.to_numeric(processed_df['FGA'], errors='coerce').fillna(0)\n",
    "        processed_df['FTA'] = pd.to_numeric(processed_df['FTA'], errors='coerce').fillna(0)\n",
    "        processed_df['MIN'] = pd.to_numeric(processed_df['MIN'], errors='coerce').fillna(0)\n",
    "        \n",
    "        usg_numerator = processed_df['FGA'] + 0.44 * processed_df['FTA'] + processed_df['TOV']\n",
    "        usg_denominator = processed_df['MIN'] # Using Player MIN as proxy denominator\n",
    "        processed_df['Player_USG_Proxy'] = np.where(usg_denominator == 0, 0, usg_numerator / usg_denominator)\n",
    "        processed_df['Player_USG_Proxy'].fillna(0, inplace=True)\n",
    "        processed_df['Player_USG_Proxy'].replace([np.inf, -np.inf], 0, inplace=True)\n",
    "        print(\"Calculated Player Usage Rate Proxy.\")\n",
    "    else:\n",
    "        missing = [col for col in ['FGA', 'FTA', 'TOV', 'MIN'] if col not in processed_df.columns]\n",
    "        print(f\"Warning: Could not calculate Player Usage Rate Proxy due to missing columns: {missing}.\")\n",
    "        processed_df['Player_USG_Proxy'] = 0 # Assign default value\n",
    "        \n",
    "    # Calculate True Shooting Percentage (TS%)\n",
    "    if all(col in processed_df.columns for col in ['PTS', 'FGA', 'FTA']):\n",
    "        processed_df['PTS'] = pd.to_numeric(processed_df['PTS'], errors='coerce').fillna(0)\n",
    "        processed_df['FGA'] = pd.to_numeric(processed_df['FGA'], errors='coerce').fillna(0)\n",
    "        processed_df['FTA'] = pd.to_numeric(processed_df['FTA'], errors='coerce').fillna(0)\n",
    "        \n",
    "        denominator = 2 * (processed_df['FGA'] + 0.44 * processed_df['FTA'])\n",
    "        processed_df['TS%'] = np.where(denominator == 0, 0, processed_df['PTS'] / denominator)\n",
    "        processed_df['TS%'].fillna(0, inplace=True)\n",
    "        processed_df['TS%'].replace([np.inf, -np.inf], 0, inplace=True)\n",
    "        print(\"Calculated TS%.\")\n",
    "    else:\n",
    "        missing = [col for col in ['PTS', 'FGA', 'FTA'] if col not in processed_df.columns]\n",
    "        print(f\"Warning: Could not calculate TS% due to missing columns: {missing}.\")\n",
    "        processed_df['TS%'] = 0 # Assign default value\n",
    "\n",
    "    # Exponentially Weighted Moving Averages (Sharper Recency)\n",
    "    cols_for_ewma = ['PTS', 'MIN', 'FGA', 'FTA', 'TS%', 'Player_USG_Proxy'] # Use the calculated features\n",
    "    ewma_spans = [3, 5] # Spans for EWMA\n",
    "    \n",
    "    for col in cols_for_ewma:\n",
    "        if col in processed_df.columns:\n",
    "            # Ensure column is numeric before EWMA calculation\n",
    "            processed_df[col] = pd.to_numeric(processed_df[col], errors='coerce').fillna(0)\n",
    "            \n",
    "            for span in ewma_spans:\n",
    "                # Calculate EWMA and shift by 1 to get previous game's average\n",
    "                # Using adjust=False provides a more stable weighting for time series\n",
    "                processed_df[f'{col}_EWMA_{span}'] = processed_df.groupby('Player_ID')[col].transform(\n",
    "                    lambda x: x.ewm(span=span, adjust=False).mean().shift(1)\n",
    "                )\n",
    "        else:\n",
    "            print(f\"Warning: Column '{col}' not found for EWMA calculation.\")\n",
    "\n",
    "    print(\"Calculated EWMA features.\")\n",
    "\n",
    "    # Cumulative Season Averages (Shifted) - Keep these for long-term context\n",
    "    # Ensure required columns exist before cumulative calculations\n",
    "    cum_avg_base_cols = ['PTS', 'MIN']\n",
    "    cum_avg_usg_ts_cols = ['FGA', 'FTA', 'TOV'] # Needed for Avg_TS/USG_Season\n",
    "\n",
    "    # Check if base columns exist\n",
    "    if all(col in processed_df.columns for col in cum_avg_base_cols):\n",
    "        processed_df['Cum_PTS'] = processed_df.groupby('Player_ID')['PTS'].transform(lambda x: x.expanding().sum().shift(1))\n",
    "        processed_df['Cum_MIN'] = processed_df.groupby('Player_ID')['MIN'].transform(lambda x: x.expanding().sum().shift(1))\n",
    "        processed_df['Cum_Games'] = processed_df.groupby('Player_ID').cumcount() \n",
    "\n",
    "        processed_df['Avg_PTS_Season'] = (processed_df['Cum_PTS'] / processed_df['Cum_Games']).replace([np.inf, -np.inf, np.nan], 0)\n",
    "        processed_df['PTS_Per36_Season'] = (processed_df['Cum_PTS'] / processed_df['Cum_MIN'] * 36).replace([np.inf, -np.inf, np.nan], 0)\n",
    "        print(\"Calculated base cumulative averages.\")\n",
    "    else:\n",
    "         missing_base_cum = [col for col in cum_avg_base_cols if col not in processed_df.columns]\n",
    "         print(f\"Warning: One or more columns ({missing_base_cum}) missing for base cumulative average calculation.\")\n",
    "\n",
    "    # Check if USG/TS columns exist for their cumulative averages\n",
    "    if all(col in processed_df.columns for col in cum_avg_usg_ts_cols):\n",
    "         # Need Cum_PTS, Cum_FGA, Cum_FTA, Cum_TOV, Cum_MIN\n",
    "        if 'Cum_PTS' not in processed_df.columns:\n",
    "             processed_df['Cum_PTS'] = processed_df.groupby('Player_ID')['PTS'].transform(lambda x: x.expanding().sum().shift(1)).fillna(0)\n",
    "        if 'Cum_MIN' not in processed_df.columns:\n",
    "             processed_df['Cum_MIN'] = processed_df.groupby('Player_ID')['MIN'].transform(lambda x: x.expanding().sum().shift(1)).fillna(0)\n",
    "             \n",
    "        processed_df['Cum_FGA'] = processed_df.groupby('Player_ID')['FGA'].transform(lambda x: x.expanding().sum().shift(1)).fillna(0)\n",
    "        processed_df['Cum_FTA'] = processed_df.groupby('Player_ID')['FTA'].transform(lambda x: x.expanding().sum().shift(1)).fillna(0)\n",
    "        processed_df['Cum_TOV'] = processed_df.groupby('Player_ID')['TOV'].transform(lambda x: x.expanding().sum().shift(1)).fillna(0)\n",
    "        \n",
    "        # Cumulative TS% calculation\n",
    "        cum_ts_denominator = 2 * (processed_df['Cum_FGA'] + 0.44 * processed_df['Cum_FTA'])\n",
    "        processed_df['Avg_TS%_Season'] = np.where(cum_ts_denominator == 0, 0, processed_df['Cum_PTS'] / cum_ts_denominator)\n",
    "        processed_df['Avg_TS%_Season'].fillna(0, inplace=True)\n",
    "        processed_df['Avg_TS%_Season'].replace([np.inf, -np.inf], 0, inplace=True)\n",
    "        \n",
    "        # Cumulative USG% Proxy calculation\n",
    "        # Sticking to simplified proxy with player MIN \n",
    "        cum_usg_numerator = processed_df['Cum_FGA'] + 0.44 * processed_df['Cum_FTA'] + processed_df['Cum_TOV']\n",
    "        cum_usg_denominator = processed_df['Cum_MIN'] \n",
    "        processed_df['Avg_USG%_Proxy_Season'] = np.where(cum_usg_denominator == 0, 0, cum_usg_numerator / cum_usg_denominator)\n",
    "        processed_df['Avg_USG%_Proxy_Season'].fillna(0, inplace=True)\n",
    "        processed_df['Avg_USG%_Proxy_Season'].replace([np.inf, -np.inf], 0, inplace=True)\n",
    "        \n",
    "        print(\"Calculated cumulative averages for TS% and USG% Proxy.\")\n",
    "    else:\n",
    "         missing_usg_ts_cum = [col for col in cum_avg_usg_ts_cols if col not in processed_df.columns]\n",
    "         print(f\"Warning: One or more columns ({missing_usg_ts_cum}) missing for TS/USG cumulative average calculation.\")\n",
    "\n",
    "    # Other Features\n",
    "    if 'Home_Away' in processed_df.columns:\n",
    "        processed_df['Is_Home'] = processed_df['Home_Away'].apply(lambda x: 1 if x == 'Home' else 0)\n",
    "    else:\n",
    "        processed_df['Is_Home'] = 0 # Default if Home_Away is missing\n",
    "\n",
    "    # Merge Opponent Stats (DEF_RATING and PACE)\n",
    "    # Use fallback values if team_stats_df is empty (due to fetch error)\n",
    "    DEFAULT_DEF_RATING = 115.0 \n",
    "    DEFAULT_PACE = 100.0\n",
    "\n",
    "    if 'team_stats_df' in locals() and not team_stats_df.empty and 'TEAM_ABBREVIATION' in team_stats_df.columns and 'Opponent' in processed_df.columns:\n",
    "        print(\"Merging fetched team defensive stats and pace...\")\n",
    "        team_stats_to_merge = team_stats_df.rename(columns={\n",
    "            'TEAM_ABBREVIATION': 'Opponent',\n",
    "            'DEF_RATING': 'Opponent_DEF_RATING',\n",
    "            'PACE': 'Opponent_PACE'\n",
    "        })\n",
    "        \n",
    "        # Ensure 'Opponent' column type alignment\n",
    "        try:\n",
    "            processed_df['Opponent'] = processed_df['Opponent'].astype(team_stats_to_merge['Opponent'].dtype)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not align Opponent column types for merge: {e}\")\n",
    "            \n",
    "        # Merge only the required columns from team_stats_to_merge\n",
    "        merge_cols = ['Opponent']\n",
    "        if 'Opponent_DEF_RATING' in team_stats_to_merge.columns: merge_cols.append('Opponent_DEF_RATING')\n",
    "        if 'Opponent_PACE' in team_stats_to_merge.columns: merge_cols.append('Opponent_PACE')\n",
    "\n",
    "        if len(merge_cols) > 1:\n",
    "            processed_df = pd.merge(processed_df, team_stats_to_merge[merge_cols], on='Opponent', how='left')\n",
    "            \n",
    "            # Handle NaNs after merge\n",
    "            if 'Opponent_DEF_RATING' in processed_df.columns:\n",
    "                 processed_df['Opponent_DEF_RATING'] = pd.to_numeric(processed_df['Opponent_DEF_RATING'], errors='coerce')\n",
    "                 avg_def_rating = processed_df['Opponent_DEF_RATING'].mean()\n",
    "                 fill_value_def = avg_def_rating if not pd.isna(avg_def_rating) else DEFAULT_DEF_RATING\n",
    "                 processed_df['Opponent_DEF_RATING'].fillna(fill_value_def, inplace=True)\n",
    "                 print(f\"Opponent DEF_RATING merged. Filled NaNs with {fill_value_def:.1f}.\")\n",
    "            else:\n",
    "                 print(\"Warning: 'Opponent_DEF_RATING' column not created after merge. Using default.\")\n",
    "                 processed_df['Opponent_DEF_RATING'] = DEFAULT_DEF_RATING\n",
    "\n",
    "            if 'Opponent_PACE' in processed_df.columns:\n",
    "                 processed_df['Opponent_PACE'] = pd.to_numeric(processed_df['Opponent_PACE'], errors='coerce')\n",
    "                 avg_pace = processed_df['Opponent_PACE'].mean()\n",
    "                 fill_value_pace = avg_pace if not pd.isna(avg_pace) else DEFAULT_PACE\n",
    "                 processed_df['Opponent_PACE'].fillna(fill_value_pace, inplace=True)\n",
    "                 print(f\"Opponent PACE merged. Filled NaNs with {fill_value_pace:.1f}.\")\n",
    "            else:\n",
    "                 print(\"Warning: 'Opponent_PACE' column not created after merge. Using default.\")\n",
    "                 processed_df['Opponent_PACE'] = DEFAULT_PACE\n",
    "\n",
    "        else:\n",
    "             print(\"Warning: No relevant team stats columns found for merging.\")\n",
    "             processed_df['Opponent_DEF_RATING'] = DEFAULT_DEF_RATING\n",
    "             processed_df['Opponent_PACE'] = DEFAULT_PACE\n",
    "\n",
    "    else:\n",
    "        print(f\"Warning: Team stats not available or Opponent column missing. Using default DEF_RATING ({DEFAULT_DEF_RATING}) and PACE ({DEFAULT_PACE}).\")\n",
    "        processed_df['Opponent_DEF_RATING'] = DEFAULT_DEF_RATING\n",
    "        processed_df['Opponent_PACE'] = DEFAULT_PACE\n",
    "\n",
    "    # Final Fill NA for all engineered features (EWMA, cumulative, boolean, opponent)\n",
    "    # Identify all potential feature columns created dynamically\n",
    "    engineered_cols = [col for col in processed_df.columns \n",
    "                       if '_EWMA_' in col \n",
    "                       or '_Roll_' in col # Keep roll for now if EWMA fails, or remove if EWMA is primary\n",
    "                       or '_Season' in col \n",
    "                       or col in ['Is_Home', 'Opponent_DEF_RATING', 'Opponent_PACE', 'Rest_Days', 'Is_B2B_Second_Night']]\n",
    "    \n",
    "    # Filter to only columns that actually exist in the DataFrame\n",
    "    existing_engineered_cols = [col for col in engineered_cols if col in processed_df.columns]\n",
    "    \n",
    "    # Fill NaNs created by shifting/EWMA at the beginning of a player's season\n",
    "    if existing_engineered_cols:\n",
    "        processed_df[existing_engineered_cols] = processed_df[existing_engineered_cols].fillna(0)\n",
    "        print(f\"Filled NaNs in engineered features: {existing_engineered_cols}\")\n",
    "    else:\n",
    "        print(\"No engineered features found to fill NaNs.\")\n",
    "\n",
    "    print(\"Feature Engineering complete.\")\n",
    "    print(processed_df.head(10))\n",
    "else:\n",
    "    print(\"Skipping Feature Engineering because 'processed_df' is not available or empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for modeling...\n",
      "Features selected for modeling: ['PTS_EWMA_3', 'PTS_EWMA_5', 'MIN_EWMA_3', 'MIN_EWMA_5', 'FGA_EWMA_3', 'FGA_EWMA_5', 'FTA_EWMA_3', 'FTA_EWMA_5', 'TS%_EWMA_3', 'TS%_EWMA_5', 'Player_USG_Proxy_EWMA_3', 'Player_USG_Proxy_EWMA_5', 'Avg_PTS_Season', 'PTS_Per36_Season', 'Avg_TS%_Season', 'Avg_USG%_Proxy_Season', 'Opponent_DEF_RATING', 'Opponent_PACE', 'Rest_Days', 'Is_B2B_Second_Night', 'Is_Home']\n",
      "Applying log1p transformation to target variable 'PTS'.\n",
      "Data prepared for modeling (target transformed). Training set size: 5832, Testing set size: 1458\n",
      "Original Min/Max PTS in Test Set: 0/49\n",
      "Transformed Min/Max PTS in Test Set: 0.0000/3.9120\n"
     ]
    }
   ],
   "source": [
    "# --- Prepare Data for Modeling ---\n",
    "\n",
    "# Check if processed_df exists and is not empty\n",
    "if 'processed_df' in locals() and not processed_df.empty:\n",
    "    print(\"Preparing data for modeling...\")\n",
    "    \n",
    "    # Define required columns based on features engineered\n",
    "    # Prefer EWMA over simple rolling if both exist\n",
    "    feature_candidates = [\n",
    "        'PTS_EWMA_3', 'PTS_EWMA_5',\n",
    "        'MIN_EWMA_3', 'MIN_EWMA_5',\n",
    "        'FGA_EWMA_3', 'FGA_EWMA_5',\n",
    "        'FTA_EWMA_3', 'FTA_EWMA_5',\n",
    "        'TS%_EWMA_3', 'TS%_EWMA_5',\n",
    "        'Player_USG_Proxy_EWMA_3', 'Player_USG_Proxy_EWMA_5',\n",
    "        'Avg_PTS_Season', 'PTS_Per36_Season', 'Avg_TS%_Season', 'Avg_USG%_Proxy_Season',\n",
    "        'Opponent_DEF_RATING', 'Opponent_PACE',\n",
    "        'Rest_Days', 'Is_B2B_Second_Night', 'Is_Home'\n",
    "    ]\n",
    "    \n",
    "    # Filter to only columns that actually exist in processed_df\n",
    "    features = [col for col in feature_candidates if col in processed_df.columns]\n",
    "    \n",
    "    # Add simple rolling average fallbacks if EWMA was not created\n",
    "    fallback_features = [\n",
    "        'PTS_Roll_3', 'PTS_Roll_5',\n",
    "        'MIN_Roll_3', 'MIN_Roll_5',\n",
    "        'FGA_Roll_3', 'FGA_Roll_5',\n",
    "        'FTA_Roll_3', 'FTA_Roll_5',\n",
    "        'TS%_Roll_3', 'TS%_Roll_5',\n",
    "        'Player_USG_Proxy_Roll_3', 'Player_USG_Proxy_Roll_5'\n",
    "    ]\n",
    "    for fb_col in fallback_features:\n",
    "        # Add the fallback if the EWMA equivalent is NOT in features AND the fallback exists\n",
    "        ewma_equiv = fb_col.replace('_Roll_', '_EWMA_')\n",
    "        if fb_col in processed_df.columns and ewma_equiv not in features and fb_col not in features:\n",
    "             features.append(fb_col)\n",
    "             \n",
    "    print(f\"Features selected for modeling: {features}\")\n",
    "\n",
    "    # Define target variable\n",
    "    target = 'PTS'\n",
    "    \n",
    "    if target not in processed_df.columns:\n",
    "        print(f\"Error: Target variable '{target}' not found in processed_df. Cannot proceed with modeling.\")\n",
    "        model_df = pd.DataFrame()\n",
    "        X_train, X_test, y_train, y_test, y_test_original = [None]*5\n",
    "    else:\n",
    "        # Drop rows where target or any selected feature is missing\n",
    "        # NaNs in engineered features should be handled by fillna(0) in Feature Engineering \n",
    "        subset_for_dropna = [target] + features\n",
    "        actual_subset_for_dropna = [col for col in subset_for_dropna if col in processed_df.columns]\n",
    "        model_df = processed_df.dropna(subset=actual_subset_for_dropna).copy()\n",
    "\n",
    "        # Check if enough data remains\n",
    "        if model_df.empty or len(model_df) < 10:\n",
    "            print(\"Not enough data with required features and target to build a model.\")\n",
    "            X_train, X_test, y_train, y_test, y_test_original = [None]*5 \n",
    "        else:\n",
    "            X = model_df[features]\n",
    "            y = model_df[target]\n",
    "            \n",
    "            # Check for NaN/inf in features or target before split\n",
    "            if X.isnull().values.any() or y.isnull().values.any() or np.isinf(X.values).any() or np.isinf(y.values).any():\n",
    "                 print(\"Warning: NaN or Inf values detected before train/test split. Attempting to fill with 0.\")\n",
    "                 X = X.fillna(0)\n",
    "                 y = y.fillna(0)\n",
    "                 X = X.replace([np.inf, -np.inf], 0)\n",
    "                 y = y.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "            \n",
    "            y_test_original = y_test.copy()\n",
    "\n",
    "            # Apply Target Transformation (log1p)\n",
    "            print(f\"Applying log1p transformation to target variable '{target}'.\")\n",
    "            y_train = np.log1p(y_train)\n",
    "            y_test = np.log1p(y_test)\n",
    "            \n",
    "            print(f\"Data prepared for modeling (target transformed). Training set size: {X_train.shape[0]}, Testing set size: {X_test.shape[0]}\")\n",
    "            print(f\"Original Min/Max PTS in Test Set: {y_test_original.min()}/{y_test_original.max()}\")\n",
    "            print(f\"Transformed Min/Max PTS in Test Set: {y_test.min():.4f}/{y_test.max():.4f}\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping Data Preparation for Modeling because 'processed_df' is not available or empty.\")\n",
    "    X_train, X_test, y_train, y_test, y_test_original = [None]*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Avg_PTS_Season Distribution (Training Data) ---\n",
      "count    5832.000000\n",
      "mean       10.465235\n",
      "std         6.941945\n",
      "min         0.000000\n",
      "25%         4.877287\n",
      "50%         9.318665\n",
      "75%        15.112022\n",
      "max        36.000000\n",
      "Name: Avg_PTS_Season, dtype: float64\n",
      "\n",
      "--- Sample Counts for Potential Thresholds (Training Data) ---\n",
      "Players >= 12 PPG: 2030 (34.8%)\n",
      "Players >= 15 PPG: 1479 (25.4%)\n",
      "Players >= 18 PPG: 985 (16.9%)\n",
      "\n",
      "Using threshold: Avg_PTS_Season >= 15\n",
      "\n",
      "--- Data Segmentation Complete ---\n",
      "Scorers - Train: 1479, Test: 393\n",
      "Role Players - Train: 4353, Test: 1065\n"
     ]
    }
   ],
   "source": [
    "# --- Analyze Distribution and Segment Data ---\n",
    "\n",
    "# Check if X_train and y_test_original exist and are not None\n",
    "if 'X_train' in locals() and X_train is not None and 'y_test_original' in locals() and y_test_original is not None:\n",
    "    print(\"--- Avg_PTS_Season Distribution (Training Data) ---\")\n",
    "    # Use the original Avg_PTS_Season from X_train which was not log-transformed\n",
    "    if 'Avg_PTS_Season' in X_train.columns:\n",
    "        print(X_train['Avg_PTS_Season'].describe())\n",
    "        \n",
    "        print(\"\\n--- Sample Counts for Potential Thresholds (Training Data) ---\")\n",
    "        for threshold in [12, 15, 18]:\n",
    "            count = (X_train['Avg_PTS_Season'] >= threshold).sum()\n",
    "            print(f\"Players >= {threshold} PPG: {count} ({(count / len(X_train) * 100):.1f}%)\")\n",
    "            \n",
    "        # Define the chosen threshold (using the same threshold as before)\n",
    "        scorer_threshold = 15\n",
    "        print(f\"\\nUsing threshold: Avg_PTS_Season >= {scorer_threshold}\")\n",
    "        \n",
    "        # Create segmentation masks for TRAIN and TEST sets\n",
    "        train_scorer_mask = X_train['Avg_PTS_Season'] >= scorer_threshold\n",
    "        test_scorer_mask = X_test['Avg_PTS_Season'] >= scorer_threshold # Use X_test for the mask\n",
    "        \n",
    "        # Segment Training Data (X is features, y is TRANSFORMED target)\n",
    "        X_train_scorers = X_train[train_scorer_mask]\n",
    "        y_train_scorers = y_train[train_scorer_mask]\n",
    "        X_train_role = X_train[~train_scorer_mask]\n",
    "        y_train_role = y_train[~train_scorer_mask]\n",
    "        \n",
    "        # Segment Testing Data (X is features, y is TRANSFORMED target, y_original is ORIGINAL target)\n",
    "        X_test_scorers = X_test[test_scorer_mask]\n",
    "        y_test_scorers = y_test[test_scorer_mask]\n",
    "        y_test_scorers_original = y_test_original[test_scorer_mask] # Segment original target too\n",
    "\n",
    "        X_test_role = X_test[~test_scorer_mask]\n",
    "        y_test_role = y_test[~test_scorer_mask]\n",
    "        y_test_role_original = y_test_original[~test_scorer_mask] # Segment original target too\n",
    "        \n",
    "        print(\"\\n--- Data Segmentation Complete ---\")\n",
    "        print(f\"Scorers - Train: {len(X_train_scorers)}, Test: {len(X_test_scorers)}\")\n",
    "        print(f\"Role Players - Train: {len(X_train_role)}, Test: {len(X_test_role)}\")\n",
    "        \n",
    "        # Store segment masks for later combined evaluation\n",
    "        test_scorer_mask_global = test_scorer_mask\n",
    "        test_role_mask_global = ~test_scorer_mask\n",
    "\n",
    "    else:\n",
    "        print(\"Warning: 'Avg_PTS_Season' not found in X_train. Skipping segmentation.\")\n",
    "        X_train_scorers, y_train_scorers, X_test_scorers, y_test_scorers, y_test_scorers_original = [None]*5\n",
    "        X_train_role, y_train_role, X_test_role, y_test_role, y_test_role_original = [None]*5\n",
    "        test_scorer_mask_global = None\n",
    "        test_role_mask_global = None\n",
    "\n",
    "else:\n",
    "    print(\"Skipping segmentation as training data or original test target is not available.\")\n",
    "    X_train_scorers, y_train_scorers, X_test_scorers, y_test_scorers, y_test_scorers_original = [None]*5\n",
    "    X_train_role, y_train_role, X_test_role, y_test_role, y_test_role_original = [None]*5\n",
    "    test_scorer_mask_global = None\n",
    "    test_role_mask_global = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Evaluation Function (Modified for Transformed Target) ---\n",
    "\n",
    "def evaluate_model(model, X_test, y_test_transformed, y_test_original, model_name, X_train_cols=None):\n",
    "    \"\"\"Calculates and prints evaluation metrics for a given model, handling transformed targets.\"\"\"\n",
    "    print(f\"\\n--- {model_name} Evaluation ---\")\n",
    "    \n",
    "    if model is None or X_test is None or y_test_original is None or X_test.empty:\n",
    "        print(f\"Skipping {model_name} evaluation as model was not trained or test data was missing.\")\n",
    "        return\n",
    "        \n",
    "    try:\n",
    "        # Predict on the transformed scale\n",
    "        y_pred_transformed = model.predict(X_test)\n",
    "\n",
    "        # Transform predictions back to the original scale\n",
    "        y_pred_original = np.expm1(y_pred_transformed)\n",
    "        y_pred_original[y_pred_original < 0] = 0 \n",
    "\n",
    "        # --- Basic Error Analysis (using original scale) ---\n",
    "        if X_test.index.equals(y_test_original.index):\n",
    "             X_test_results = X_test.copy()\n",
    "             X_test_results['Actual_PTS'] = y_test_original\n",
    "             X_test_results['Predicted_PTS'] = y_pred_original\n",
    "             X_test_results['Error'] = X_test_results['Actual_PTS'] - X_test_results['Predicted_PTS']\n",
    "             X_test_results['Abs_Error'] = np.abs(X_test_results['Error'])\n",
    "        else:\n",
    "             print(\"Warning: X_test index does not match y_test_original index. Skipping detailed error analysis table.\")\n",
    "             X_test_results = pd.DataFrame({'Actual_PTS': y_test_original, 'Predicted_PTS': y_pred_original})\n",
    "             X_test_results['Error'] = X_test_results['Actual_PTS'] - X_test_results['Predicted_PTS']\n",
    "             X_test_results['Abs_Error'] = np.abs(X_test_results['Error'])\n",
    "\n",
    "        # --- Calculate Metrics (using original scale) ---\n",
    "        mae = mean_absolute_error(y_test_original, y_pred_original)\n",
    "        mse = mean_squared_error(y_test_original, y_pred_original) \n",
    "        rmse = np.sqrt(mse) \n",
    "        \n",
    "        non_zero_mask = y_test_original != 0\n",
    "        if np.any(non_zero_mask):\n",
    "            mape = mean_absolute_percentage_error(y_test_original[non_zero_mask], y_pred_original[non_zero_mask])\n",
    "            mape_note = f\"(excluding { (~non_zero_mask).sum() } games with 0 actual points)\"\n",
    "        else:\n",
    "            mape = np.nan\n",
    "            mape_note = \"(MAPE not calculable)\"\n",
    "        \n",
    "        within_3_pts = X_test_results['Abs_Error'] <= 3\n",
    "        within_3_pts_accuracy = within_3_pts.mean() * 100\n",
    "        \n",
    "        # --- Print Metrics ---\n",
    "        print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "        print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\") \n",
    "        print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2%} {mape_note}\")\n",
    "        print(f\"Accuracy (within +/- 3 points): {within_3_pts_accuracy:.2f}%\")\n",
    "        \n",
    "        # --- Print Sample Predictions and Errors ---\n",
    "        print(f\"\\nSample Predictions vs Actual ({model_name}):\")\n",
    "        print(X_test_results.head())\n",
    "        \n",
    "        print(\"\\nLargest Errors (Top 5):\")\n",
    "        print(X_test_results.sort_values(by='Abs_Error', ascending=False).head())\n",
    "        \n",
    "        # Optional: Feature Importances (Specific to tree-based models)\n",
    "        if hasattr(model, 'feature_importances_') and X_train_cols is not None:\n",
    "            print(f\"\\nFeature Importances ({model_name}):\")\n",
    "            importance_features = X_train_cols if isinstance(X_train_cols, pd.Index) else pd.Index(X_train_cols)\n",
    "            if len(importance_features) == len(model.feature_importances_):\n",
    "                importances = pd.DataFrame({\n",
    "                    'Feature': importance_features,\n",
    "                    'Importance': model.feature_importances_\n",
    "                }).sort_values(by='Importance', ascending=False)\n",
    "                print(importances)\n",
    "            else:\n",
    "                print(\"Warning: Feature count mismatch between X_train_cols and model importances. Cannot display importances.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during {model_name} evaluation: {e}\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function to Train, Evaluate, and Save Models for a Segment ---\n",
    "\n",
    "def train_evaluate_segment(X_train_seg, y_train_seg_transformed, X_test_seg, y_test_seg_original, segment_label):\n",
    "    \"\"\"Tunes, trains, evaluates, and saves Ridge, XGBoost, and LightGBM models for a data segment.\"\"\"\n",
    "    global MODEL_DIR # Use the global model directory variable\n",
    "    print(f\"\\n{'='*20} Processing Segment: {segment_label} {'='*20}\")\n",
    "    \n",
    "    if X_train_seg is None or y_train_seg_transformed is None or X_train_seg.empty or len(X_train_seg) < 10:\n",
    "        print(f\"Skipping {segment_label} segment due to insufficient training data ({len(X_train_seg) if X_train_seg is not None else 0} samples).\")\n",
    "        return None, None, None\n",
    "        \n",
    "    model_ridge_seg = None\n",
    "    model_xgb_seg = None\n",
    "    model_lgbm_seg = None\n",
    "    \n",
    "    # --- Ridge --- \n",
    "    print(f\"\\n--- Tuning Ridge Regression Model ({segment_label}) ---\")\n",
    "    param_grid_ridge = {'alpha': [0.1, 1.0, 10.0, 100.0]}\n",
    "    ridge_estimator = Ridge()\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    grid_search_ridge = GridSearchCV(ridge_estimator, param_grid_ridge, cv=tscv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "    try:\n",
    "        grid_search_ridge.fit(X_train_seg, y_train_seg_transformed)\n",
    "        model_ridge_seg = grid_search_ridge.best_estimator_\n",
    "        print(f\"Best alpha found for Ridge ({segment_label}): {grid_search_ridge.best_params_['alpha']}\")\n",
    "        print(f\"Tuned Ridge Regression Model training complete ({segment_label}).\")\n",
    "        save_path = os.path.join(MODEL_DIR, f'ridge_model_{segment_label.lower().replace(\" \", \"_\")}.pkl')\n",
    "        joblib.dump(model_ridge_seg, save_path)\n",
    "        print(f\"Ridge model saved for {segment_label} to {save_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Ridge GridSearchCV ({segment_label}): {e}\")\n",
    "        traceback.print_exc()\n",
    "        model_ridge_seg = None\n",
    "    evaluate_model(model_ridge_seg, X_test_seg, y_test_seg_original, y_test_seg_original, f\"Tuned Ridge ({segment_label})\")\n",
    "    \n",
    "    # --- XGBoost ---\n",
    "    print(f\"\\n--- Tuning XGBoost Model ({segment_label}) ---\")\n",
    "    param_grid_xgb = {\n",
    "        'n_estimators': [100, 200], 'max_depth': [3, 5], 'learning_rate': [0.05, 0.1],\n",
    "        'subsample': [0.8, 1.0], 'colsample_bytree': [0.8, 1.0], 'reg_alpha': [0, 0.1], 'reg_lambda': [1.0]\n",
    "    }\n",
    "    if len(X_train_seg) > 500:\n",
    "        param_grid_xgb['n_estimators'] = [100, 200, 300]\n",
    "        param_grid_xgb['max_depth'] = [3, 5, 7]\n",
    "        param_grid_xgb['learning_rate'] = [0.01, 0.05, 0.1]\n",
    "        param_grid_xgb['subsample'] = [0.7, 0.8, 0.9, 1.0]\n",
    "        param_grid_xgb['colsample_bytree'] = [0.7, 0.8, 0.9, 1.0]\n",
    "        param_grid_xgb['reg_alpha'] = [0, 0.1, 0.5]\n",
    "        param_grid_xgb['reg_lambda'] = [0.5, 1.0, 1.5]\n",
    "    xgb_estimator = XGBRegressor(random_state=42, objective='reg:squarederror', tree_method='hist')\n",
    "    grid_search_xgb = GridSearchCV(estimator=xgb_estimator, param_grid=param_grid_xgb, scoring='neg_mean_absolute_error', cv=tscv, n_jobs=-1, verbose=0)\n",
    "    try:\n",
    "        print(f\"Starting XGBoost GridSearchCV ({segment_label})...\")\n",
    "        grid_search_xgb.fit(X_train_seg, y_train_seg_transformed)\n",
    "        model_xgb_seg = grid_search_xgb.best_estimator_\n",
    "        print(f\"Best parameters found for XGBoost ({segment_label}): {grid_search_xgb.best_params_}\")\n",
    "        print(f\"Best MAE score during CV ({segment_label}): {-grid_search_xgb.best_score_:.2f}\")\n",
    "        print(f\"Tuned XGBoost Model training complete ({segment_label}).\")\n",
    "        save_path = os.path.join(MODEL_DIR, f'xgb_model_{segment_label.lower().replace(\" \", \"_\")}.pkl')\n",
    "        joblib.dump(model_xgb_seg, save_path)\n",
    "        print(f\"XGBoost model saved for {segment_label} to {save_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during XGBoost GridSearchCV ({segment_label}): {e}\")\n",
    "        traceback.print_exc()\n",
    "        model_xgb_seg = None\n",
    "    evaluate_model(model_xgb_seg, X_test_seg, y_test_seg_original, y_test_seg_original, f\"Tuned XGBoost ({segment_label})\", X_train_cols=X_train_seg.columns)\n",
    "    \n",
    "    # --- LightGBM ---\n",
    "    print(f\"\\n--- Tuning LightGBM Model ({segment_label}) ---\")\n",
    "    param_grid_lgbm = {\n",
    "        'n_estimators': [100, 200], 'max_depth': [3, 5], 'learning_rate': [0.05, 0.1],\n",
    "        'subsample': [0.8, 1.0], 'colsample_bytree': [0.8, 1.0], 'reg_alpha': [0, 0.1], 'reg_lambda': [1.0]\n",
    "    }\n",
    "    if len(X_train_seg) > 500:\n",
    "        param_grid_lgbm['n_estimators'] = [100, 200, 300]\n",
    "        param_grid_lgbm['max_depth'] = [3, 5, 7]\n",
    "        param_grid_lgbm['learning_rate'] = [0.01, 0.05, 0.1]\n",
    "        param_grid_lgbm['subsample'] = [0.7, 0.8, 0.9, 1.0]\n",
    "        param_grid_lgbm['colsample_bytree'] = [0.7, 0.8, 0.9, 1.0]\n",
    "        param_grid_lgbm['reg_alpha'] = [0, 0.1, 0.5]\n",
    "        param_grid_lgbm['reg_lambda'] = [0.5, 1.0, 1.5]\n",
    "    lgbm_estimator = lgb.LGBMRegressor(random_state=42, objective='regression_l2')\n",
    "    grid_search_lgbm = GridSearchCV(estimator=lgbm_estimator, param_grid=param_grid_lgbm, scoring='neg_mean_absolute_error', cv=tscv, n_jobs=-1, verbose=0)\n",
    "    try:\n",
    "        print(f\"Starting LightGBM GridSearchCV ({segment_label})...\")\n",
    "        grid_search_lgbm.fit(X_train_seg, y_train_seg_transformed)\n",
    "        model_lgbm_seg = grid_search_lgbm.best_estimator_\n",
    "        print(f\"Best parameters found for LightGBM ({segment_label}): {grid_search_lgbm.best_params_}\")\n",
    "        print(f\"Best MAE score during CV ({segment_label}): {-grid_search_lgbm.best_score_:.2f}\")\n",
    "        print(f\"Tuned LightGBM Model training complete ({segment_label}).\")\n",
    "        save_path = os.path.join(MODEL_DIR, f'lgbm_model_{segment_label.lower().replace(\" \", \"_\")}.pkl')\n",
    "        joblib.dump(model_lgbm_seg, save_path)\n",
    "        print(f\"LightGBM model saved for {segment_label} to {save_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during LightGBM GridSearchCV ({segment_label}): {e}\")\n",
    "        traceback.print_exc()\n",
    "        model_lgbm_seg = None\n",
    "    evaluate_model(model_lgbm_seg, X_test_seg, y_test_seg_original, y_test_seg_original, f\"Tuned LightGBM ({segment_label})\", X_train_cols=X_train_seg.columns)\n",
    "    \n",
    "    print(f\"\\n{'='*20} Finished Segment: {segment_label} {'='*20}\")\n",
    "    return model_ridge_seg, model_xgb_seg, model_lgbm_seg\n",
    "\n",
    "# Ensure segmented variables are initialized\n",
    "if 'X_train_scorers' not in locals():\n",
    "     X_train_scorers, y_train_scorers, X_test_scorers, y_test_scorers, y_test_scorers_original = [None]*5\n",
    "     X_train_role, y_train_role, X_test_role, y_test_role, y_test_role_original = [None]*5\n",
    "     test_scorer_mask_global = None\n",
    "     test_role_mask_global = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " === BASELINE MODEL (ALL DATA) ===\n",
      "Tuning Ridge Regression Model (Baseline)...\n",
      "Best alpha found for Ridge (Baseline): 0.01\n",
      "Tuned Ridge Regression Model training complete (Baseline).\n",
      "Baseline Ridge model saved to models/2024-25\\ridge_model_baseline.pkl.\n"
     ]
    }
   ],
   "source": [
    "# --- Model Building & Tuning (Ridge Regression - Baseline) ---\n",
    "print(\"\\n === BASELINE MODEL (ALL DATA) ===\")\n",
    "model_ridge_baseline = None\n",
    "if 'X_train' in locals() and X_train is not None and 'y_train' in locals() and y_train is not None and not X_train.empty:\n",
    "    print(\"Tuning Ridge Regression Model (Baseline)...\")\n",
    "    param_grid_ridge = {'alpha': [0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 20.0, 50.0, 100.0]}\n",
    "    ridge_estimator = Ridge()\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    grid_search_ridge = GridSearchCV(ridge_estimator, param_grid_ridge, cv=tscv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "    try:\n",
    "        grid_search_ridge.fit(X_train, y_train)\n",
    "        model_ridge_baseline = grid_search_ridge.best_estimator_\n",
    "        print(f\"Best alpha found for Ridge (Baseline): {grid_search_ridge.best_params_['alpha']}\")\n",
    "        print(\"Tuned Ridge Regression Model training complete (Baseline).\")\n",
    "        save_path = os.path.join(MODEL_DIR, 'ridge_model_baseline.pkl')\n",
    "        joblib.dump(model_ridge_baseline, save_path)\n",
    "        print(f\"Baseline Ridge model saved to {save_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Ridge GridSearchCV (Baseline): {e}\")\n",
    "        traceback.print_exc()\n",
    "        model_ridge_baseline = None\n",
    "else:\n",
    "    print(\"Skipping Ridge tuning due to lack of training data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tuned Ridge (Baseline) Evaluation ---\n",
      "Mean Absolute Error (MAE): 5.01\n",
      "Root Mean Squared Error (RMSE): 6.87\n",
      "Mean Absolute Percentage Error (MAPE): 50.14% (excluding 145 games with 0 actual points)\n",
      "Accuracy (within +/- 3 points): 43.42%\n",
      "\n",
      "Sample Predictions vs Actual (Tuned Ridge (Baseline)):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "1056   20.392953   18.781173   33.005499   31.911444   14.186562   13.632315   \n",
      "5907   21.141338   16.250644   27.370876   21.757188   12.919287   10.250668   \n",
      "866    16.532715   17.091862   32.554688   33.324296   11.227539   12.216747   \n",
      "3613   31.656860   27.842186   35.452789   34.666517   18.266296   16.386177   \n",
      "3035    6.310892    6.759531   14.724441   15.936651    4.650916    5.245164   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "1056    7.878767    6.073409    0.573870    0.568364  ...   \n",
      "5907    1.067596    0.968590    0.616145    0.533709  ...   \n",
      "866     3.194336    3.075880    0.665997    0.642214  ...   \n",
      "3613    2.702911    3.262124    0.802944    0.762387  ...   \n",
      "3035    2.251335    1.885907    0.555339    0.557341  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "1056               0.541082                118.0          100.0        3.0   \n",
      "5907               0.581034                115.1          100.0        2.0   \n",
      "866                0.510048                113.3          100.0        2.0   \n",
      "3613               0.450855                115.3          100.0        2.0   \n",
      "3035               0.350506                111.8          100.0        2.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "1056                    0        1          31      16.313066  14.686934   \n",
      "5907                    0        1          10       8.683757   1.316243   \n",
      "866                     0        0          14      16.264423  -2.264423   \n",
      "3613                    0        0          16      20.261957  -4.261957   \n",
      "3035                    0        0           1       5.096624  -4.096624   \n",
      "\n",
      "      Abs_Error  \n",
      "1056  14.686934  \n",
      "5907   1.316243  \n",
      "866    2.264423  \n",
      "3613   4.261957  \n",
      "3035   4.096624  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Largest Errors (Top 5):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "4828    4.432442    6.015148   17.781279   19.824970    6.396309    7.043066   \n",
      "586     0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "6791   19.898682   16.288275   30.949463   27.728457   12.926514   10.954098   \n",
      "4581   36.000000   36.000000   34.000000   34.000000   27.000000   27.000000   \n",
      "4712    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "4828    0.265810    0.406650    0.311693    0.387556  ...   \n",
      "586     0.000000    0.000000    0.000000    0.000000  ...   \n",
      "6791    1.008301    0.726399    0.745026    0.714792  ...   \n",
      "4581    1.000000    1.000000    0.655977    0.655977  ...   \n",
      "4712    0.000000    0.000000    0.000000    0.000000  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "4828               0.423775                115.3          100.0        3.0   \n",
      "586                0.000000                117.3          100.0        2.0   \n",
      "6791               0.391298                119.4          100.0        3.0   \n",
      "4581               0.865882                109.1          100.0        2.0   \n",
      "4712               0.000000                113.3          100.0        2.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "4828                    0        1          41       5.893511  35.106489   \n",
      "586                     0        0          30       2.849623  27.150377   \n",
      "6791                    0        1          37      10.195973  26.804027   \n",
      "4581                    0        0          24      50.379621 -26.379621   \n",
      "4712                    0        1          28       2.602374  25.397626   \n",
      "\n",
      "      Abs_Error  \n",
      "4828  35.106489  \n",
      "586   27.150377  \n",
      "6791  26.804027  \n",
      "4581  26.379621  \n",
      "4712  25.397626  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- Model Evaluation (Tuned Ridge Regression - Baseline) ---\n",
    "if 'model_ridge_baseline' in locals() and model_ridge_baseline is not None:\n",
    "    evaluate_model(model_ridge_baseline, X_test, y_test, y_test_original, \"Tuned Ridge (Baseline)\") \n",
    "else:\n",
    "    print(\"Skipping Baseline Ridge evaluation as model was not trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tuning XGBoost Model (Baseline) ---\n",
      "Starting XGBoost GridSearchCV (this may take a while)...\n",
      "Fitting 5 folds for each of 3888 candidates, totalling 19440 fits\n",
      "\n",
      "Best parameters found for XGBoost (Baseline): {'colsample_bytree': 0.9, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100, 'reg_alpha': 0.5, 'reg_lambda': 1.0, 'subsample': 0.7}\n",
      "Best MAE score during CV (Baseline): 0.56\n",
      "Tuned XGBoost Model training complete (Baseline).\n",
      "Baseline XGBoost model saved to models/2024-25\\xgb_model_baseline.pkl.\n"
     ]
    }
   ],
   "source": [
    "# --- Model Building & Tuning (XGBoost - Baseline) ---\n",
    "model_xgb_baseline = None\n",
    "if 'X_train' in locals() and X_train is not None and 'y_train' in locals() and y_train is not None and not X_train.empty:\n",
    "    print(\"\\n--- Tuning XGBoost Model (Baseline) ---\")\n",
    "    param_grid_xgb = {\n",
    "        'n_estimators': [100, 200, 300], 'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'subsample': [0.7, 0.8, 0.9, 1.0], 'colsample_bytree': [0.7, 0.8, 0.9, 1.0],\n",
    "        'reg_alpha': [0, 0.1, 0.5], 'reg_lambda': [0.5, 1.0, 1.5]\n",
    "    }\n",
    "    xgb_estimator = XGBRegressor(random_state=42, objective='reg:squarederror', tree_method='hist')\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    grid_search_xgb = GridSearchCV(estimator=xgb_estimator, param_grid=param_grid_xgb, scoring='neg_mean_absolute_error', cv=tscv, n_jobs=-1, verbose=1)\n",
    "    try:\n",
    "        print(\"Starting XGBoost GridSearchCV (this may take a while)...\")\n",
    "        grid_search_xgb.fit(X_train, y_train)\n",
    "        model_xgb_baseline = grid_search_xgb.best_estimator_\n",
    "        print(f\"\\nBest parameters found for XGBoost (Baseline): {grid_search_xgb.best_params_}\")\n",
    "        print(f\"Best MAE score during CV (Baseline): {-grid_search_xgb.best_score_:.2f}\")\n",
    "        print(\"Tuned XGBoost Model training complete (Baseline).\")\n",
    "        save_path = os.path.join(MODEL_DIR, 'xgb_model_baseline.pkl')\n",
    "        joblib.dump(model_xgb_baseline, save_path)\n",
    "        print(f\"Baseline XGBoost model saved to {save_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during XGBoost GridSearchCV (Baseline): {e}\")\n",
    "        traceback.print_exc()\n",
    "        model_xgb_baseline = None\n",
    "else:\n",
    "    print(\"Skipping XGBoost tuning due to lack of training data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tuned XGBoost (Baseline) Evaluation ---\n",
      "Mean Absolute Error (MAE): 4.82\n",
      "Root Mean Squared Error (RMSE): 6.60\n",
      "Mean Absolute Percentage Error (MAPE): 49.69% (excluding 145 games with 0 actual points)\n",
      "Accuracy (within +/- 3 points): 45.68%\n",
      "\n",
      "Sample Predictions vs Actual (Tuned XGBoost (Baseline)):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "1056   20.392953   18.781173   33.005499   31.911444   14.186562   13.632315   \n",
      "5907   21.141338   16.250644   27.370876   21.757188   12.919287   10.250668   \n",
      "866    16.532715   17.091862   32.554688   33.324296   11.227539   12.216747   \n",
      "3613   31.656860   27.842186   35.452789   34.666517   18.266296   16.386177   \n",
      "3035    6.310892    6.759531   14.724441   15.936651    4.650916    5.245164   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "1056    7.878767    6.073409    0.573870    0.568364  ...   \n",
      "5907    1.067596    0.968590    0.616145    0.533709  ...   \n",
      "866     3.194336    3.075880    0.665997    0.642214  ...   \n",
      "3613    2.702911    3.262124    0.802944    0.762387  ...   \n",
      "3035    2.251335    1.885907    0.555339    0.557341  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "1056               0.541082                118.0          100.0        3.0   \n",
      "5907               0.581034                115.1          100.0        2.0   \n",
      "866                0.510048                113.3          100.0        2.0   \n",
      "3613               0.450855                115.3          100.0        2.0   \n",
      "3035               0.350506                111.8          100.0        2.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "1056                    0        1          31      17.441666  13.558334   \n",
      "5907                    0        1          10       9.847054   0.152946   \n",
      "866                     0        0          14      15.081436  -1.081436   \n",
      "3613                    0        0          16      18.201122  -2.201122   \n",
      "3035                    0        0           1       5.351102  -4.351102   \n",
      "\n",
      "      Abs_Error  \n",
      "1056  13.558334  \n",
      "5907   0.152946  \n",
      "866    1.081436  \n",
      "3613   2.201122  \n",
      "3035   4.351102  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Largest Errors (Top 5):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "4828    4.432442    6.015148   17.781279   19.824970    6.396309    7.043066   \n",
      "6791   19.898682   16.288275   30.949463   27.728457   12.926514   10.954098   \n",
      "586     0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "828    19.393205   19.016931   31.519646   31.983537   15.347453   15.783018   \n",
      "2069   43.273193   37.254826   39.376953   38.472177   26.767090   24.276454   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "4828    0.265810    0.406650    0.311693    0.387556  ...   \n",
      "6791    1.008301    0.726399    0.745026    0.714792  ...   \n",
      "586     0.000000    0.000000    0.000000    0.000000  ...   \n",
      "828     3.578246    3.412519    0.550803    0.522486  ...   \n",
      "2069    8.494629    7.446714    0.691803    0.656763  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "4828               0.423775                115.3          100.0        3.0   \n",
      "6791               0.391298                119.4          100.0        3.0   \n",
      "586                0.000000                117.3          100.0        2.0   \n",
      "828                0.637602                119.4          100.0        3.0   \n",
      "2069               0.698436                119.4          100.0        1.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "4828                    0        1          41       6.561778  34.438222   \n",
      "6791                    0        1          37      10.432507  26.567493   \n",
      "586                     0        0          30       3.515144  26.484856   \n",
      "828                     0        1          45      19.542345  25.457655   \n",
      "2069                    1        1          49      24.544628  24.455372   \n",
      "\n",
      "      Abs_Error  \n",
      "4828  34.438222  \n",
      "6791  26.567493  \n",
      "586   26.484856  \n",
      "828   25.457655  \n",
      "2069  24.455372  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Feature Importances (Tuned XGBoost (Baseline)):\n",
      "                    Feature  Importance\n",
      "1                PTS_EWMA_5    0.353715\n",
      "5                FGA_EWMA_5    0.201801\n",
      "12           Avg_PTS_Season    0.122744\n",
      "3                MIN_EWMA_5    0.074648\n",
      "4                FGA_EWMA_3    0.048659\n",
      "2                MIN_EWMA_3    0.039239\n",
      "0                PTS_EWMA_3    0.032402\n",
      "15    Avg_USG%_Proxy_Season    0.018404\n",
      "18                Rest_Days    0.014071\n",
      "13         PTS_Per36_Season    0.012440\n",
      "7                FTA_EWMA_5    0.011693\n",
      "11  Player_USG_Proxy_EWMA_5    0.011321\n",
      "16      Opponent_DEF_RATING    0.010783\n",
      "14           Avg_TS%_Season    0.010092\n",
      "6                FTA_EWMA_3    0.009755\n",
      "10  Player_USG_Proxy_EWMA_3    0.009671\n",
      "9                TS%_EWMA_5    0.009394\n",
      "8                TS%_EWMA_3    0.009170\n",
      "17            Opponent_PACE    0.000000\n",
      "19      Is_B2B_Second_Night    0.000000\n",
      "20                  Is_Home    0.000000\n"
     ]
    }
   ],
   "source": [
    "# --- Model Evaluation (Tuned XGBoost - Baseline) ---\n",
    "train_cols = X_train.columns if X_train is not None else None\n",
    "if 'model_xgb_baseline' in locals() and model_xgb_baseline is not None:\n",
    "    evaluate_model(model_xgb_baseline, X_test, y_test, y_test_original, \"Tuned XGBoost (Baseline)\", X_train_cols=train_cols) \n",
    "else:\n",
    "    print(\"Skipping Baseline XGBoost evaluation as model was not trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tuning LightGBM Model (Baseline) ---\n",
      "Starting LightGBM GridSearchCV (this may take a while)...\n",
      "Fitting 5 folds for each of 3888 candidates, totalling 19440 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4152\n",
      "[LightGBM] [Info] Number of data points in the train set: 5832, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 2.132275\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "Best parameters found for LightGBM (Baseline): {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100, 'reg_alpha': 0, 'reg_lambda': 0.5, 'subsample': 0.7}\n",
      "Best MAE score during CV (Baseline): 0.55\n",
      "Tuned LightGBM Model training complete (Baseline).\n",
      "Baseline LightGBM model saved to models/2024-25\\lgbm_model_baseline.pkl.\n"
     ]
    }
   ],
   "source": [
    "# --- Model Building & Tuning (LightGBM - Baseline) ---\n",
    "model_lgbm_baseline = None\n",
    "if 'X_train' in locals() and X_train is not None and 'y_train' in locals() and y_train is not None and not X_train.empty:\n",
    "    print(\"\\n--- Tuning LightGBM Model (Baseline) ---\")\n",
    "    param_grid_lgbm = {\n",
    "        'n_estimators': [100, 200, 300], 'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'subsample': [0.7, 0.8, 0.9, 1.0], 'colsample_bytree': [0.7, 0.8, 0.9, 1.0],\n",
    "        'reg_alpha': [0, 0.1, 0.5], 'reg_lambda': [0.5, 1.0, 1.5]\n",
    "    }\n",
    "    lgbm_estimator = lgb.LGBMRegressor(random_state=42, objective='regression_l2')\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    grid_search_lgbm = GridSearchCV(estimator=lgbm_estimator, param_grid=param_grid_lgbm, scoring='neg_mean_absolute_error', cv=tscv, n_jobs=-1, verbose=1)\n",
    "    try:\n",
    "        print(\"Starting LightGBM GridSearchCV (this may take a while)...\")\n",
    "        grid_search_lgbm.fit(X_train, y_train)\n",
    "        model_lgbm_baseline = grid_search_lgbm.best_estimator_\n",
    "        print(f\"\\nBest parameters found for LightGBM (Baseline): {grid_search_lgbm.best_params_}\")\n",
    "        print(f\"Best MAE score during CV (Baseline): {-grid_search_lgbm.best_score_:.2f}\")\n",
    "        print(\"Tuned LightGBM Model training complete (Baseline).\")\n",
    "        save_path = os.path.join(MODEL_DIR, 'lgbm_model_baseline.pkl')\n",
    "        joblib.dump(model_lgbm_baseline, save_path)\n",
    "        print(f\"Baseline LightGBM model saved to {save_path}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during LightGBM GridSearchCV (Baseline): {e}\")\n",
    "        traceback.print_exc()\n",
    "        model_lgbm_baseline = None\n",
    "else:\n",
    "    print(\"Skipping LightGBM tuning due to lack of training data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tuned LightGBM (Baseline) Evaluation ---\n",
      "Mean Absolute Error (MAE): 4.82\n",
      "Root Mean Squared Error (RMSE): 6.61\n",
      "Mean Absolute Percentage Error (MAPE): 49.63% (excluding 145 games with 0 actual points)\n",
      "Accuracy (within +/- 3 points): 44.65%\n",
      "\n",
      "Sample Predictions vs Actual (Tuned LightGBM (Baseline)):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "1056   20.392953   18.781173   33.005499   31.911444   14.186562   13.632315   \n",
      "5907   21.141338   16.250644   27.370876   21.757188   12.919287   10.250668   \n",
      "866    16.532715   17.091862   32.554688   33.324296   11.227539   12.216747   \n",
      "3613   31.656860   27.842186   35.452789   34.666517   18.266296   16.386177   \n",
      "3035    6.310892    6.759531   14.724441   15.936651    4.650916    5.245164   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "1056    7.878767    6.073409    0.573870    0.568364  ...   \n",
      "5907    1.067596    0.968590    0.616145    0.533709  ...   \n",
      "866     3.194336    3.075880    0.665997    0.642214  ...   \n",
      "3613    2.702911    3.262124    0.802944    0.762387  ...   \n",
      "3035    2.251335    1.885907    0.555339    0.557341  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "1056               0.541082                118.0          100.0        3.0   \n",
      "5907               0.581034                115.1          100.0        2.0   \n",
      "866                0.510048                113.3          100.0        2.0   \n",
      "3613               0.450855                115.3          100.0        2.0   \n",
      "3035               0.350506                111.8          100.0        2.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "1056                    0        1          31      17.559571  13.440429   \n",
      "5907                    0        1          10      10.394743  -0.394743   \n",
      "866                     0        0          14      14.926221  -0.926221   \n",
      "3613                    0        0          16      18.665853  -2.665853   \n",
      "3035                    0        0           1       5.623613  -4.623613   \n",
      "\n",
      "      Abs_Error  \n",
      "1056  13.440429  \n",
      "5907   0.394743  \n",
      "866    0.926221  \n",
      "3613   2.665853  \n",
      "3035   4.623613  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Largest Errors (Top 5):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "4828    4.432442    6.015148   17.781279   19.824970    6.396309    7.043066   \n",
      "586     0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "6791   19.898682   16.288275   30.949463   27.728457   12.926514   10.954098   \n",
      "828    19.393205   19.016931   31.519646   31.983537   15.347453   15.783018   \n",
      "1370   26.206632   27.629702   36.227091   37.018860   13.914841   15.859939   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "4828    0.265810    0.406650    0.311693    0.387556  ...   \n",
      "586     0.000000    0.000000    0.000000    0.000000  ...   \n",
      "6791    1.008301    0.726399    0.745026    0.714792  ...   \n",
      "828     3.578246    3.412519    0.550803    0.522486  ...   \n",
      "1370   13.237138   11.505245    0.653682    0.652443  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "4828               0.423775                115.3          100.0        3.0   \n",
      "586                0.000000                117.3          100.0        2.0   \n",
      "6791               0.391298                119.4          100.0        3.0   \n",
      "828                0.637602                119.4          100.0        3.0   \n",
      "1370               0.665928                119.4          100.0        2.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "4828                    0        1          41       6.167266  34.832734   \n",
      "586                     0        0          30       3.836669  26.163331   \n",
      "6791                    0        1          37      10.849775  26.150225   \n",
      "828                     0        1          45      19.034577  25.965423   \n",
      "1370                    0        1          47      22.011863  24.988137   \n",
      "\n",
      "      Abs_Error  \n",
      "4828  34.832734  \n",
      "586   26.163331  \n",
      "6791  26.150225  \n",
      "828   25.965423  \n",
      "1370  24.988137  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Feature Importances (Tuned LightGBM (Baseline)):\n",
      "                    Feature  Importance\n",
      "12           Avg_PTS_Season          96\n",
      "2                MIN_EWMA_3          83\n",
      "5                FGA_EWMA_5          66\n",
      "16      Opponent_DEF_RATING          61\n",
      "3                MIN_EWMA_5          42\n",
      "1                PTS_EWMA_5          37\n",
      "18                Rest_Days          37\n",
      "13         PTS_Per36_Season          32\n",
      "14           Avg_TS%_Season          32\n",
      "6                FTA_EWMA_3          28\n",
      "7                FTA_EWMA_5          27\n",
      "4                FGA_EWMA_3          26\n",
      "15    Avg_USG%_Proxy_Season          24\n",
      "11  Player_USG_Proxy_EWMA_5          22\n",
      "10  Player_USG_Proxy_EWMA_3          14\n",
      "8                TS%_EWMA_3          10\n",
      "9                TS%_EWMA_5           8\n",
      "0                PTS_EWMA_3           7\n",
      "20                  Is_Home           3\n",
      "17            Opponent_PACE           0\n",
      "19      Is_B2B_Second_Night           0\n"
     ]
    }
   ],
   "source": [
    "# --- Model Evaluation (Tuned LightGBM - Baseline) ---\n",
    "train_cols = X_train.columns if X_train is not None else None\n",
    "if 'model_lgbm_baseline' in locals() and model_lgbm_baseline is not None:\n",
    "    evaluate_model(model_lgbm_baseline, X_test, y_test, y_test_original, \"Tuned LightGBM (Baseline)\", X_train_cols=train_cols) \n",
    "else:\n",
    "    print(\"Skipping Baseline LightGBM evaluation as model was not trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Processing Segment: Scorers ====================\n",
      "\n",
      "--- Tuning Ridge Regression Model (Scorers) ---\n",
      "Best alpha found for Ridge (Scorers): 0.1\n",
      "Tuned Ridge Regression Model training complete (Scorers).\n",
      "Ridge model saved for Scorers to models/2024-25\\ridge_model_scorers.pkl.\n",
      "\n",
      "--- Tuned Ridge (Scorers) Evaluation ---\n",
      "Mean Absolute Error (MAE): 6.52\n",
      "Root Mean Squared Error (RMSE): 8.29\n",
      "Mean Absolute Percentage Error (MAPE): 42.43% (excluding 1 games with 0 actual points)\n",
      "Accuracy (within +/- 3 points): 31.55%\n",
      "\n",
      "Sample Predictions vs Actual (Tuned Ridge (Scorers)):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "1056   20.392953   18.781173   33.005499   31.911444   14.186562   13.632315   \n",
      "866    16.532715   17.091862   32.554688   33.324296   11.227539   12.216747   \n",
      "3613   31.656860   27.842186   35.452789   34.666517   18.266296   16.386177   \n",
      "4727   21.397888   22.051085   34.510620   35.595225   19.166687   19.985165   \n",
      "2168   26.069102   26.226446   32.327177   31.900167   18.334556   18.841405   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "1056    7.878767    6.073409    0.573870    0.568364  ...   \n",
      "866     3.194336    3.075880    0.665997    0.642214  ...   \n",
      "3613    2.702911    3.262124    0.802944    0.762387  ...   \n",
      "4727    4.248718    4.284337    0.521979    0.515558  ...   \n",
      "2168    3.538723    3.756982    0.674922    0.655303  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "1056               0.541082                118.0          100.0        3.0   \n",
      "866                0.510048                113.3          100.0        2.0   \n",
      "3613               0.450855                115.3          100.0        2.0   \n",
      "4727               0.722344                114.8          100.0        1.0   \n",
      "2168               0.717238                113.6          100.0        2.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "1056                    0        1          31      16.246344  14.753656   \n",
      "866                     0        0          14      16.262629  -2.262629   \n",
      "3613                    0        0          16      17.951059  -1.951059   \n",
      "4727                    1        1          26      22.722465   3.277535   \n",
      "2168                    0        0          21      21.959479  -0.959479   \n",
      "\n",
      "      Abs_Error  \n",
      "1056  14.753656  \n",
      "866    2.262629  \n",
      "3613   1.951059  \n",
      "4727   3.277535  \n",
      "2168   0.959479  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Largest Errors (Top 5):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "828    19.393205   19.016931   31.519646   31.983537   15.347453   15.783018   \n",
      "5022   20.394531   19.497333   34.429688   33.077884   12.988281   12.200884   \n",
      "838    20.203509   21.287767   31.573750   31.971111   17.578464   17.862365   \n",
      "2069   43.273193   37.254826   39.376953   38.472177   26.767090   24.276454   \n",
      "4666   13.611002   15.165783   27.560543   29.128114   11.855784   12.651996   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "828     3.578246    3.412519    0.550803    0.522486  ...   \n",
      "5022    7.128906    7.015851    0.647349    0.666081  ...   \n",
      "838     2.442948    2.966391    0.528521    0.543323  ...   \n",
      "2069    8.494629    7.446714    0.691803    0.656763  ...   \n",
      "4666    2.328911    3.030436    0.520054    0.535067  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "828                0.637602                119.4          100.0        3.0   \n",
      "5022               0.508333                113.3          100.0        2.0   \n",
      "838                0.648240                115.3          100.0        1.0   \n",
      "2069               0.698436                119.4          100.0        1.0   \n",
      "4666               0.624440                110.8          100.0        1.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "828                     0        1          45      19.067998  25.932002   \n",
      "5022                    0        1          38      14.916424  23.083576   \n",
      "838                     1        1          43      20.097217  22.902783   \n",
      "2069                    1        1          49      26.166605  22.833395   \n",
      "4666                    1        1          38      15.647339  22.352661   \n",
      "\n",
      "      Abs_Error  \n",
      "828   25.932002  \n",
      "5022  23.083576  \n",
      "838   22.902783  \n",
      "2069  22.833395  \n",
      "4666  22.352661  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "--- Tuning XGBoost Model (Scorers) ---\n",
      "Starting XGBoost GridSearchCV (Scorers)...\n",
      "Best parameters found for XGBoost (Scorers): {'colsample_bytree': 0.7, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'reg_alpha': 0, 'reg_lambda': 1.5, 'subsample': 0.7}\n",
      "Best MAE score during CV (Scorers): 0.33\n",
      "Tuned XGBoost Model training complete (Scorers).\n",
      "XGBoost model saved for Scorers to models/2024-25\\xgb_model_scorers.pkl.\n",
      "\n",
      "--- Tuned XGBoost (Scorers) Evaluation ---\n",
      "Mean Absolute Error (MAE): 6.45\n",
      "Root Mean Squared Error (RMSE): 8.30\n",
      "Mean Absolute Percentage Error (MAPE): 42.66% (excluding 1 games with 0 actual points)\n",
      "Accuracy (within +/- 3 points): 33.33%\n",
      "\n",
      "Sample Predictions vs Actual (Tuned XGBoost (Scorers)):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "1056   20.392953   18.781173   33.005499   31.911444   14.186562   13.632315   \n",
      "866    16.532715   17.091862   32.554688   33.324296   11.227539   12.216747   \n",
      "3613   31.656860   27.842186   35.452789   34.666517   18.266296   16.386177   \n",
      "4727   21.397888   22.051085   34.510620   35.595225   19.166687   19.985165   \n",
      "2168   26.069102   26.226446   32.327177   31.900167   18.334556   18.841405   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "1056    7.878767    6.073409    0.573870    0.568364  ...   \n",
      "866     3.194336    3.075880    0.665997    0.642214  ...   \n",
      "3613    2.702911    3.262124    0.802944    0.762387  ...   \n",
      "4727    4.248718    4.284337    0.521979    0.515558  ...   \n",
      "2168    3.538723    3.756982    0.674922    0.655303  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "1056               0.541082                118.0          100.0        3.0   \n",
      "866                0.510048                113.3          100.0        2.0   \n",
      "3613               0.450855                115.3          100.0        2.0   \n",
      "4727               0.722344                114.8          100.0        1.0   \n",
      "2168               0.717238                113.6          100.0        2.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "1056                    0        1          31      17.799795  13.200205   \n",
      "866                     0        0          14      16.326370  -2.326370   \n",
      "3613                    0        0          16      17.523655  -1.523655   \n",
      "4727                    1        1          26      22.272921   3.727079   \n",
      "2168                    0        0          21      22.975071  -1.975071   \n",
      "\n",
      "      Abs_Error  \n",
      "1056  13.200205  \n",
      "866    2.326370  \n",
      "3613   1.523655  \n",
      "4727   3.727079  \n",
      "2168   1.975071  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Largest Errors (Top 5):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "2069   43.273193   37.254826   39.376953   38.472177   26.767090   24.276454   \n",
      "828    19.393205   19.016931   31.519646   31.983537   15.347453   15.783018   \n",
      "1370   26.206632   27.629702   36.227091   37.018860   13.914841   15.859939   \n",
      "838    20.203509   21.287767   31.573750   31.971111   17.578464   17.862365   \n",
      "4666   13.611002   15.165783   27.560543   29.128114   11.855784   12.651996   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "2069    8.494629    7.446714    0.691803    0.656763  ...   \n",
      "828     3.578246    3.412519    0.550803    0.522486  ...   \n",
      "1370   13.237138   11.505245    0.653682    0.652443  ...   \n",
      "838     2.442948    2.966391    0.528521    0.543323  ...   \n",
      "4666    2.328911    3.030436    0.520054    0.535067  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "2069               0.698436                119.4          100.0        1.0   \n",
      "828                0.637602                119.4          100.0        3.0   \n",
      "1370               0.665928                119.4          100.0        2.0   \n",
      "838                0.648240                115.3          100.0        1.0   \n",
      "4666               0.624440                110.8          100.0        1.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "2069                    1        1          49      23.264055  25.735945   \n",
      "828                     0        1          45      19.420267  25.579733   \n",
      "1370                    0        1          47      21.746334  25.253666   \n",
      "838                     1        1          43      19.658064  23.341936   \n",
      "4666                    1        1          38      16.283926  21.716074   \n",
      "\n",
      "      Abs_Error  \n",
      "2069  25.735945  \n",
      "828   25.579733  \n",
      "1370  25.253666  \n",
      "838   23.341936  \n",
      "4666  21.716074  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Feature Importances (Tuned XGBoost (Scorers)):\n",
      "                    Feature  Importance\n",
      "5                FGA_EWMA_5    0.123735\n",
      "12           Avg_PTS_Season    0.088891\n",
      "1                PTS_EWMA_5    0.066975\n",
      "4                FGA_EWMA_3    0.066348\n",
      "3                MIN_EWMA_5    0.058104\n",
      "2                MIN_EWMA_3    0.051645\n",
      "0                PTS_EWMA_3    0.050749\n",
      "7                FTA_EWMA_5    0.046532\n",
      "11  Player_USG_Proxy_EWMA_5    0.044592\n",
      "13         PTS_Per36_Season    0.043393\n",
      "15    Avg_USG%_Proxy_Season    0.042761\n",
      "6                FTA_EWMA_3    0.041853\n",
      "14           Avg_TS%_Season    0.040769\n",
      "10  Player_USG_Proxy_EWMA_3    0.040444\n",
      "19      Is_B2B_Second_Night    0.038977\n",
      "18                Rest_Days    0.034035\n",
      "20                  Is_Home    0.033642\n",
      "16      Opponent_DEF_RATING    0.031248\n",
      "8                TS%_EWMA_3    0.028249\n",
      "9                TS%_EWMA_5    0.027059\n",
      "17            Opponent_PACE    0.000000\n",
      "\n",
      "--- Tuning LightGBM Model (Scorers) ---\n",
      "Starting LightGBM GridSearchCV (Scorers)...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000287 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4130\n",
      "[LightGBM] [Info] Number of data points in the train set: 1479, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 2.956088\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters found for LightGBM (Scorers): {'colsample_bytree': 0.7, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'reg_alpha': 0.5, 'reg_lambda': 1.5, 'subsample': 0.7}\n",
      "Best MAE score during CV (Scorers): 0.33\n",
      "Tuned LightGBM Model training complete (Scorers).\n",
      "LightGBM model saved for Scorers to models/2024-25\\lgbm_model_scorers.pkl.\n",
      "\n",
      "--- Tuned LightGBM (Scorers) Evaluation ---\n",
      "Mean Absolute Error (MAE): 6.46\n",
      "Root Mean Squared Error (RMSE): 8.29\n",
      "Mean Absolute Percentage Error (MAPE): 42.81% (excluding 1 games with 0 actual points)\n",
      "Accuracy (within +/- 3 points): 34.10%\n",
      "\n",
      "Sample Predictions vs Actual (Tuned LightGBM (Scorers)):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "1056   20.392953   18.781173   33.005499   31.911444   14.186562   13.632315   \n",
      "866    16.532715   17.091862   32.554688   33.324296   11.227539   12.216747   \n",
      "3613   31.656860   27.842186   35.452789   34.666517   18.266296   16.386177   \n",
      "4727   21.397888   22.051085   34.510620   35.595225   19.166687   19.985165   \n",
      "2168   26.069102   26.226446   32.327177   31.900167   18.334556   18.841405   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "1056    7.878767    6.073409    0.573870    0.568364  ...   \n",
      "866     3.194336    3.075880    0.665997    0.642214  ...   \n",
      "3613    2.702911    3.262124    0.802944    0.762387  ...   \n",
      "4727    4.248718    4.284337    0.521979    0.515558  ...   \n",
      "2168    3.538723    3.756982    0.674922    0.655303  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "1056               0.541082                118.0          100.0        3.0   \n",
      "866                0.510048                113.3          100.0        2.0   \n",
      "3613               0.450855                115.3          100.0        2.0   \n",
      "4727               0.722344                114.8          100.0        1.0   \n",
      "2168               0.717238                113.6          100.0        2.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "1056                    0        1          31      17.913123  13.086877   \n",
      "866                     0        0          14      16.152628  -2.152628   \n",
      "3613                    0        0          16      17.200065  -1.200065   \n",
      "4727                    1        1          26      22.483400   3.516600   \n",
      "2168                    0        0          21      22.796899  -1.796899   \n",
      "\n",
      "      Abs_Error  \n",
      "1056  13.086877  \n",
      "866    2.152628  \n",
      "3613   1.200065  \n",
      "4727   3.516600  \n",
      "2168   1.796899  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Largest Errors (Top 5):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "2069   43.273193   37.254826   39.376953   38.472177   26.767090   24.276454   \n",
      "828    19.393205   19.016931   31.519646   31.983537   15.347453   15.783018   \n",
      "1370   26.206632   27.629702   36.227091   37.018860   13.914841   15.859939   \n",
      "838    20.203509   21.287767   31.573750   31.971111   17.578464   17.862365   \n",
      "4666   13.611002   15.165783   27.560543   29.128114   11.855784   12.651996   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "2069    8.494629    7.446714    0.691803    0.656763  ...   \n",
      "828     3.578246    3.412519    0.550803    0.522486  ...   \n",
      "1370   13.237138   11.505245    0.653682    0.652443  ...   \n",
      "838     2.442948    2.966391    0.528521    0.543323  ...   \n",
      "4666    2.328911    3.030436    0.520054    0.535067  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "2069               0.698436                119.4          100.0        1.0   \n",
      "828                0.637602                119.4          100.0        3.0   \n",
      "1370               0.665928                119.4          100.0        2.0   \n",
      "838                0.648240                115.3          100.0        1.0   \n",
      "4666               0.624440                110.8          100.0        1.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "2069                    1        1          49      22.910547  26.089453   \n",
      "828                     0        1          45      19.134595  25.865405   \n",
      "1370                    0        1          47      22.011695  24.988305   \n",
      "838                     1        1          43      19.647500  23.352500   \n",
      "4666                    1        1          38      16.119575  21.880425   \n",
      "\n",
      "      Abs_Error  \n",
      "2069  26.089453  \n",
      "828   25.865405  \n",
      "1370  24.988305  \n",
      "838   23.352500  \n",
      "4666  21.880425  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Feature Importances (Tuned LightGBM (Scorers)):\n",
      "                    Feature  Importance\n",
      "5                FGA_EWMA_5         190\n",
      "3                MIN_EWMA_5         135\n",
      "12           Avg_PTS_Season         133\n",
      "2                MIN_EWMA_3         116\n",
      "14           Avg_TS%_Season         112\n",
      "7                FTA_EWMA_5          92\n",
      "11  Player_USG_Proxy_EWMA_5          87\n",
      "13         PTS_Per36_Season          80\n",
      "6                FTA_EWMA_3          70\n",
      "16      Opponent_DEF_RATING          60\n",
      "15    Avg_USG%_Proxy_Season          57\n",
      "1                PTS_EWMA_5          42\n",
      "10  Player_USG_Proxy_EWMA_3          35\n",
      "18                Rest_Days          30\n",
      "4                FGA_EWMA_3          30\n",
      "8                TS%_EWMA_3          27\n",
      "9                TS%_EWMA_5          14\n",
      "0                PTS_EWMA_3          13\n",
      "19      Is_B2B_Second_Night           4\n",
      "17            Opponent_PACE           0\n",
      "20                  Is_Home           0\n",
      "\n",
      "==================== Finished Segment: Scorers ====================\n",
      "\n",
      "==================== Processing Segment: Role Players ====================\n",
      "\n",
      "--- Tuning Ridge Regression Model (Role Players) ---\n",
      "Best alpha found for Ridge (Role Players): 0.1\n",
      "Tuned Ridge Regression Model training complete (Role Players).\n",
      "Ridge model saved for Role Players to models/2024-25\\ridge_model_role_players.pkl.\n",
      "\n",
      "--- Tuned Ridge (Role Players) Evaluation ---\n",
      "Mean Absolute Error (MAE): 4.29\n",
      "Root Mean Squared Error (RMSE): 5.92\n",
      "Mean Absolute Percentage Error (MAPE): 52.57% (excluding 144 games with 0 actual points)\n",
      "Accuracy (within +/- 3 points): 49.11%\n",
      "\n",
      "Sample Predictions vs Actual (Tuned Ridge (Role Players)):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "5907   21.141338   16.250644   27.370876   21.757188   12.919287   10.250668   \n",
      "3035    6.310892    6.759531   14.724441   15.936651    4.650916    5.245164   \n",
      "1882    6.012224    7.735643   28.266903   28.511599    7.170502    7.236121   \n",
      "3805    8.891357    8.928914   19.871582   20.801067    6.587646    6.959341   \n",
      "457     1.570195    2.245487   11.998581   11.952509    2.846083    3.037930   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "5907    1.067596    0.968590    0.616145    0.533709  ...   \n",
      "3035    2.251335    1.885907    0.555339    0.557341  ...   \n",
      "1882    0.824364    0.908157    0.388412    0.491060  ...   \n",
      "3805    3.954102    3.778346    0.489757    0.472690  ...   \n",
      "457     0.250000    0.296296    0.207870    0.287062  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "5907               0.581034                115.1          100.0        2.0   \n",
      "3035               0.350506                111.8          100.0        2.0   \n",
      "1882               0.323938                111.8          100.0        4.0   \n",
      "3805               0.478634                114.8          100.0        4.0   \n",
      "457                0.338065                110.1          100.0        2.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS     Error  \\\n",
      "5907                    0        1          10      10.289571 -0.289571   \n",
      "3035                    0        0           1       5.661729 -4.661729   \n",
      "1882                    0        1           2       7.971565 -5.971565   \n",
      "3805                    0        1          12       7.074173  4.925827   \n",
      "457                     0        0           0       2.460064 -2.460064   \n",
      "\n",
      "      Abs_Error  \n",
      "5907   0.289571  \n",
      "3035   4.661729  \n",
      "1882   5.971565  \n",
      "3805   4.925827  \n",
      "457    2.460064  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Largest Errors (Top 5):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "4828    4.432442    6.015148   17.781279   19.824970    6.396309    7.043066   \n",
      "586     0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "6791   19.898682   16.288275   30.949463   27.728457   12.926514   10.954098   \n",
      "4712    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "1210    9.429871   10.394076   21.570527   24.224832    8.492533    9.076483   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "4828    0.265810    0.406650    0.311693    0.387556  ...   \n",
      "586     0.000000    0.000000    0.000000    0.000000  ...   \n",
      "6791    1.008301    0.726399    0.745026    0.714792  ...   \n",
      "4712    0.000000    0.000000    0.000000    0.000000  ...   \n",
      "1210    1.269739    1.278305    0.542253    0.565315  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "4828               0.423775                115.3          100.0        3.0   \n",
      "586                0.000000                117.3          100.0        2.0   \n",
      "6791               0.391298                119.4          100.0        3.0   \n",
      "4712               0.000000                113.3          100.0        2.0   \n",
      "1210               0.460682                112.0          100.0        1.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "4828                    0        1          41       5.826147  35.173853   \n",
      "586                     0        0          30       3.070955  26.929045   \n",
      "6791                    0        1          37      10.890314  26.109686   \n",
      "4712                    0        1          28       2.822363  25.177637   \n",
      "1210                    1        0          30       7.067446  22.932554   \n",
      "\n",
      "      Abs_Error  \n",
      "4828  35.173853  \n",
      "586   26.929045  \n",
      "6791  26.109686  \n",
      "4712  25.177637  \n",
      "1210  22.932554  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "--- Tuning XGBoost Model (Role Players) ---\n",
      "Starting XGBoost GridSearchCV (Role Players)...\n",
      "Best parameters found for XGBoost (Role Players): {'colsample_bytree': 1.0, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 0.7}\n",
      "Best MAE score during CV (Role Players): 0.63\n",
      "Tuned XGBoost Model training complete (Role Players).\n",
      "XGBoost model saved for Role Players to models/2024-25\\xgb_model_role_players.pkl.\n",
      "\n",
      "--- Tuned XGBoost (Role Players) Evaluation ---\n",
      "Mean Absolute Error (MAE): 4.24\n",
      "Root Mean Squared Error (RMSE): 5.87\n",
      "Mean Absolute Percentage Error (MAPE): 52.80% (excluding 144 games with 0 actual points)\n",
      "Accuracy (within +/- 3 points): 48.83%\n",
      "\n",
      "Sample Predictions vs Actual (Tuned XGBoost (Role Players)):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "5907   21.141338   16.250644   27.370876   21.757188   12.919287   10.250668   \n",
      "3035    6.310892    6.759531   14.724441   15.936651    4.650916    5.245164   \n",
      "1882    6.012224    7.735643   28.266903   28.511599    7.170502    7.236121   \n",
      "3805    8.891357    8.928914   19.871582   20.801067    6.587646    6.959341   \n",
      "457     1.570195    2.245487   11.998581   11.952509    2.846083    3.037930   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "5907    1.067596    0.968590    0.616145    0.533709  ...   \n",
      "3035    2.251335    1.885907    0.555339    0.557341  ...   \n",
      "1882    0.824364    0.908157    0.388412    0.491060  ...   \n",
      "3805    3.954102    3.778346    0.489757    0.472690  ...   \n",
      "457     0.250000    0.296296    0.207870    0.287062  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "5907               0.581034                115.1          100.0        2.0   \n",
      "3035               0.350506                111.8          100.0        2.0   \n",
      "1882               0.323938                111.8          100.0        4.0   \n",
      "3805               0.478634                114.8          100.0        4.0   \n",
      "457                0.338065                110.1          100.0        2.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS     Error  \\\n",
      "5907                    0        1          10       9.498542  0.501458   \n",
      "3035                    0        0           1       5.141547 -4.141547   \n",
      "1882                    0        1           2       7.390049 -5.390049   \n",
      "3805                    0        1          12       7.455377  4.544623   \n",
      "457                     0        0           0       1.820848 -1.820848   \n",
      "\n",
      "      Abs_Error  \n",
      "5907   0.501458  \n",
      "3035   4.141547  \n",
      "1882   5.390049  \n",
      "3805   4.544623  \n",
      "457    1.820848  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Largest Errors (Top 5):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "4828    4.432442    6.015148   17.781279   19.824970    6.396309    7.043066   \n",
      "586     0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "6791   19.898682   16.288275   30.949463   27.728457   12.926514   10.954098   \n",
      "4712    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "7252    4.773600    3.707688   13.651308   10.393761    5.414332    4.146801   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "4828    0.265810    0.406650    0.311693    0.387556  ...   \n",
      "586     0.000000    0.000000    0.000000    0.000000  ...   \n",
      "6791    1.008301    0.726399    0.745026    0.714792  ...   \n",
      "4712    0.000000    0.000000    0.000000    0.000000  ...   \n",
      "7252    0.580078    0.592501    0.319571    0.345721  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "4828               0.423775                115.3          100.0        3.0   \n",
      "586                0.000000                117.3          100.0        2.0   \n",
      "6791               0.391298                119.4          100.0        3.0   \n",
      "4712               0.000000                113.3          100.0        2.0   \n",
      "7252               0.428654                119.1          100.0        2.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "4828                    0        1          41       6.393525  34.606475   \n",
      "586                     0        0          30       3.307038  26.692962   \n",
      "6791                    0        1          37      10.692539  26.307461   \n",
      "4712                    0        1          28       3.941579  24.058421   \n",
      "7252                    0        0          26       3.532056  22.467944   \n",
      "\n",
      "      Abs_Error  \n",
      "4828  34.606475  \n",
      "586   26.692962  \n",
      "6791  26.307461  \n",
      "4712  24.058421  \n",
      "7252  22.467944  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Feature Importances (Tuned XGBoost (Role Players)):\n",
      "                    Feature  Importance\n",
      "5                FGA_EWMA_5    0.330383\n",
      "12           Avg_PTS_Season    0.117591\n",
      "2                MIN_EWMA_3    0.111546\n",
      "1                PTS_EWMA_5    0.094208\n",
      "4                FGA_EWMA_3    0.047391\n",
      "3                MIN_EWMA_5    0.031405\n",
      "18                Rest_Days    0.027294\n",
      "0                PTS_EWMA_3    0.025802\n",
      "15    Avg_USG%_Proxy_Season    0.023954\n",
      "13         PTS_Per36_Season    0.022416\n",
      "16      Opponent_DEF_RATING    0.022027\n",
      "7                FTA_EWMA_5    0.021716\n",
      "11  Player_USG_Proxy_EWMA_5    0.021236\n",
      "10  Player_USG_Proxy_EWMA_3    0.020873\n",
      "6                FTA_EWMA_3    0.018750\n",
      "14           Avg_TS%_Season    0.018613\n",
      "8                TS%_EWMA_3    0.018178\n",
      "9                TS%_EWMA_5    0.015878\n",
      "20                  Is_Home    0.010739\n",
      "17            Opponent_PACE    0.000000\n",
      "19      Is_B2B_Second_Night    0.000000\n",
      "\n",
      "--- Tuning LightGBM Model (Role Players) ---\n",
      "Starting LightGBM GridSearchCV (Role Players)...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4150\n",
      "[LightGBM] [Info] Number of data points in the train set: 4353, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 1.852372\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters found for LightGBM (Role Players): {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'subsample': 0.7}\n",
      "Best MAE score during CV (Role Players): 0.63\n",
      "Tuned LightGBM Model training complete (Role Players).\n",
      "LightGBM model saved for Role Players to models/2024-25\\lgbm_model_role_players.pkl.\n",
      "\n",
      "--- Tuned LightGBM (Role Players) Evaluation ---\n",
      "Mean Absolute Error (MAE): 4.23\n",
      "Root Mean Squared Error (RMSE): 5.86\n",
      "Mean Absolute Percentage Error (MAPE): 52.66% (excluding 144 games with 0 actual points)\n",
      "Accuracy (within +/- 3 points): 48.83%\n",
      "\n",
      "Sample Predictions vs Actual (Tuned LightGBM (Role Players)):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "5907   21.141338   16.250644   27.370876   21.757188   12.919287   10.250668   \n",
      "3035    6.310892    6.759531   14.724441   15.936651    4.650916    5.245164   \n",
      "1882    6.012224    7.735643   28.266903   28.511599    7.170502    7.236121   \n",
      "3805    8.891357    8.928914   19.871582   20.801067    6.587646    6.959341   \n",
      "457     1.570195    2.245487   11.998581   11.952509    2.846083    3.037930   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "5907    1.067596    0.968590    0.616145    0.533709  ...   \n",
      "3035    2.251335    1.885907    0.555339    0.557341  ...   \n",
      "1882    0.824364    0.908157    0.388412    0.491060  ...   \n",
      "3805    3.954102    3.778346    0.489757    0.472690  ...   \n",
      "457     0.250000    0.296296    0.207870    0.287062  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "5907               0.581034                115.1          100.0        2.0   \n",
      "3035               0.350506                111.8          100.0        2.0   \n",
      "1882               0.323938                111.8          100.0        4.0   \n",
      "3805               0.478634                114.8          100.0        4.0   \n",
      "457                0.338065                110.1          100.0        2.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS     Error  \\\n",
      "5907                    0        1          10       9.742810  0.257190   \n",
      "3035                    0        0           1       5.669692 -4.669692   \n",
      "1882                    0        1           2       7.138741 -5.138741   \n",
      "3805                    0        1          12       7.293324  4.706676   \n",
      "457                     0        0           0       1.863519 -1.863519   \n",
      "\n",
      "      Abs_Error  \n",
      "5907   0.257190  \n",
      "3035   4.669692  \n",
      "1882   5.138741  \n",
      "3805   4.706676  \n",
      "457    1.863519  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Largest Errors (Top 5):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "4828    4.432442    6.015148   17.781279   19.824970    6.396309    7.043066   \n",
      "6791   19.898682   16.288275   30.949463   27.728457   12.926514   10.954098   \n",
      "586     0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "4712    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "7252    4.773600    3.707688   13.651308   10.393761    5.414332    4.146801   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "4828    0.265810    0.406650    0.311693    0.387556  ...   \n",
      "6791    1.008301    0.726399    0.745026    0.714792  ...   \n",
      "586     0.000000    0.000000    0.000000    0.000000  ...   \n",
      "4712    0.000000    0.000000    0.000000    0.000000  ...   \n",
      "7252    0.580078    0.592501    0.319571    0.345721  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "4828               0.423775                115.3          100.0        3.0   \n",
      "6791               0.391298                119.4          100.0        3.0   \n",
      "586                0.000000                117.3          100.0        2.0   \n",
      "4712               0.000000                113.3          100.0        2.0   \n",
      "7252               0.428654                119.1          100.0        2.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "4828                    0        1          41       5.925729  35.074271   \n",
      "6791                    0        1          37      10.791384  26.208616   \n",
      "586                     0        0          30       3.889469  26.110531   \n",
      "4712                    0        1          28       3.994221  24.005779   \n",
      "7252                    0        0          26       3.393984  22.606016   \n",
      "\n",
      "      Abs_Error  \n",
      "4828  35.074271  \n",
      "6791  26.208616  \n",
      "586   26.110531  \n",
      "4712  24.005779  \n",
      "7252  22.606016  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Feature Importances (Tuned LightGBM (Role Players)):\n",
      "                    Feature  Importance\n",
      "2                MIN_EWMA_3         104\n",
      "12           Avg_PTS_Season          87\n",
      "16      Opponent_DEF_RATING          63\n",
      "5                FGA_EWMA_5          52\n",
      "7                FTA_EWMA_5          38\n",
      "18                Rest_Days          37\n",
      "1                PTS_EWMA_5          35\n",
      "3                MIN_EWMA_5          32\n",
      "15    Avg_USG%_Proxy_Season          30\n",
      "10  Player_USG_Proxy_EWMA_3          28\n",
      "4                FGA_EWMA_3          27\n",
      "13         PTS_Per36_Season          26\n",
      "6                FTA_EWMA_3          26\n",
      "11  Player_USG_Proxy_EWMA_5          25\n",
      "14           Avg_TS%_Season          25\n",
      "8                TS%_EWMA_3          13\n",
      "0                PTS_EWMA_3           7\n",
      "9                TS%_EWMA_5           6\n",
      "19      Is_B2B_Second_Night           3\n",
      "17            Opponent_PACE           0\n",
      "20                  Is_Home           0\n",
      "\n",
      "==================== Finished Segment: Role Players ====================\n"
     ]
    }
   ],
   "source": [
    "# --- Train and Evaluate Segmented Models ---\n",
    "\n",
    "if 'X_train_scorers' in locals() and X_train_scorers is not None and not X_train_scorers.empty and \\\n",
    "   'X_train_role' in locals() and X_train_role is not None and not X_train_role.empty:\n",
    "    \n",
    "    # Train/Evaluate Scorers Segment\n",
    "    model_ridge_scorers, model_xgb_scorers, model_lgbm_scorers = train_evaluate_segment(\n",
    "        X_train_scorers, y_train_scorers, X_test_scorers, y_test_scorers_original, \"Scorers\"\n",
    "    )\n",
    "    \n",
    "    # Train/Evaluate Role Players Segment\n",
    "    model_ridge_role, model_xgb_role, model_lgbm_role = train_evaluate_segment(\n",
    "        X_train_role, y_train_role, X_test_role, y_test_role_original, \"Role Players\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(\"Skipping segmented model training as segmentation did not run successfully or segments are empty.\")\n",
    "    model_ridge_scorers, model_xgb_scorers, model_lgbm_scorers = [None]*3\n",
    "    model_ridge_role, model_xgb_role, model_lgbm_role = [None]*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Combined HYBRID Model (2024-25) ---\n",
      "--- (Role Player Ridge + Baseline XGBoost) ---\n",
      "Loading required models...\n",
      "Required models loaded successfully.\n",
      "Generating combined HYBRID predictions...\n",
      "Test Set Segmentation (using masks): Scorers = 393, Role Players = 1065\n",
      "Combined transformed HYBRID predictions generated.\n",
      "Combined HYBRID predictions transformed back to original scale.\n",
      "Calculating combined HYBRID metrics...\n",
      "\n",
      "--- METRICS COMPARISON (2024-25) ---\n",
      "\n",
      "Combined HYBRID Model (Role Ridge + Baseline XGB):\n",
      "  Mean Absolute Error (MAE): 4.86\n",
      "  Root Mean Squared Error (RMSE): 6.65\n",
      "  Mean Absolute Percentage Error (MAPE): 49.31% (excluding 145 games with 0 actual points)\n",
      "  Accuracy (within +/- 3 points): 45.34%\n",
      "\n",
      "Baseline XGBoost Model (Re-evaluated on original scale):\n",
      "\n",
      "--- Baseline XGB (for comparison) Evaluation ---\n",
      "Mean Absolute Error (MAE): 4.82\n",
      "Root Mean Squared Error (RMSE): 6.60\n",
      "Mean Absolute Percentage Error (MAPE): 49.69% (excluding 145 games with 0 actual points)\n",
      "Accuracy (within +/- 3 points): 45.68%\n",
      "\n",
      "Sample Predictions vs Actual (Baseline XGB (for comparison)):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "1056   20.392953   18.781173   33.005499   31.911444   14.186562   13.632315   \n",
      "5907   21.141338   16.250644   27.370876   21.757188   12.919287   10.250668   \n",
      "866    16.532715   17.091862   32.554688   33.324296   11.227539   12.216747   \n",
      "3613   31.656860   27.842186   35.452789   34.666517   18.266296   16.386177   \n",
      "3035    6.310892    6.759531   14.724441   15.936651    4.650916    5.245164   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "1056    7.878767    6.073409    0.573870    0.568364  ...   \n",
      "5907    1.067596    0.968590    0.616145    0.533709  ...   \n",
      "866     3.194336    3.075880    0.665997    0.642214  ...   \n",
      "3613    2.702911    3.262124    0.802944    0.762387  ...   \n",
      "3035    2.251335    1.885907    0.555339    0.557341  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "1056               0.541082                118.0          100.0        3.0   \n",
      "5907               0.581034                115.1          100.0        2.0   \n",
      "866                0.510048                113.3          100.0        2.0   \n",
      "3613               0.450855                115.3          100.0        2.0   \n",
      "3035               0.350506                111.8          100.0        2.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "1056                    0        1          31      17.441666  13.558334   \n",
      "5907                    0        1          10       9.847054   0.152946   \n",
      "866                     0        0          14      15.081436  -1.081436   \n",
      "3613                    0        0          16      18.201122  -2.201122   \n",
      "3035                    0        0           1       5.351102  -4.351102   \n",
      "\n",
      "      Abs_Error  \n",
      "1056  13.558334  \n",
      "5907   0.152946  \n",
      "866    1.081436  \n",
      "3613   2.201122  \n",
      "3035   4.351102  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Largest Errors (Top 5):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "4828    4.432442    6.015148   17.781279   19.824970    6.396309    7.043066   \n",
      "6791   19.898682   16.288275   30.949463   27.728457   12.926514   10.954098   \n",
      "586     0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "828    19.393205   19.016931   31.519646   31.983537   15.347453   15.783018   \n",
      "2069   43.273193   37.254826   39.376953   38.472177   26.767090   24.276454   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "4828    0.265810    0.406650    0.311693    0.387556  ...   \n",
      "6791    1.008301    0.726399    0.745026    0.714792  ...   \n",
      "586     0.000000    0.000000    0.000000    0.000000  ...   \n",
      "828     3.578246    3.412519    0.550803    0.522486  ...   \n",
      "2069    8.494629    7.446714    0.691803    0.656763  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "4828               0.423775                115.3          100.0        3.0   \n",
      "6791               0.391298                119.4          100.0        3.0   \n",
      "586                0.000000                117.3          100.0        2.0   \n",
      "828                0.637602                119.4          100.0        3.0   \n",
      "2069               0.698436                119.4          100.0        1.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "4828                    0        1          41       6.561778  34.438222   \n",
      "6791                    0        1          37      10.432507  26.567493   \n",
      "586                     0        0          30       3.515144  26.484856   \n",
      "828                     0        1          45      19.542345  25.457655   \n",
      "2069                    1        1          49      24.544628  24.455372   \n",
      "\n",
      "      Abs_Error  \n",
      "4828  34.438222  \n",
      "6791  26.567493  \n",
      "586   26.484856  \n",
      "828   25.457655  \n",
      "2069  24.455372  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- Combined Segmented Model Evaluation (Hybrid: Role Player Ridge + Baseline XGBoost) ---\n",
    "\n",
    "print(f\"\\n--- Evaluating Combined HYBRID Model ({SEASON}) ---\")\n",
    "print(\"--- (Role Player Ridge + Baseline XGBoost) ---\")\n",
    "\n",
    "if 'X_test' not in locals() or X_test is None or X_test.empty or \\\n",
    "   'y_test_original' not in locals() or y_test_original is None or y_test_original.empty or \\\n",
    "   'test_scorer_mask_global' not in locals() or test_scorer_mask_global is None:\n",
    "\n",
    "    print(\"Error: Essential test data or segmentation masks not found. Please ensure previous cells have run successfully.\")\n",
    "\n",
    "else:\n",
    "    try:\n",
    "        # --- Load the required models ---\n",
    "        print(\"Loading required models...\")\n",
    "        model_role_path = os.path.join(MODEL_DIR, 'ridge_model_role_players.pkl')\n",
    "        model_scorer_path = os.path.join(MODEL_DIR, 'xgb_model_baseline.pkl') \n",
    "        \n",
    "        model_role_loaded = joblib.load(model_role_path)\n",
    "        model_scorer_loaded = joblib.load(model_scorer_path) # Load BASELINE XGB for scorers\n",
    "        print(\"Required models loaded successfully.\")\n",
    "\n",
    "        # --- Generate Combined Predictions ---\n",
    "        print(\"Generating combined HYBRID predictions...\")\n",
    "        scorer_mask = test_scorer_mask_global\n",
    "        role_mask = test_role_mask_global\n",
    "        n_scorers_test = scorer_mask.sum()\n",
    "        n_role_test = role_mask.sum()\n",
    "        print(f\"Test Set Segmentation (using masks): Scorers = {n_scorers_test}, Role Players = {n_role_test}\")\n",
    "\n",
    "        if n_scorers_test == 0 and n_role_test == 0:\n",
    "             print(\"Error: Both test segments are empty based on the mask. Cannot proceed.\")\n",
    "        else:\n",
    "            y_pred_combined_transformed = pd.Series(np.zeros(len(y_test_original), dtype=float), index=y_test_original.index)\n",
    "            if n_scorers_test > 0:\n",
    "                 X_test_scorers_segment = X_test[scorer_mask]\n",
    "                 y_pred_combined_transformed[scorer_mask] = model_scorer_loaded.predict(X_test_scorers_segment)\n",
    "            if n_role_test > 0:\n",
    "                 X_test_role_segment = X_test[role_mask]\n",
    "                 y_pred_combined_transformed[role_mask] = model_role_loaded.predict(X_test_role_segment)\n",
    "            print(\"Combined transformed HYBRID predictions generated.\")\n",
    "\n",
    "            # --- Transform Combined Predictions Back to Original Scale ---\n",
    "            y_pred_combined_original = np.expm1(y_pred_combined_transformed)\n",
    "            y_pred_combined_original[y_pred_combined_original < 0] = 0\n",
    "            print(\"Combined HYBRID predictions transformed back to original scale.\")\n",
    "\n",
    "            # --- Calculate Combined Metrics Directly (using original scale) ---\n",
    "            print(\"Calculating combined HYBRID metrics...\")\n",
    "            combined_mae = mean_absolute_error(y_test_original, y_pred_combined_original)\n",
    "            combined_mse = mean_squared_error(y_test_original, y_pred_combined_original)\n",
    "            combined_rmse = np.sqrt(combined_mse)\n",
    "            non_zero_mask_combined = y_test_original != 0\n",
    "            if np.any(non_zero_mask_combined):\n",
    "                combined_mape = mean_absolute_percentage_error(y_test_original[non_zero_mask_combined], y_pred_combined_original[non_zero_mask_combined])\n",
    "                combined_mape_note = f\"(excluding {(~non_zero_mask_combined).sum()} games with 0 actual points)\"\n",
    "            else:\n",
    "                combined_mape = np.nan \n",
    "                combined_mape_note = \"(MAPE not calculable)\"\n",
    "            combined_within_3_pts_accuracy = (np.abs(y_test_original - y_pred_combined_original) <= 3).mean() * 100\n",
    "            \n",
    "            # --- Print Comparison ---\n",
    "            print(f\"\\n--- METRICS COMPARISON ({SEASON}) ---\")\n",
    "            print(\"\\nCombined HYBRID Model (Role Ridge + Baseline XGB):\")\n",
    "            print(f\"  Mean Absolute Error (MAE): {combined_mae:.2f}\")\n",
    "            print(f\"  Root Mean Squared Error (RMSE): {combined_rmse:.2f}\")\n",
    "            print(f\"  Mean Absolute Percentage Error (MAPE): {combined_mape:.2%} {combined_mape_note}\")\n",
    "            print(f\"  Accuracy (within +/- 3 points): {combined_within_3_pts_accuracy:.2f}%\")\n",
    "\n",
    "            # Re-evaluate Baseline XGBoost Model for direct comparison\n",
    "            print(\"\\nBaseline XGBoost Model (Re-evaluated on original scale):\") \n",
    "            if 'model_xgb_baseline' in locals() and model_xgb_baseline is not None:\n",
    "                 evaluate_model(model_xgb_baseline, X_test, y_test, y_test_original, \"Baseline XGB (for comparison)\")\n",
    "            else:\n",
    "                 print(\"  Baseline XGBoost model ('model_xgb_baseline') not found in memory. Cannot re-evaluate.\")\n",
    "                 # Add fallback load if needed:\n",
    "                 # try:\n",
    "                 #    model_xgb_baseline_loaded = joblib.load(os.path.join(MODEL_DIR, 'xgb_model_baseline.pkl')) \n",
    "                 #    evaluate_model(model_xgb_baseline_loaded, X_test, y_test, y_test_original, \"Baseline XGB (Loaded for comparison)\")\n",
    "                 # except FileNotFoundError:\n",
    "                 #    print(f\"  Could not load '{os.path.join(MODEL_DIR, 'xgb_model_baseline.pkl')}' for comparison.\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error loading required model for hybrid evaluation: {e}.\")\n",
    "        traceback.print_exc()\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during combined hybrid evaluation: {e}\")\n",
    "        traceback.print_exc()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba_prop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
