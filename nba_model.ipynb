{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "from nba_api.stats.endpoints import playergamelog, commonplayerinfo, leaguegamefinder, leaguedashteamstats, leaguedashplayerstats\n",
    "from nba_api.stats.static import players, teams\n",
    "import time \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, TimeSeriesSplit # Added TimeSeriesSplit\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error # Added MAPE\n",
    "from xgboost import XGBRegressor\n",
    "import lightgbm as lgb # Added LightGBM\n",
    "import joblib # Added for saving models\n",
    "import traceback # Added for detailed error printing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total players found: 5024\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_name</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>is_active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76001</td>\n",
       "      <td>Alaa Abdelnaby</td>\n",
       "      <td>Alaa</td>\n",
       "      <td>Abdelnaby</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76002</td>\n",
       "      <td>Zaid Abdul-Aziz</td>\n",
       "      <td>Zaid</td>\n",
       "      <td>Abdul-Aziz</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76003</td>\n",
       "      <td>Kareem Abdul-Jabbar</td>\n",
       "      <td>Kareem</td>\n",
       "      <td>Abdul-Jabbar</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>Mahmoud Abdul-Rauf</td>\n",
       "      <td>Mahmoud</td>\n",
       "      <td>Abdul-Rauf</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1505</td>\n",
       "      <td>Tariq Abdul-Wahad</td>\n",
       "      <td>Tariq</td>\n",
       "      <td>Abdul-Wahad</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id            full_name first_name     last_name  is_active\n",
       "0  76001       Alaa Abdelnaby       Alaa     Abdelnaby      False\n",
       "1  76002      Zaid Abdul-Aziz       Zaid    Abdul-Aziz      False\n",
       "2  76003  Kareem Abdul-Jabbar     Kareem  Abdul-Jabbar      False\n",
       "3     51   Mahmoud Abdul-Rauf    Mahmoud    Abdul-Rauf      False\n",
       "4   1505    Tariq Abdul-Wahad      Tariq   Abdul-Wahad      False"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all players\n",
    "nba_players = players.get_players()\n",
    "players_df = pd.DataFrame(nba_players)\n",
    "print(f\"Total players found: {len(players_df)}\")\n",
    "players_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total teams found: 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_name</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>nickname</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>year_founded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1610612737</td>\n",
       "      <td>Atlanta Hawks</td>\n",
       "      <td>ATL</td>\n",
       "      <td>Hawks</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1610612738</td>\n",
       "      <td>Boston Celtics</td>\n",
       "      <td>BOS</td>\n",
       "      <td>Celtics</td>\n",
       "      <td>Boston</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>1946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1610612739</td>\n",
       "      <td>Cleveland Cavaliers</td>\n",
       "      <td>CLE</td>\n",
       "      <td>Cavaliers</td>\n",
       "      <td>Cleveland</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1610612740</td>\n",
       "      <td>New Orleans Pelicans</td>\n",
       "      <td>NOP</td>\n",
       "      <td>Pelicans</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>Louisiana</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1610612741</td>\n",
       "      <td>Chicago Bulls</td>\n",
       "      <td>CHI</td>\n",
       "      <td>Bulls</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>1966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             full_name abbreviation   nickname         city  \\\n",
       "0  1610612737         Atlanta Hawks          ATL      Hawks      Atlanta   \n",
       "1  1610612738        Boston Celtics          BOS    Celtics       Boston   \n",
       "2  1610612739   Cleveland Cavaliers          CLE  Cavaliers    Cleveland   \n",
       "3  1610612740  New Orleans Pelicans          NOP   Pelicans  New Orleans   \n",
       "4  1610612741         Chicago Bulls          CHI      Bulls      Chicago   \n",
       "\n",
       "           state  year_founded  \n",
       "0        Georgia          1949  \n",
       "1  Massachusetts          1946  \n",
       "2           Ohio          1970  \n",
       "3      Louisiana          2002  \n",
       "4       Illinois          1966  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all teams\n",
    "nba_teams = teams.get_teams()\n",
    "teams_df = pd.DataFrame(nba_teams)\n",
    "print(f\"Total teams found: {len(teams_df)}\")\n",
    "teams_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching team stats (Defense & Pace)...\n",
      "Available columns in team stats:\n",
      "Index(['TEAM_ID', 'TEAM_NAME', 'GP', 'W', 'L', 'W_PCT', 'MIN', 'DEF_RATING',\n",
      "       'DREB', 'DREB_PCT', 'STL', 'BLK', 'OPP_PTS_OFF_TOV',\n",
      "       'OPP_PTS_2ND_CHANCE', 'OPP_PTS_FB', 'OPP_PTS_PAINT', 'GP_RANK',\n",
      "       'W_RANK', 'L_RANK', 'W_PCT_RANK', 'MIN_RANK', 'DEF_RATING_RANK',\n",
      "       'DREB_RANK', 'DREB_PCT_RANK', 'STL_RANK', 'BLK_RANK',\n",
      "       'OPP_PTS_OFF_TOV_RANK', 'OPP_PTS_2ND_CHANCE_RANK', 'OPP_PTS_FB_RANK',\n",
      "       'OPP_PTS_PAINT_RANK'],\n",
      "      dtype='object')\n",
      "Using 'TEAM_NAME' as identifier.\n",
      "Merging team stats to get TEAM_ABBREVIATION using 'TEAM_NAME'...\n",
      "Merged successfully, using TEAM_ABBREVIATION.\n",
      "\n",
      "Team stats (Defense & Pace) processed.\n",
      "  TEAM_ABBREVIATION  DEF_RATING\n",
      "0               ATL       118.4\n",
      "1               BOS       110.6\n",
      "2               BKN       115.4\n",
      "3               CHA       119.2\n",
      "4               CHI       115.7\n"
     ]
    }
   ],
   "source": [
    "# Fetch Team Defensive Stats and Pace for the season\n",
    "print(\"Fetching team stats (Defense & Pace)...\")\n",
    "team_stats_df = pd.DataFrame() \n",
    "try:\n",
    "    # Fetch stats, including Pace\n",
    "    team_stats = leaguedashteamstats.LeagueDashTeamStats(\n",
    "        season='2023-24',\n",
    "        measure_type_detailed_defense='Defense' # This measure type includes Pace in the result\n",
    "    )\n",
    "    temp_df = team_stats.get_data_frames()[0]\n",
    "    \n",
    "    print(\"Available columns in team stats:\")\n",
    "    print(temp_df.columns) \n",
    "\n",
    "    # Identify the team column (prefer TEAM_ABBREVIATION for merging later)\n",
    "    identifier_column = None\n",
    "    if 'TEAM_ABBREVIATION' in temp_df.columns:\n",
    "        identifier_column = 'TEAM_ABBREVIATION'\n",
    "        print(f\"Using '{identifier_column}' as identifier.\")\n",
    "    elif 'TEAM_NAME' in temp_df.columns:\n",
    "        identifier_column = 'TEAM_NAME'\n",
    "        print(f\"Using '{identifier_column}' as identifier.\")\n",
    "    elif 'TEAM_ID' in temp_df.columns:\n",
    "        identifier_column = 'TEAM_ID'\n",
    "        print(f\"Using '{identifier_column}' as identifier.\")\n",
    "    else:\n",
    "        raise KeyError(f\"Could not find a suitable team identifier column. Available: {temp_df.columns}\")\n",
    "\n",
    "    # Select relevant columns (identifier, DEF_RATING, PACE)\n",
    "    required_team_cols = [identifier_column, 'DEF_RATING', 'PACE']\n",
    "    available_team_cols = [col for col in required_team_cols if col in temp_df.columns]\n",
    "    \n",
    "    if len(available_team_cols) < 2: # Need at least identifier and one stat\n",
    "         print(f\"Warning: Not enough required team columns found. Found: {available_team_cols}\")\n",
    "         team_stats_df = pd.DataFrame() # Ensure it's empty\n",
    "    else:\n",
    "        team_stats_df = temp_df[available_team_cols].copy()\n",
    "        \n",
    "        # If identifier is not abbreviation, try to merge to get abbreviation\n",
    "        if identifier_column != 'TEAM_ABBREVIATION' and 'teams_df' in locals() and not teams_df.empty:\n",
    "             print(f\"Merging team stats to get TEAM_ABBREVIATION using '{identifier_column}'...\")\n",
    "             merge_left_col = identifier_column\n",
    "             merge_right_col = 'full_name' if identifier_column == 'TEAM_NAME' else 'id'\n",
    "             \n",
    "             if identifier_column == 'TEAM_ID':\n",
    "                 team_stats_df[identifier_column] = team_stats_df[identifier_column].astype(int)\n",
    "                 teams_df['id'] = teams_df['id'].astype(int)\n",
    "\n",
    "             merged_temp_df = pd.merge(team_stats_df, teams_df[['id', 'full_name', 'abbreviation']], left_on=merge_left_col, right_on=merge_right_col, how='left')\n",
    "             \n",
    "             if 'abbreviation' in merged_temp_df.columns:\n",
    "                 # Keep abbreviation and the stats, drop the original identifier\n",
    "                 cols_to_keep = ['abbreviation'] + [col for col in available_team_cols if col != identifier_column]\n",
    "                 team_stats_df = merged_temp_df[cols_to_keep].rename(columns={'abbreviation': 'TEAM_ABBREVIATION'})\n",
    "                 print(\"Merged successfully, using TEAM_ABBREVIATION.\")\n",
    "             else:\n",
    "                  print(f\"Warning: Could not find 'abbreviation' after merging with teams_df based on '{identifier_column}'. Using original identifier column.\")\n",
    "                  team_stats_df = team_stats_df.rename(columns={identifier_column: 'TEAM_ABBREVIATION'}) # Rename for consistency if we couldn't merge\n",
    "        else: # If identifier was already abbreviation or teams_df not available\n",
    "             team_stats_df = team_stats_df.rename(columns={identifier_column: 'TEAM_ABBREVIATION'})\n",
    "\n",
    "    if not team_stats_df.empty and 'TEAM_ABBREVIATION' in team_stats_df.columns:\n",
    "        print(\"\\nTeam stats (Defense & Pace) processed.\")\n",
    "        print(team_stats_df.head())\n",
    "    else:\n",
    "         print(\"\\nCould not process team stats correctly after renaming/merging.\")\n",
    "         team_stats_df = pd.DataFrame() # Ensure empty on failure\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nError fetching or processing team stats: {e}\")\n",
    "    traceback.print_exc()\n",
    "    team_stats_df = pd.DataFrame() # Ensure it's empty on error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing raw game logs from nba_gamelogs_raw_2023-24.csv...\n",
      "Essential columns found in existing CSV.\n",
      "\n",
      "Total game logs available: 5193\n",
      "Unique players in logs: 100\n",
      "'FTA' column successfully included.\n",
      "'TOV' column successfully included.\n",
      "'FGA' column successfully included.\n",
      "'PTS' column successfully included.\n",
      "'MIN' column successfully included.\n",
      "'GAME_DATE' column successfully included.\n",
      "'MATCHUP' column successfully included.\n",
      "   SEASON_ID  Player_ID   Game_ID     GAME_DATE      MATCHUP WL  MIN  FGM  \\\n",
      "0      22023    1630639  22301196  APR 14, 2024    DAL @ OKC  L   24    5   \n",
      "1      22023    1630639  22301181  APR 12, 2024  DAL vs. DET  L   22    1   \n",
      "2      22023    1630639  22301161  APR 10, 2024    DAL @ MIA  W    2    0   \n",
      "3      22023    1630639  22301144  APR 09, 2024    DAL @ CHA  W    4    1   \n",
      "4      22023    1630639  22301097  APR 05, 2024  DAL vs. GSW  W    5    0   \n",
      "\n",
      "   FGA  FG_PCT  ...  DREB  REB  AST  STL  BLK  TOV  PF  PTS  PLUS_MINUS  \\\n",
      "0   13   0.385  ...     4    5    2    0    0    1   1   12         -18   \n",
      "1    6   0.167  ...     5    6    2    0    0    2   0    2          -4   \n",
      "2    0   0.000  ...     2    2    1    0    0    0   0    0           4   \n",
      "3    2   0.500  ...     0    0    0    0    0    1   1    2           2   \n",
      "4    2   0.000  ...     0    0    1    0    0    0   0    0          -1   \n",
      "\n",
      "   VIDEO_AVAILABLE  \n",
      "0                1  \n",
      "1                1  \n",
      "2                1  \n",
      "3                1  \n",
      "4                1  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function to get game logs for a player and season with delay\n",
    "def get_player_log(player_id, season='2023-24'):\n",
    "    print(f\"Fetching logs for player {player_id}...\")\n",
    "    try:\n",
    "        # Note: PlayerGameLog endpoint provides FGA, PTS, FTA, and TOV\n",
    "        log = playergamelog.PlayerGameLog(player_id=player_id, season=season)\n",
    "        df = log.get_data_frames()[0]\n",
    "        time.sleep(0.6) # NBA API rate limit\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching logs for player {player_id}: {e}\")\n",
    "        time.sleep(0.6)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# --- Define Season and Output File ---\n",
    "SEASON = '2023-24'\n",
    "RAW_GAMELOG_FILE = f'nba_gamelogs_raw_{SEASON}.csv'\n",
    "MIN_MINUTES_THRESHOLD = 15 # Minimum average minutes per game to be included\n",
    "MAX_PLAYERS_TO_FETCH = 100 # Limit players for faster fetching if needed\n",
    "\n",
    "# --- Check if Processed Data Exists and Contains TOV ---\n",
    "FETCH_REQUIRED = False\n",
    "if os.path.exists(RAW_GAMELOG_FILE):\n",
    "    print(f\"Loading existing raw game logs from {RAW_GAMELOG_FILE}...\")\n",
    "    try:\n",
    "        all_gamelogs_df = pd.read_csv(RAW_GAMELOG_FILE)\n",
    "        # Ensure Player_ID is integer if loaded from CSV\n",
    "        if 'Player_ID' in all_gamelogs_df.columns:\n",
    "            all_gamelogs_df['Player_ID'] = all_gamelogs_df['Player_ID'].astype(int)\n",
    "        # Check if essential columns are present (including TOV, FGA, FTA)\n",
    "        essential_cols_check = ['TOV', 'FGA', 'FTA', 'PTS', 'MIN']\n",
    "        missing_essential = [col for col in essential_cols_check if col not in all_gamelogs_df.columns]\n",
    "        if missing_essential:\n",
    "            print(f\"Warning: Missing essential columns ({missing_essential}) from existing CSV. Re-fetching required.\")\n",
    "            FETCH_REQUIRED = True\n",
    "        else:\n",
    "            print(\"Essential columns found in existing CSV.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or checking CSV file {RAW_GAMELOG_FILE}: {e}. Re-fetching required.\")\n",
    "        FETCH_REQUIRED = True\n",
    "        all_gamelogs_df = pd.DataFrame() # Ensure it's empty if loading failed\n",
    "else:\n",
    "    print(\"Raw game log file not found. Fetching data...\")\n",
    "    FETCH_REQUIRED = True\n",
    "    all_gamelogs_df = pd.DataFrame()\n",
    "\n",
    "# --- Fetch Data if Required ---\n",
    "if FETCH_REQUIRED:\n",
    "    # Remove old file if it exists but is incomplete\n",
    "    if os.path.exists(RAW_GAMELOG_FILE):\n",
    "        print(f\"Removing incomplete file: {RAW_GAMELOG_FILE}\")\n",
    "        try:\n",
    "            os.remove(RAW_GAMELOG_FILE)\n",
    "        except OSError as e:\n",
    "            print(f\"Error removing file: {e}\")\n",
    "            \n",
    "    # --- Filter Players Based on Season Stats (e.g., Minutes Played) ---\n",
    "    print(f\"Fetching player stats for {SEASON} to filter...\")\n",
    "    player_ids_to_fetch = []\n",
    "    try:\n",
    "        player_stats = leaguedashplayerstats.LeagueDashPlayerStats(season=SEASON)\n",
    "        player_stats_df = player_stats.get_data_frames()[0]\n",
    "        time.sleep(0.6)\n",
    "        \n",
    "        # Filter players playing significant minutes\n",
    "        # Ensure MIN is numeric before filtering\n",
    "        player_stats_df['MIN'] = pd.to_numeric(player_stats_df['MIN'], errors='coerce')\n",
    "        relevant_players_df = player_stats_df[player_stats_df['MIN'] >= MIN_MINUTES_THRESHOLD].copy()\n",
    "        player_ids_to_fetch = relevant_players_df['PLAYER_ID'].unique().tolist()\n",
    "        print(f\"Found {len(player_ids_to_fetch)} players averaging >= {MIN_MINUTES_THRESHOLD} MPG.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching player stats for filtering: {e}. Falling back to all active players.\")\n",
    "        traceback.print_exc()\n",
    "        # Fallback: Get all active players if stats fetch fails\n",
    "        active_players_df = players_df[players_df['is_active'] == True]\n",
    "        player_ids_to_fetch = active_players_df['id'].tolist()\n",
    "        print(f\"Fetching for all {len(player_ids_to_fetch)} active players (fallback).\")\n",
    "        \n",
    "    # --- Limit players if needed ---\n",
    "    if len(player_ids_to_fetch) > MAX_PLAYERS_TO_FETCH:\n",
    "        print(f\"Limiting fetch to {MAX_PLAYERS_TO_FETCH} players for speed.\")\n",
    "        player_ids_to_fetch = player_ids_to_fetch[:MAX_PLAYERS_TO_FETCH]\n",
    "        \n",
    "    # --- Fetching game logs for filtered players ---\n",
    "    if player_ids_to_fetch:\n",
    "        print(f\"Fetching game logs for {len(player_ids_to_fetch)} players...\")\n",
    "        fetched_logs = [] # Collect dataframes in a list first\n",
    "        for i, p_id in enumerate(player_ids_to_fetch):\n",
    "            print(f\"Progress: {i+1}/{len(player_ids_to_fetch)}\")\n",
    "            player_log_df = get_player_log(p_id, season=SEASON)\n",
    "            if not player_log_df.empty:\n",
    "                # Add Player_ID if it's missing (sometimes happens)\n",
    "                if 'Player_ID' not in player_log_df.columns:\n",
    "                     player_log_df['Player_ID'] = p_id\n",
    "                fetched_logs.append(player_log_df)\n",
    "                \n",
    "        # --- Concatenate and Save the fetched data ---\n",
    "        if fetched_logs:\n",
    "            all_gamelogs_df = pd.concat(fetched_logs, ignore_index=True)\n",
    "            print(f\"\\nSaving {len(all_gamelogs_df)} game logs to {RAW_GAMELOG_FILE}...\")\n",
    "            all_gamelogs_df.to_csv(RAW_GAMELOG_FILE, index=False)\n",
    "            print(\"Save complete.\")\n",
    "        else:\n",
    "            print(\"\\nNo game logs were fetched or concatenated.\")\n",
    "            all_gamelogs_df = pd.DataFrame() # Ensure it's an empty DF if nothing was fetched\n",
    "    else:\n",
    "        print(\"\\nNo player IDs identified for fetching.\")\n",
    "        all_gamelogs_df = pd.DataFrame()\n",
    "\n",
    "# --- Display results ---\n",
    "if 'all_gamelogs_df' in locals() and not all_gamelogs_df.empty:\n",
    "    print(f\"\\nTotal game logs available: {len(all_gamelogs_df)}\")\n",
    "    print(f\"Unique players in logs: {all_gamelogs_df['Player_ID'].nunique()}\")\n",
    "    # Check essential columns after loading/fetching\n",
    "    essential_cols_check = ['FTA', 'TOV', 'FGA', 'PTS', 'MIN', 'GAME_DATE', 'MATCHUP']\n",
    "    for col in essential_cols_check:\n",
    "        if col in all_gamelogs_df.columns:\n",
    "            print(f\"'{col}' column successfully included.\")\n",
    "        else:\n",
    "            print(f\"Warning: '{col}' column is missing from the loaded/fetched data!\")\n",
    "    print(all_gamelogs_df.head())\n",
    "else:\n",
    "    print(\"\\nall_gamelogs_df is empty. Cannot proceed with preprocessing/modeling.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2much\\AppData\\Local\\Temp\\ipykernel_79100\\3982206826.py:9: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  processed_df['GAME_DATE'] = pd.to_datetime(processed_df['GAME_DATE'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing complete.\n",
      "      Player_ID   Game_ID  GAME_DATE      MATCHUP WL  MIN  PTS  REB  AST  \\\n",
      "4303     101108  22300062 2023-10-24  GSW vs. PHX  L   34   14    6    9   \n",
      "4302     101108  22300087 2023-10-27    GSW @ SAC  W   33   10    2   12   \n",
      "4301     101108  22300096 2023-10-29    GSW @ HOU  W   27    8    5    7   \n",
      "4300     101108  22300108 2023-10-30    GSW @ NOP  W   25   13    6    5   \n",
      "4299     101108  22300126 2023-11-01  GSW vs. SAC  W   28    2    4    8   \n",
      "\n",
      "      FG3M  STL  BLK  TOV  FGA  FTA Opponent Home_Away  \n",
      "4303     0    2    0    1   15    7      PHX      Home  \n",
      "4302     0    3    0    3   12    0      SAC      Away  \n",
      "4301     0    1    0    1    8    2      HOU      Away  \n",
      "4300     1    2    0    1   10    0      NOP      Away  \n",
      "4299     0    0    0    0    5    0      SAC      Home  \n"
     ]
    }
   ],
   "source": [
    "# --- Data Preprocessing ---\n",
    "\n",
    "# Check if all_gamelogs_df exists and is not empty before proceeding\n",
    "if 'all_gamelogs_df' in locals() and not all_gamelogs_df.empty:\n",
    "    processed_df = all_gamelogs_df.copy()\n",
    "    \n",
    "    # Ensure GAME_DATE is datetime and sort for time-based features\n",
    "    if 'GAME_DATE' in processed_df.columns:\n",
    "        processed_df['GAME_DATE'] = pd.to_datetime(processed_df['GAME_DATE'])\n",
    "    else:\n",
    "        print(\"Error: 'GAME_DATE' column missing! Cannot proceed with time-based processing.\")\n",
    "        processed_df = pd.DataFrame() # Empty the df to prevent further errors\n",
    "\n",
    "    if not processed_df.empty:\n",
    "        processed_df = processed_df.sort_values(by=['Player_ID', 'GAME_DATE'])\n",
    "\n",
    "        # Select relevant columns (including FGA, FTA, and TOV)\n",
    "        # Ensure all expected columns exist, handle missing ones if necessary\n",
    "        expected_cols = ['Player_ID', 'Game_ID', 'GAME_DATE', 'MATCHUP', 'WL', \n",
    "                         'MIN', 'PTS', 'REB', 'AST', 'FG3M', 'STL', 'BLK', 'TOV', 'FGA', 'FTA'] # Added TOV\n",
    "        available_cols = [col for col in expected_cols if col in processed_df.columns]\n",
    "        missing_cols = [col for col in expected_cols if col not in processed_df.columns]\n",
    "        if missing_cols:\n",
    "            print(f\"Warning: Missing expected columns for initial selection: {missing_cols}. Proceeding with available columns.\")\n",
    "        processed_df = processed_df[available_cols]\n",
    "\n",
    "        # Ensure necessary columns for calculations are numeric, coercing errors\n",
    "        numeric_cols_check = ['PTS', 'FGA', 'FTA', 'MIN', 'TOV', 'REB', 'AST', 'FG3M', 'STL', 'BLK'] # Expanded numeric checks\n",
    "        for col in numeric_cols_check:\n",
    "            if col in processed_df.columns:\n",
    "                processed_df[col] = pd.to_numeric(processed_df[col], errors='coerce')\n",
    "            else:\n",
    "                 print(f\"Warning: Column {col} needed for processing is missing.\")\n",
    "                 \n",
    "        # Drop rows where essential numeric columns became NaN after coercion\n",
    "        # Important: Check if columns exist before adding to subset\n",
    "        dropna_subset = ['PTS', 'FGA', 'FTA', 'MIN']\n",
    "        if 'TOV' in processed_df.columns: dropna_subset.append('TOV')\n",
    "        if 'FGA' in processed_df.columns: dropna_subset.append('FGA')\n",
    "        if 'FTA' in processed_df.columns: dropna_subset.append('FTA')\n",
    "        \n",
    "        # Only drop if the columns actually exist in the DataFrame\n",
    "        actual_dropna_subset = [col for col in dropna_subset if col in processed_df.columns]\n",
    "        processed_df.dropna(subset=actual_dropna_subset, inplace=True)\n",
    "\n",
    "        # Parse Matchup to get Opponent and Home/Away\n",
    "        def parse_matchup(matchup_str):\n",
    "            if pd.isna(matchup_str):\n",
    "                 return 'Unknown', 'Unknown'\n",
    "            if '@' in matchup_str:\n",
    "                parts = matchup_str.split(' @ ')\n",
    "                opponent = parts[1] if len(parts) > 1 else 'Unknown'\n",
    "                home_away = 'Away'\n",
    "            elif 'vs.' in matchup_str:\n",
    "                parts = matchup_str.split(' vs. ')\n",
    "                opponent = parts[1] if len(parts) > 1 else 'Unknown'\n",
    "                home_away = 'Home'\n",
    "            else: \n",
    "                opponent = 'Unknown'\n",
    "                home_away = 'Unknown'\n",
    "            return opponent, home_away\n",
    "\n",
    "        if 'MATCHUP' in processed_df.columns:\n",
    "            # Apply the function and assign results back as new columns\n",
    "            parsed_matchup = processed_df['MATCHUP'].apply(lambda x: pd.Series(parse_matchup(x), index=['Opponent', 'Home_Away']))\n",
    "            processed_df = pd.concat([processed_df, parsed_matchup], axis=1)\n",
    "            # Handle potential empty results from apply if all MATCHUP were NaN\n",
    "            if 'Opponent' not in processed_df.columns:\n",
    "                 processed_df['Opponent'] = 'Unknown'\n",
    "            if 'Home_Away' not in processed_df.columns:\n",
    "                 processed_df['Home_Away'] = 'Unknown'\n",
    "        else:\n",
    "            print(\"Warning: 'MATCHUP' column not found. Cannot determine Opponent or Home/Away.\")\n",
    "            processed_df['Opponent'] = 'Unknown'\n",
    "            processed_df['Home_Away'] = 'Unknown'\n",
    "\n",
    "        # Calculate Rest Days (already done in Feature Engineering, but good to ensure sorted first)\n",
    "        # processed_df['Rest_Days'] = processed_df.groupby('Player_ID')['GAME_DATE'].diff().dt.days\n",
    "        # processed_df['Rest_Days'].fillna(processed_df['Rest_Days'].mode()[0] if not processed_df['Rest_Days'].mode().empty else 2, inplace=True) # Fill first game with mode or 2\n",
    "\n",
    "        print(\"Data preprocessing complete.\")\n",
    "        print(processed_df.head())\n",
    "    \n",
    "else:\n",
    "    print(\"Skipping Data Preprocessing because 'all_gamelogs_df' is not available or empty.\")\n",
    "    processed_df = pd.DataFrame() # Ensure processed_df exists even if empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Feature Engineering...\n",
      "Calculated Rest Days.\n",
      "Calculated Is_B2B_Second_Night.\n",
      "Calculated Player Usage Rate Proxy.\n",
      "Calculated TS%.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2much\\AppData\\Local\\Temp\\ipykernel_79100\\354773687.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  processed_df['Rest_Days'].fillna(processed_df['Rest_Days'].mode()[0], inplace=True)\n",
      "C:\\Users\\2much\\AppData\\Local\\Temp\\ipykernel_79100\\354773687.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  processed_df['Player_USG_Proxy'].fillna(0, inplace=True)\n",
      "C:\\Users\\2much\\AppData\\Local\\Temp\\ipykernel_79100\\354773687.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  processed_df['Player_USG_Proxy'].replace([np.inf, -np.inf], 0, inplace=True)\n",
      "C:\\Users\\2much\\AppData\\Local\\Temp\\ipykernel_79100\\354773687.py:49: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  processed_df['TS%'].fillna(0, inplace=True)\n",
      "C:\\Users\\2much\\AppData\\Local\\Temp\\ipykernel_79100\\354773687.py:50: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  processed_df['TS%'].replace([np.inf, -np.inf], 0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated EWMA features.\n",
      "Calculated base cumulative averages.\n",
      "Calculated cumulative averages for TS% and USG% Proxy.\n",
      "Merging fetched team defensive stats and pace...\n",
      "Opponent DEF_RATING merged. Filled NaNs with 114.5.\n",
      "Warning: 'Opponent_PACE' column not created after merge. Using default.\n",
      "Filled NaNs in engineered features: ['Rest_Days', 'Is_B2B_Second_Night', 'PTS_EWMA_3', 'PTS_EWMA_5', 'MIN_EWMA_3', 'MIN_EWMA_5', 'FGA_EWMA_3', 'FGA_EWMA_5', 'FTA_EWMA_3', 'FTA_EWMA_5', 'TS%_EWMA_3', 'TS%_EWMA_5', 'Player_USG_Proxy_EWMA_3', 'Player_USG_Proxy_EWMA_5', 'Avg_PTS_Season', 'PTS_Per36_Season', 'Avg_TS%_Season', 'Avg_USG%_Proxy_Season', 'Is_Home', 'Opponent_DEF_RATING', 'Opponent_PACE']\n",
      "Feature Engineering complete.\n",
      "   Player_ID   Game_ID  GAME_DATE      MATCHUP WL  MIN  PTS  REB  AST  FG3M  \\\n",
      "0     101108  22300062 2023-10-24  GSW vs. PHX  L   34   14    6    9     0   \n",
      "1     101108  22300087 2023-10-27    GSW @ SAC  W   33   10    2   12     0   \n",
      "2     101108  22300096 2023-10-29    GSW @ HOU  W   27    8    5    7     0   \n",
      "3     101108  22300108 2023-10-30    GSW @ NOP  W   25   13    6    5     1   \n",
      "4     101108  22300126 2023-11-01  GSW vs. SAC  W   28    2    4    8     0   \n",
      "5     101108  22300005 2023-11-03    GSW @ OKC  W   28    1    2   13     0   \n",
      "6     101108  22300142 2023-11-05    GSW @ CLE  L   25    5    1    2     1   \n",
      "7     101108  22300145 2023-11-06    GSW @ DET  W   21   17    5    6     2   \n",
      "8     101108  22300169 2023-11-08    GSW @ DEN  L   27    9    5    4     1   \n",
      "9     101108  22300176 2023-11-11  GSW vs. CLE  L   26    9    3    9     1   \n",
      "\n",
      "   ...  Avg_PTS_Season  PTS_Per36_Season  Cum_FGA  Cum_FTA  Cum_TOV  \\\n",
      "0  ...        0.000000          0.000000      0.0      0.0      0.0   \n",
      "1  ...       14.000000         14.823529     15.0      7.0      1.0   \n",
      "2  ...       12.000000         12.895522     27.0      7.0      4.0   \n",
      "3  ...       10.666667         12.255319     35.0      9.0      5.0   \n",
      "4  ...       11.250000         13.613445     45.0      9.0      6.0   \n",
      "5  ...        9.400000         11.510204     50.0      9.0      6.0   \n",
      "6  ...        8.000000          9.874286     56.0     11.0      6.0   \n",
      "7  ...        7.571429          9.540000     66.0     11.0      6.0   \n",
      "8  ...        8.750000         11.402715     75.0     14.0      6.0   \n",
      "9  ...        8.777778         11.467742     85.0     14.0      7.0   \n",
      "\n",
      "  Avg_TS%_Season Avg_USG%_Proxy_Season  Is_Home  Opponent_DEF_RATING  \\\n",
      "0       0.000000              0.000000        1                113.7   \n",
      "1       0.387168              0.561176        0                114.4   \n",
      "2       0.398936              0.508657        0                112.8   \n",
      "3       0.410678              0.467660        0                111.9   \n",
      "4       0.459559              0.461849        1                114.4   \n",
      "5       0.435508              0.407891        0                111.0   \n",
      "6       0.394477              0.381943        0                112.1   \n",
      "7       0.374082              0.384200        0                118.0   \n",
      "8       0.431247              0.394389        0                112.3   \n",
      "9       0.433304              0.395806        1                112.1   \n",
      "\n",
      "   Opponent_PACE  \n",
      "0          100.0  \n",
      "1          100.0  \n",
      "2          100.0  \n",
      "3          100.0  \n",
      "4          100.0  \n",
      "5          100.0  \n",
      "6          100.0  \n",
      "7          100.0  \n",
      "8          100.0  \n",
      "9          100.0  \n",
      "\n",
      "[10 rows x 46 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2much\\AppData\\Local\\Temp\\ipykernel_79100\\354773687.py:110: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  processed_df['Avg_TS%_Season'].fillna(0, inplace=True)\n",
      "C:\\Users\\2much\\AppData\\Local\\Temp\\ipykernel_79100\\354773687.py:111: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  processed_df['Avg_TS%_Season'].replace([np.inf, -np.inf], 0, inplace=True)\n",
      "C:\\Users\\2much\\AppData\\Local\\Temp\\ipykernel_79100\\354773687.py:119: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  processed_df['Avg_USG%_Proxy_Season'].fillna(0, inplace=True)\n",
      "C:\\Users\\2much\\AppData\\Local\\Temp\\ipykernel_79100\\354773687.py:120: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  processed_df['Avg_USG%_Proxy_Season'].replace([np.inf, -np.inf], 0, inplace=True)\n",
      "C:\\Users\\2much\\AppData\\Local\\Temp\\ipykernel_79100\\354773687.py:165: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  processed_df['Opponent_DEF_RATING'].fillna(fill_value_def, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# --- Feature Engineering ---\n",
    "\n",
    "# Check if processed_df exists and is not empty\n",
    "if 'processed_df' in locals() and not processed_df.empty:\n",
    "    print(\"Starting Feature Engineering...\")\n",
    "    \n",
    "    # Calculate Rest Days\n",
    "    processed_df['Rest_Days'] = processed_df.groupby('Player_ID')['GAME_DATE'].diff().dt.days\n",
    "    # Fill first game NaN with a reasonable value (e.g., mode, average, or specific indicator)\n",
    "    # Using mode is better than a fixed value like 2 if the typical rest isn't 2 days\n",
    "    if not processed_df['Rest_Days'].mode().empty:\n",
    "        processed_df['Rest_Days'].fillna(processed_df['Rest_Days'].mode()[0], inplace=True)\n",
    "    else:\n",
    "        processed_df['Rest_Days'].fillna(2, inplace=True) # Fallback if mode is empty\n",
    "    print(\"Calculated Rest Days.\")\n",
    "\n",
    "    # Add Is_B2B_Second_Night feature\n",
    "    # B2B is when Rest_Days is exactly 1\n",
    "    processed_df['Is_B2B_Second_Night'] = processed_df['Rest_Days'].apply(lambda x: 1 if x == 1 else 0)\n",
    "    print(\"Calculated Is_B2B_Second_Night.\")\n",
    "    \n",
    "    # Calculate Player Usage Rate Proxy (Requires FGA, FTA, TOV, MIN)\n",
    "    # Using the simplified player-level proxy, but will use EWMA on this.\n",
    "    if all(col in processed_df.columns for col in ['FGA', 'FTA', 'TOV', 'MIN']):\n",
    "        processed_df['TOV'] = pd.to_numeric(processed_df['TOV'], errors='coerce').fillna(0)\n",
    "        processed_df['FGA'] = pd.to_numeric(processed_df['FGA'], errors='coerce').fillna(0)\n",
    "        processed_df['FTA'] = pd.to_numeric(processed_df['FTA'], errors='coerce').fillna(0)\n",
    "        processed_df['MIN'] = pd.to_numeric(processed_df['MIN'], errors='coerce').fillna(0)\n",
    "        \n",
    "        usg_numerator = processed_df['FGA'] + 0.44 * processed_df['FTA'] + processed_df['TOV']\n",
    "        usg_denominator = processed_df['MIN'] # Using Player MIN as proxy denominator\n",
    "        processed_df['Player_USG_Proxy'] = np.where(usg_denominator == 0, 0, usg_numerator / usg_denominator)\n",
    "        processed_df['Player_USG_Proxy'].fillna(0, inplace=True)\n",
    "        processed_df['Player_USG_Proxy'].replace([np.inf, -np.inf], 0, inplace=True)\n",
    "        print(\"Calculated Player Usage Rate Proxy.\")\n",
    "    else:\n",
    "        missing = [col for col in ['FGA', 'FTA', 'TOV', 'MIN'] if col not in processed_df.columns]\n",
    "        print(f\"Warning: Could not calculate Player Usage Rate Proxy due to missing columns: {missing}.\")\n",
    "        processed_df['Player_USG_Proxy'] = 0 # Assign default value\n",
    "        \n",
    "    # Calculate True Shooting Percentage (TS%)\n",
    "    if all(col in processed_df.columns for col in ['PTS', 'FGA', 'FTA']):\n",
    "        processed_df['PTS'] = pd.to_numeric(processed_df['PTS'], errors='coerce').fillna(0)\n",
    "        processed_df['FGA'] = pd.to_numeric(processed_df['FGA'], errors='coerce').fillna(0)\n",
    "        processed_df['FTA'] = pd.to_numeric(processed_df['FTA'], errors='coerce').fillna(0)\n",
    "        \n",
    "        denominator = 2 * (processed_df['FGA'] + 0.44 * processed_df['FTA'])\n",
    "        processed_df['TS%'] = np.where(denominator == 0, 0, processed_df['PTS'] / denominator)\n",
    "        processed_df['TS%'].fillna(0, inplace=True)\n",
    "        processed_df['TS%'].replace([np.inf, -np.inf], 0, inplace=True)\n",
    "        print(\"Calculated TS%.\")\n",
    "    else:\n",
    "        missing = [col for col in ['PTS', 'FGA', 'FTA'] if col not in processed_df.columns]\n",
    "        print(f\"Warning: Could not calculate TS% due to missing columns: {missing}.\")\n",
    "        processed_df['TS%'] = 0 # Assign default value\n",
    "\n",
    "    # Exponentially Weighted Moving Averages (Sharper Recency)\n",
    "    cols_for_ewma = ['PTS', 'MIN', 'FGA', 'FTA', 'TS%', 'Player_USG_Proxy'] # Use the calculated features\n",
    "    ewma_spans = [3, 5] # Spans for EWMA\n",
    "    \n",
    "    for col in cols_for_ewma:\n",
    "        if col in processed_df.columns:\n",
    "            # Ensure column is numeric before EWMA calculation\n",
    "            processed_df[col] = pd.to_numeric(processed_df[col], errors='coerce').fillna(0)\n",
    "            \n",
    "            for span in ewma_spans:\n",
    "                # Calculate EWMA and shift by 1 to get previous game's average\n",
    "                # Using adjust=False provides a more stable weighting for time series\n",
    "                processed_df[f'{col}_EWMA_{span}'] = processed_df.groupby('Player_ID')[col].transform(\n",
    "                    lambda x: x.ewm(span=span, adjust=False).mean().shift(1)\n",
    "                )\n",
    "        else:\n",
    "            print(f\"Warning: Column '{col}' not found for EWMA calculation.\")\n",
    "\n",
    "    print(\"Calculated EWMA features.\")\n",
    "\n",
    "    # Cumulative Season Averages (Shifted) - Keep these for long-term context\n",
    "    # Ensure required columns exist before cumulative calculations\n",
    "    cum_avg_base_cols = ['PTS', 'MIN']\n",
    "    cum_avg_usg_ts_cols = ['FGA', 'FTA', 'TOV'] # Needed for Avg_TS/USG_Season\n",
    "\n",
    "    # Check if base columns exist\n",
    "    if all(col in processed_df.columns for col in cum_avg_base_cols):\n",
    "        processed_df['Cum_PTS'] = processed_df.groupby('Player_ID')['PTS'].transform(lambda x: x.expanding().sum().shift(1))\n",
    "        processed_df['Cum_MIN'] = processed_df.groupby('Player_ID')['MIN'].transform(lambda x: x.expanding().sum().shift(1))\n",
    "        processed_df['Cum_Games'] = processed_df.groupby('Player_ID').cumcount() \n",
    "\n",
    "        processed_df['Avg_PTS_Season'] = (processed_df['Cum_PTS'] / processed_df['Cum_Games']).replace([np.inf, -np.inf, np.nan], 0)\n",
    "        processed_df['PTS_Per36_Season'] = (processed_df['Cum_PTS'] / processed_df['Cum_MIN'] * 36).replace([np.inf, -np.inf, np.nan], 0)\n",
    "        print(\"Calculated base cumulative averages.\")\n",
    "    else:\n",
    "         missing_base_cum = [col for col in cum_avg_base_cols if col not in processed_df.columns]\n",
    "         print(f\"Warning: One or more columns ({missing_base_cum}) missing for base cumulative average calculation.\")\n",
    "\n",
    "    # Check if USG/TS columns exist for their cumulative averages\n",
    "    if all(col in processed_df.columns for col in cum_avg_usg_ts_cols):\n",
    "         # Need Cum_PTS, Cum_FGA, Cum_FTA, Cum_TOV, Cum_MIN\n",
    "        if 'Cum_PTS' not in processed_df.columns:\n",
    "             processed_df['Cum_PTS'] = processed_df.groupby('Player_ID')['PTS'].transform(lambda x: x.expanding().sum().shift(1)).fillna(0)\n",
    "        if 'Cum_MIN' not in processed_df.columns:\n",
    "             processed_df['Cum_MIN'] = processed_df.groupby('Player_ID')['MIN'].transform(lambda x: x.expanding().sum().shift(1)).fillna(0)\n",
    "             \n",
    "        processed_df['Cum_FGA'] = processed_df.groupby('Player_ID')['FGA'].transform(lambda x: x.expanding().sum().shift(1)).fillna(0)\n",
    "        processed_df['Cum_FTA'] = processed_df.groupby('Player_ID')['FTA'].transform(lambda x: x.expanding().sum().shift(1)).fillna(0)\n",
    "        processed_df['Cum_TOV'] = processed_df.groupby('Player_ID')['TOV'].transform(lambda x: x.expanding().sum().shift(1)).fillna(0)\n",
    "        \n",
    "        # Cumulative TS% calculation\n",
    "        cum_ts_denominator = 2 * (processed_df['Cum_FGA'] + 0.44 * processed_df['Cum_FTA'])\n",
    "        processed_df['Avg_TS%_Season'] = np.where(cum_ts_denominator == 0, 0, processed_df['Cum_PTS'] / cum_ts_denominator)\n",
    "        processed_df['Avg_TS%_Season'].fillna(0, inplace=True)\n",
    "        processed_df['Avg_TS%_Season'].replace([np.inf, -np.inf], 0, inplace=True)\n",
    "        \n",
    "        # Cumulative USG% Proxy calculation\n",
    "        # Use Cumulative FGA, FTA, TOV from player, but need Cumulative Team MIN and Team stats for proper USG%\n",
    "        # Sticking to simplified proxy with player MIN cum_usg_denominator = processed_df['Cum_MIN'] \n",
    "        cum_usg_numerator = processed_df['Cum_FGA'] + 0.44 * processed_df['Cum_FTA'] + processed_df['Cum_TOV']\n",
    "        cum_usg_denominator = processed_df['Cum_MIN'] \n",
    "        processed_df['Avg_USG%_Proxy_Season'] = np.where(cum_usg_denominator == 0, 0, cum_usg_numerator / cum_usg_denominator)\n",
    "        processed_df['Avg_USG%_Proxy_Season'].fillna(0, inplace=True)\n",
    "        processed_df['Avg_USG%_Proxy_Season'].replace([np.inf, -np.inf], 0, inplace=True)\n",
    "        \n",
    "        print(\"Calculated cumulative averages for TS% and USG% Proxy.\")\n",
    "    else:\n",
    "         missing_usg_ts_cum = [col for col in cum_avg_usg_ts_cols if col not in processed_df.columns]\n",
    "         print(f\"Warning: One or more columns ({missing_usg_ts_cum}) missing for TS/USG cumulative average calculation.\")\n",
    "\n",
    "    # Other Features\n",
    "    if 'Home_Away' in processed_df.columns:\n",
    "        processed_df['Is_Home'] = processed_df['Home_Away'].apply(lambda x: 1 if x == 'Home' else 0)\n",
    "    else:\n",
    "        processed_df['Is_Home'] = 0 # Default if Home_Away is missing\n",
    "\n",
    "    # Merge Opponent Stats (DEF_RATING and PACE)\n",
    "    # Use fallback values if team_stats_df is empty (due to fetch error)\n",
    "    DEFAULT_DEF_RATING = 115.0 \n",
    "    DEFAULT_PACE = 100.0\n",
    "\n",
    "    if 'team_stats_df' in locals() and not team_stats_df.empty and 'TEAM_ABBREVIATION' in team_stats_df.columns and 'Opponent' in processed_df.columns:\n",
    "        print(\"Merging fetched team defensive stats and pace...\")\n",
    "        team_stats_to_merge = team_stats_df.rename(columns={\n",
    "            'TEAM_ABBREVIATION': 'Opponent',\n",
    "            'DEF_RATING': 'Opponent_DEF_RATING',\n",
    "            'PACE': 'Opponent_PACE'\n",
    "        })\n",
    "        \n",
    "        # Ensure 'Opponent' column type alignment\n",
    "        try:\n",
    "            processed_df['Opponent'] = processed_df['Opponent'].astype(team_stats_to_merge['Opponent'].dtype)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not align Opponent column types for merge: {e}\")\n",
    "            \n",
    "        # Merge only the required columns from team_stats_to_merge\n",
    "        merge_cols = ['Opponent']\n",
    "        if 'Opponent_DEF_RATING' in team_stats_to_merge.columns: merge_cols.append('Opponent_DEF_RATING')\n",
    "        if 'Opponent_PACE' in team_stats_to_merge.columns: merge_cols.append('Opponent_PACE')\n",
    "\n",
    "        if len(merge_cols) > 1:\n",
    "            processed_df = pd.merge(processed_df, team_stats_to_merge[merge_cols], on='Opponent', how='left')\n",
    "            \n",
    "            # Handle NaNs after merge\n",
    "            if 'Opponent_DEF_RATING' in processed_df.columns:\n",
    "                 processed_df['Opponent_DEF_RATING'] = pd.to_numeric(processed_df['Opponent_DEF_RATING'], errors='coerce')\n",
    "                 avg_def_rating = processed_df['Opponent_DEF_RATING'].mean()\n",
    "                 fill_value_def = avg_def_rating if not pd.isna(avg_def_rating) else DEFAULT_DEF_RATING\n",
    "                 processed_df['Opponent_DEF_RATING'].fillna(fill_value_def, inplace=True)\n",
    "                 print(f\"Opponent DEF_RATING merged. Filled NaNs with {fill_value_def:.1f}.\")\n",
    "            else:\n",
    "                 print(\"Warning: 'Opponent_DEF_RATING' column not created after merge. Using default.\")\n",
    "                 processed_df['Opponent_DEF_RATING'] = DEFAULT_DEF_RATING\n",
    "\n",
    "            if 'Opponent_PACE' in processed_df.columns:\n",
    "                 processed_df['Opponent_PACE'] = pd.to_numeric(processed_df['Opponent_PACE'], errors='coerce')\n",
    "                 avg_pace = processed_df['Opponent_PACE'].mean()\n",
    "                 fill_value_pace = avg_pace if not pd.isna(avg_pace) else DEFAULT_PACE\n",
    "                 processed_df['Opponent_PACE'].fillna(fill_value_pace, inplace=True)\n",
    "                 print(f\"Opponent PACE merged. Filled NaNs with {fill_value_pace:.1f}.\")\n",
    "            else:\n",
    "                 print(\"Warning: 'Opponent_PACE' column not created after merge. Using default.\")\n",
    "                 processed_df['Opponent_PACE'] = DEFAULT_PACE\n",
    "\n",
    "        else:\n",
    "             print(\"Warning: No relevant team stats columns found for merging.\")\n",
    "             processed_df['Opponent_DEF_RATING'] = DEFAULT_DEF_RATING\n",
    "             processed_df['Opponent_PACE'] = DEFAULT_PACE\n",
    "\n",
    "    else:\n",
    "        print(f\"Warning: Team stats not available or Opponent column missing. Using default DEF_RATING ({DEFAULT_DEF_RATING}) and PACE ({DEFAULT_PACE}).\")\n",
    "        processed_df['Opponent_DEF_RATING'] = DEFAULT_DEF_RATING\n",
    "        processed_df['Opponent_PACE'] = DEFAULT_PACE\n",
    "\n",
    "    # Final Fill NA for all engineered features (EWMA, cumulative, boolean, opponent)\n",
    "    # Identify all potential feature columns created dynamically\n",
    "    engineered_cols = [col for col in processed_df.columns \n",
    "                       if '_EWMA_' in col \n",
    "                       or '_Roll_' in col # Keep roll for now if EWMA fails, or remove if EWMA is primary\n",
    "                       or '_Season' in col \n",
    "                       or col in ['Is_Home', 'Opponent_DEF_RATING', 'Opponent_PACE', 'Rest_Days', 'Is_B2B_Second_Night']]\n",
    "    \n",
    "    # Filter to only columns that actually exist in the DataFrame\n",
    "    existing_engineered_cols = [col for col in engineered_cols if col in processed_df.columns]\n",
    "    \n",
    "    # Fill NaNs created by shifting/EWMA at the beginning of a player's season\n",
    "    if existing_engineered_cols:\n",
    "        processed_df[existing_engineered_cols] = processed_df[existing_engineered_cols].fillna(0)\n",
    "        print(f\"Filled NaNs in engineered features: {existing_engineered_cols}\")\n",
    "    else:\n",
    "        print(\"No engineered features found to fill NaNs.\")\n",
    "\n",
    "    print(\"Feature Engineering complete.\")\n",
    "    print(processed_df.head(10))\n",
    "else:\n",
    "    print(\"Skipping Feature Engineering because 'processed_df' is not available or empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for modeling...\n",
      "Features selected for modeling: ['PTS_EWMA_3', 'PTS_EWMA_5', 'MIN_EWMA_3', 'MIN_EWMA_5', 'FGA_EWMA_3', 'FGA_EWMA_5', 'FTA_EWMA_3', 'FTA_EWMA_5', 'TS%_EWMA_3', 'TS%_EWMA_5', 'Player_USG_Proxy_EWMA_3', 'Player_USG_Proxy_EWMA_5', 'Avg_PTS_Season', 'PTS_Per36_Season', 'Avg_TS%_Season', 'Avg_USG%_Proxy_Season', 'Opponent_DEF_RATING', 'Opponent_PACE', 'Rest_Days', 'Is_B2B_Second_Night', 'Is_Home']\n",
      "Applying log1p transformation to target variable 'PTS'.\n",
      "Data prepared for modeling (target transformed). Training set size: 4154, Testing set size: 1039\n",
      "Original Min/Max PTS in Test Set: 0/41\n",
      "Transformed Min/Max PTS in Test Set: 0.0000/3.7377\n"
     ]
    }
   ],
   "source": [
    "# --- Prepare Data for Modeling ---\n",
    "\n",
    "# Check if processed_df exists and is not empty\n",
    "if 'processed_df' in locals() and not processed_df.empty:\n",
    "    print(\"Preparing data for modeling...\")\n",
    "    \n",
    "    # Define required columns based on features engineered\n",
    "    # Prefer EWMA over simple rolling if both exist\n",
    "    feature_candidates = [\n",
    "        'PTS_EWMA_3', 'PTS_EWMA_5',\n",
    "        'MIN_EWMA_3', 'MIN_EWMA_5',\n",
    "        'FGA_EWMA_3', 'FGA_EWMA_5',\n",
    "        'FTA_EWMA_3', 'FTA_EWMA_5',\n",
    "        'TS%_EWMA_3', 'TS%_EWMA_5',\n",
    "        'Player_USG_Proxy_EWMA_3', 'Player_USG_Proxy_EWMA_5',\n",
    "        'Avg_PTS_Season', 'PTS_Per36_Season', 'Avg_TS%_Season', 'Avg_USG%_Proxy_Season',\n",
    "        'Opponent_DEF_RATING', 'Opponent_PACE',\n",
    "        'Rest_Days', 'Is_B2B_Second_Night', 'Is_Home'\n",
    "    ]\n",
    "    \n",
    "    # Filter to only columns that actually exist in processed_df\n",
    "    features = [col for col in feature_candidates if col in processed_df.columns]\n",
    "    \n",
    "    # Add simple rolling average fallbacks if EWMA was not created\n",
    "    fallback_features = [\n",
    "        'PTS_Roll_3', 'PTS_Roll_5',\n",
    "        'MIN_Roll_3', 'MIN_Roll_5',\n",
    "        'FGA_Roll_3', 'FGA_Roll_5',\n",
    "        'FTA_Roll_3', 'FTA_Roll_5',\n",
    "        'TS%_Roll_3', 'TS%_Roll_5',\n",
    "        'Player_USG_Proxy_Roll_3', 'Player_USG_Proxy_Roll_5'\n",
    "    ]\n",
    "    for fb_col in fallback_features:\n",
    "        # Add the fallback if the EWMA equivalent is NOT in features AND the fallback exists\n",
    "        ewma_equiv = fb_col.replace('_Roll_', '_EWMA_')\n",
    "        if fb_col in processed_df.columns and ewma_equiv not in features and fb_col not in features:\n",
    "             features.append(fb_col)\n",
    "             \n",
    "    print(f\"Features selected for modeling: {features}\")\n",
    "\n",
    "    # Define target variable\n",
    "    target = 'PTS'\n",
    "    \n",
    "    if target not in processed_df.columns:\n",
    "        print(f\"Error: Target variable '{target}' not found in processed_df. Cannot proceed with modeling.\")\n",
    "        model_df = pd.DataFrame()\n",
    "        X_train, X_test, y_train, y_test, y_test_original = [None]*5\n",
    "    else:\n",
    "        # Drop rows where target or any selected feature is missing\n",
    "        # NaNs in engineered features should be handled by fillna(0) in Feature Engineering, \n",
    "        # so this mainly catches NaNs in original columns used in features if any slipped through.\n",
    "        subset_for_dropna = [target] + features\n",
    "        # Filter to only columns actually present before dropping\n",
    "        actual_subset_for_dropna = [col for col in subset_for_dropna if col in processed_df.columns]\n",
    "        \n",
    "        model_df = processed_df.dropna(subset=actual_subset_for_dropna).copy()\n",
    "\n",
    "        # Check if enough data remains\n",
    "        if model_df.empty or len(model_df) < 10: # Arbitrary threshold for minimum data\n",
    "            print(\"Not enough data with required features and target to build a model.\")\n",
    "            X_train, X_test, y_train, y_test, y_test_original = [None]*5 \n",
    "        else:\n",
    "            X = model_df[features]\n",
    "            y = model_df[target]\n",
    "            \n",
    "            # Check for NaN/inf in features or target before split\n",
    "            # This should ideally not be needed if fillna(0) worked, but as a safeguard:\n",
    "            if X.isnull().values.any() or y.isnull().values.any() or np.isinf(X.values).any() or np.isinf(y.values).any():\n",
    "                 print(\"Warning: NaN or Inf values detected in features or target before train/test split. Attempting to fill with 0.\")\n",
    "                 X = X.fillna(0)\n",
    "                 y = y.fillna(0)\n",
    "                 X = X.replace([np.inf, -np.inf], 0)\n",
    "                 y = y.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "            # Split data - using shuffle=True is generally okay for regressions unless temporal order is strictly required\n",
    "            # For player game logs, sorting then splitting can sometimes be useful if players consistently improve/decline over the season\n",
    "            # But train_test_split with shuffle is standard practice unless there's a specific time-series forecasting need.\n",
    "            # Let's keep shuffle=True for now as per original code, but be aware of TimeSeriesSplit for CV.\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "            \n",
    "            # Store original y_test before transformation\n",
    "            y_test_original = y_test.copy()\n",
    "\n",
    "            # Apply Target Transformation (log1p)\n",
    "            # Add a small constant (like 1) before log to handle 0 points if necessary\n",
    "            # np.log1p(x) is equivalent to log(x + 1) and handles small numbers better\n",
    "            print(f\"Applying log1p transformation to target variable '{target}'.\")\n",
    "            y_train = np.log1p(y_train)\n",
    "            y_test = np.log1p(y_test)\n",
    "            \n",
    "            print(f\"Data prepared for modeling (target transformed). Training set size: {X_train.shape[0]}, Testing set size: {X_test.shape[0]}\")\n",
    "            print(f\"Original Min/Max PTS in Test Set: {y_test_original.min()}/{y_test_original.max()}\")\n",
    "            print(f\"Transformed Min/Max PTS in Test Set: {y_test.min():.4f}/{y_test.max():.4f}\")\n",
    "\n",
    "else:\n",
    "    print(\"Skipping Data Preparation for Modeling because 'processed_df' is not available or empty.\")\n",
    "    X_train, X_test, y_train, y_test, y_test_original = [None]*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Avg_PTS_Season Distribution (Training Data) ---\n",
      "count    4154.000000\n",
      "mean       10.170649\n",
      "std         6.542242\n",
      "min         0.000000\n",
      "25%         5.050321\n",
      "50%         9.000000\n",
      "75%        14.041954\n",
      "max        36.000000\n",
      "Name: Avg_PTS_Season, dtype: float64\n",
      "\n",
      "--- Sample Counts for Potential Thresholds (Training Data) ---\n",
      "Players >= 12 PPG: 1531 (36.9%)\n",
      "Players >= 15 PPG: 942 (22.7%)\n",
      "Players >= 18 PPG: 583 (14.0%)\n",
      "\n",
      "Using threshold: Avg_PTS_Season >= 15\n",
      "\n",
      "--- Data Segmentation Complete ---\n",
      "Scorers - Train: 942, Test: 236\n",
      "Role Players - Train: 3212, Test: 803\n"
     ]
    }
   ],
   "source": [
    "# --- Analyze Distribution and Segment Data ---\n",
    "\n",
    "# Check if X_train and y_test_original exist and are not None\n",
    "if 'X_train' in locals() and X_train is not None and 'y_test_original' in locals() and y_test_original is not None:\n",
    "    print(\"--- Avg_PTS_Season Distribution (Training Data) ---\")\n",
    "    # Use the original Avg_PTS_Season from X_train which was not log-transformed\n",
    "    if 'Avg_PTS_Season' in X_train.columns:\n",
    "        print(X_train['Avg_PTS_Season'].describe())\n",
    "        \n",
    "        print(\"\\n--- Sample Counts for Potential Thresholds (Training Data) ---\")\n",
    "        for threshold in [12, 15, 18]:\n",
    "            count = (X_train['Avg_PTS_Season'] >= threshold).sum()\n",
    "            print(f\"Players >= {threshold} PPG: {count} ({(count / len(X_train) * 100):.1f}%)\")\n",
    "            \n",
    "        # Define the chosen threshold (using the same threshold as before)\n",
    "        scorer_threshold = 15\n",
    "        print(f\"\\nUsing threshold: Avg_PTS_Season >= {scorer_threshold}\")\n",
    "        \n",
    "        # Create segmentation masks for TRAIN and TEST sets\n",
    "        # Masks are based on the ORIGINAL (untransformed) Avg_PTS_Season feature\n",
    "        train_scorer_mask = X_train['Avg_PTS_Season'] >= scorer_threshold\n",
    "        test_scorer_mask = X_test['Avg_PTS_Season'] >= scorer_threshold # Use X_test for the mask\n",
    "        \n",
    "        # Segment Training Data (X is features, y is TRANSFORMED target)\n",
    "        X_train_scorers = X_train[train_scorer_mask]\n",
    "        y_train_scorers = y_train[train_scorer_mask]\n",
    "        X_train_role = X_train[~train_scorer_mask]\n",
    "        y_train_role = y_train[~train_scorer_mask]\n",
    "        \n",
    "        # Segment Testing Data (X is features, y is TRANSFORMED target, y_original is ORIGINAL target)\n",
    "        X_test_scorers = X_test[test_scorer_mask]\n",
    "        y_test_scorers = y_test[test_scorer_mask]\n",
    "        y_test_scorers_original = y_test_original[test_scorer_mask] # Segment original target too\n",
    "\n",
    "        X_test_role = X_test[~test_scorer_mask]\n",
    "        y_test_role = y_test[~test_scorer_mask]\n",
    "        y_test_role_original = y_test_original[~test_scorer_mask] # Segment original target too\n",
    "        \n",
    "        print(\"\\n--- Data Segmentation Complete ---\")\n",
    "        print(f\"Scorers - Train: {len(X_train_scorers)}, Test: {len(X_test_scorers)}\")\n",
    "        print(f\"Role Players - Train: {len(X_train_role)}, Test: {len(X_test_role)}\")\n",
    "        \n",
    "        # Store segment masks for later combined evaluation\n",
    "        # These masks are based on the test set from this cell\n",
    "        # (Ensure X_test used here is the same X_test used in prepare data)\n",
    "        test_scorer_mask_global = test_scorer_mask\n",
    "        test_role_mask_global = ~test_scorer_mask\n",
    "\n",
    "    else:\n",
    "        print(\"Warning: 'Avg_PTS_Season' not found in X_train. Skipping segmentation.\")\n",
    "        # Ensure segmented variables are None if segmentation is skipped\n",
    "        X_train_scorers, y_train_scorers, X_test_scorers, y_test_scorers, y_test_scorers_original = [None]*5\n",
    "        X_train_role, y_train_role, X_test_role, y_test_role, y_test_role_original = [None]*5\n",
    "        test_scorer_mask_global = None\n",
    "        test_role_mask_global = None\n",
    "\n",
    "else:\n",
    "    print(\"Skipping segmentation as training data or original test target is not available.\")\n",
    "    # Ensure segmented variables are None if segmentation is skipped\n",
    "    X_train_scorers, y_train_scorers, X_test_scorers, y_test_scorers, y_test_scorers_original = [None]*5\n",
    "    X_train_role, y_train_role, X_test_role, y_test_role, y_test_role_original = [None]*5\n",
    "    test_scorer_mask_global = None\n",
    "    test_role_mask_global = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Evaluation Function (Modified for Transformed Target) ---\n",
    "\n",
    "def evaluate_model(model, X_test, y_test_transformed, y_test_original, model_name, X_train_cols=None):\n",
    "    \"\"\"Calculates and prints evaluation metrics for a given model, handling transformed targets.\"\"\"\n",
    "    print(f\"\\n--- {model_name} Evaluation ---\")\n",
    "    \n",
    "    if model is None or X_test is None or y_test_original is None or X_test.empty:\n",
    "        print(f\"Skipping {model_name} evaluation as model was not trained or test data was missing.\")\n",
    "        return\n",
    "        \n",
    "    try:\n",
    "        # Predict on the transformed scale\n",
    "        y_pred_transformed = model.predict(X_test)\n",
    "\n",
    "        # Transform predictions back to the original scale\n",
    "        y_pred_original = np.expm1(y_pred_transformed)\n",
    "        \n",
    "        # Handle potential negative predictions after inverse transform (shouldn't happen with log1p/expm1 on non-negative targets)\n",
    "        y_pred_original[y_pred_original < 0] = 0 \n",
    "\n",
    "        # --- Basic Error Analysis (using original scale) ---\n",
    "        # Create a temporary DataFrame for analysis if X_test has an index matching y_test_original\n",
    "        # Ensure X_test_results includes the original target and predicted values\n",
    "        if X_test.index.equals(y_test_original.index):\n",
    "             X_test_results = X_test.copy()\n",
    "             X_test_results['Actual_PTS'] = y_test_original\n",
    "             X_test_results['Predicted_PTS'] = y_pred_original\n",
    "             X_test_results['Error'] = X_test_results['Actual_PTS'] - X_test_results['Predicted_PTS']\n",
    "             X_test_results['Abs_Error'] = np.abs(X_test_results['Error'])\n",
    "        else:\n",
    "             # Fallback if indices don't match (e.g., after some filtering/segmentation issues)\n",
    "             print(\"Warning: X_test index does not match y_test_original index. Skipping detailed error analysis table.\")\n",
    "             X_test_results = pd.DataFrame({'Actual_PTS': y_test_original, 'Predicted_PTS': y_pred_original})\n",
    "             X_test_results['Error'] = X_test_results['Actual_PTS'] - X_test_results['Predicted_PTS']\n",
    "             X_test_results['Abs_Error'] = np.abs(X_test_results['Error'])\n",
    "\n",
    "        # --- Calculate Metrics (using original scale) ---\n",
    "        mae = mean_absolute_error(y_test_original, y_pred_original)\n",
    "        mse = mean_squared_error(y_test_original, y_pred_original) \n",
    "        rmse = np.sqrt(mse) \n",
    "        \n",
    "        # Filter out zero actual values for MAPE calculation\n",
    "        non_zero_mask = y_test_original != 0\n",
    "        if np.any(non_zero_mask):\n",
    "            mape = mean_absolute_percentage_error(y_test_original[non_zero_mask], y_pred_original[non_zero_mask])\n",
    "            mape_note = f\"(excluding { (~non_zero_mask).sum() } games with 0 actual points)\"\n",
    "        else:\n",
    "            mape = np.nan # Or some other indicator that MAPE couldn't be calculated\n",
    "            mape_note = \"(MAPE not calculable as all actual points were 0)\"\n",
    "        \n",
    "        # Calculate % within +/- 3 points\n",
    "        within_3_pts = X_test_results['Abs_Error'] <= 3\n",
    "        within_3_pts_accuracy = within_3_pts.mean() * 100\n",
    "        \n",
    "        # --- Print Metrics ---\n",
    "        print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "        print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\") \n",
    "        print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2%} {mape_note}\")\n",
    "        print(f\"Accuracy (within +/- 3 points): {within_3_pts_accuracy:.2f}%\")\n",
    "        \n",
    "        # --- Print Sample Predictions and Errors ---\n",
    "        print(f\"\\nSample Predictions vs Actual ({model_name}):\")\n",
    "        print(X_test_results.head())\n",
    "        \n",
    "        print(\"\\nLargest Errors (Top 5):\")\n",
    "        print(X_test_results.sort_values(by='Abs_Error', ascending=False).head())\n",
    "        \n",
    "        # Optional: Feature Importances (Specific to tree-based models)\n",
    "        if hasattr(model, 'feature_importances_') and X_train_cols is not None:\n",
    "            print(f\"\\nFeature Importances ({model_name}):\")\n",
    "            # Ensure columns match in case of index misalignment\n",
    "            importance_features = X_train_cols if isinstance(X_train_cols, pd.Index) else pd.Index(X_train_cols) # Ensure index type\n",
    "            \n",
    "            # Check if the number of features matches importances\n",
    "            if len(importance_features) == len(model.feature_importances_):\n",
    "                importances = pd.DataFrame({\n",
    "                    'Feature': importance_features,\n",
    "                    'Importance': model.feature_importances_\n",
    "                }).sort_values(by='Importance', ascending=False)\n",
    "                print(importances)\n",
    "            else:\n",
    "                print(\"Warning: Feature count mismatch between X_train_cols and model importances. Cannot display importances.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during {model_name} evaluation: {e}\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function to Train, Evaluate, and Save Models for a Segment ---\n",
    "\n",
    "def train_evaluate_segment(X_train_seg, y_train_seg_transformed, X_test_seg, y_test_seg_original, segment_label):\n",
    "    \"\"\"Tunes, trains, evaluates, and saves Ridge, XGBoost, and LightGBM models for a data segment.\"\"\"\n",
    "    print(f\"\\n{'='*20} Processing Segment: {segment_label} {'='*20}\")\n",
    "    \n",
    "    # Check if data is sufficient\n",
    "    if X_train_seg is None or y_train_seg_transformed is None or X_train_seg.empty or len(X_train_seg) < 10: # Min threshold\n",
    "        print(f\"Skipping {segment_label} segment due to insufficient training data ({len(X_train_seg) if X_train_seg is not None else 0} samples).\")\n",
    "        return None, None, None\n",
    "        \n",
    "    model_ridge_seg = None\n",
    "    model_xgb_seg = None\n",
    "    model_lgbm_seg = None\n",
    "    \n",
    "    # --- Ridge --- \n",
    "    print(f\"\\n--- Tuning Ridge Regression Model ({segment_label}) ---\")\n",
    "    param_grid_ridge = {'alpha': [0.1, 1.0, 10.0, 100.0]}\n",
    "    ridge_estimator = Ridge()\n",
    "    # Using TimeSeriesSplit for more appropriate CV on time-series data\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    grid_search_ridge = GridSearchCV(ridge_estimator, param_grid_ridge, cv=tscv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "    try:\n",
    "        grid_search_ridge.fit(X_train_seg, y_train_seg_transformed)\n",
    "        model_ridge_seg = grid_search_ridge.best_estimator_\n",
    "        print(f\"Best alpha found for Ridge ({segment_label}): {grid_search_ridge.best_params_['alpha']}\")\n",
    "        print(f\"Tuned Ridge Regression Model training complete ({segment_label}).\")\n",
    "        joblib.dump(model_ridge_seg, f'models/ridge_model_{segment_label.lower().replace(\" \", \"_\")}.pkl')\n",
    "        print(f\"Ridge model saved for {segment_label}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Ridge GridSearchCV ({segment_label}): {e}\")\n",
    "        traceback.print_exc()\n",
    "        model_ridge_seg = None\n",
    "        \n",
    "    # Evaluate Ridge\n",
    "    evaluate_model(model_ridge_seg, X_test_seg, y_test_seg_original, y_test_seg_original, f\"Tuned Ridge ({segment_label})\") # Note: y_test_original passed twice, function uses only the first and last\n",
    "    \n",
    "    # --- XGBoost ---\n",
    "    print(f\"\\n--- Tuning XGBoost Model ({segment_label}) ---\")\n",
    "    param_grid_xgb = {\n",
    "        'n_estimators': [100, 200], \n",
    "        'max_depth': [3, 5],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'subsample': [0.8, 1.0], # Adjusted subsample range\n",
    "        'colsample_bytree': [0.8, 1.0], # Adjusted colsample range\n",
    "        'reg_alpha': [0, 0.1],\n",
    "        'reg_lambda': [1.0]\n",
    "    }\n",
    "    # Smaller grid for segments for faster tuning\n",
    "    if len(X_train_seg) > 500: # Use slightly larger grid for larger segments\n",
    "        param_grid_xgb['n_estimators'] = [100, 200, 300]\n",
    "        param_grid_xgb['max_depth'] = [3, 5, 7]\n",
    "        param_grid_xgb['learning_rate'] = [0.01, 0.05, 0.1]\n",
    "        param_grid_xgb['subsample'] = [0.7, 0.8, 0.9, 1.0]\n",
    "        param_grid_xgb['colsample_bytree'] = [0.7, 0.8, 0.9, 1.0]\n",
    "        param_grid_xgb['reg_alpha'] = [0, 0.1, 0.5]\n",
    "        param_grid_xgb['reg_lambda'] = [0.5, 1.0, 1.5]\n",
    "\n",
    "    xgb_estimator = XGBRegressor(random_state=42, objective='reg:squarederror', tree_method='hist') # Use hist for faster training if available\n",
    "    # Using TimeSeriesSplit for CV\n",
    "    grid_search_xgb = GridSearchCV(\n",
    "        estimator=xgb_estimator,\n",
    "        param_grid=param_grid_xgb,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=tscv,\n",
    "        n_jobs=-1,\n",
    "        verbose=0 \n",
    "    )\n",
    "    try:\n",
    "        print(f\"Starting XGBoost GridSearchCV ({segment_label})...\")\n",
    "        grid_search_xgb.fit(X_train_seg, y_train_seg_transformed)\n",
    "        model_xgb_seg = grid_search_xgb.best_estimator_\n",
    "        print(f\"Best parameters found for XGBoost ({segment_label}): {grid_search_xgb.best_params_}\")\n",
    "        print(f\"Best MAE score during CV ({segment_label}): {-grid_search_xgb.best_score_:.2f}\")\n",
    "        print(f\"Tuned XGBoost Model training complete ({segment_label}).\")\n",
    "        joblib.dump(model_xgb_seg, f'models/xgb_model_{segment_label.lower().replace(\" \", \"_\")}.pkl')\n",
    "        print(f\"XGBoost model saved for {segment_label}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during XGBoost GridSearchCV ({segment_label}): {e}\")\n",
    "        traceback.print_exc()\n",
    "        model_xgb_seg = None\n",
    "        \n",
    "    # Evaluate XGBoost\n",
    "    evaluate_model(model_xgb_seg, X_test_seg, y_test_seg_original, y_test_seg_original, f\"Tuned XGBoost ({segment_label})\", X_train_cols=X_train_seg.columns)\n",
    "    \n",
    "    # --- LightGBM ---\n",
    "    print(f\"\\n--- Tuning LightGBM Model ({segment_label}) ---\")\n",
    "    param_grid_lgbm = {\n",
    "        'n_estimators': [100, 200], \n",
    "        'max_depth': [3, 5],\n",
    "        'learning_rate': [0.05, 0.1],\n",
    "        'subsample': [0.8, 1.0], \n",
    "        'colsample_bytree': [0.8, 1.0],\n",
    "        'reg_alpha': [0, 0.1],\n",
    "        'reg_lambda': [1.0]\n",
    "    }\n",
    "     # Smaller grid for segments for faster tuning\n",
    "    if len(X_train_seg) > 500: # Use slightly larger grid for larger segments\n",
    "        param_grid_lgbm['n_estimators'] = [100, 200, 300]\n",
    "        param_grid_lgbm['max_depth'] = [3, 5, 7]\n",
    "        param_grid_lgbm['learning_rate'] = [0.01, 0.05, 0.1]\n",
    "        param_grid_lgbm['subsample'] = [0.7, 0.8, 0.9, 1.0]\n",
    "        param_grid_lgbm['colsample_bytree'] = [0.7, 0.8, 0.9, 1.0]\n",
    "        param_grid_lgbm['reg_alpha'] = [0, 0.1, 0.5]\n",
    "        param_grid_lgbm['reg_lambda'] = [0.5, 1.0, 1.5]\n",
    "\n",
    "    lgbm_estimator = lgb.LGBMRegressor(random_state=42, objective='regression_l2') # regression_l2 is MSE, common for regression\n",
    "     # Using TimeSeriesSplit for CV\n",
    "    grid_search_lgbm = GridSearchCV(\n",
    "        estimator=lgbm_estimator,\n",
    "        param_grid=param_grid_lgbm,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=tscv,\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    try:\n",
    "        print(f\"Starting LightGBM GridSearchCV ({segment_label})...\")\n",
    "        grid_search_lgbm.fit(X_train_seg, y_train_seg_transformed)\n",
    "        model_lgbm_seg = grid_search_lgbm.best_estimator_\n",
    "        print(f\"Best parameters found for LightGBM ({segment_label}): {grid_search_lgbm.best_params_}\")\n",
    "        print(f\"Best MAE score during CV ({segment_label}): {-grid_search_lgbm.best_score_:.2f}\")\n",
    "        print(f\"Tuned LightGBM Model training complete ({segment_label}).\")\n",
    "        joblib.dump(model_lgbm_seg, f'models/lgbm_model_{segment_label.lower().replace(\" \", \"_\")}.pkl')\n",
    "        print(f\"LightGBM model saved for {segment_label}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during LightGBM GridSearchCV ({segment_label}): {e}\")\n",
    "        traceback.print_exc()\n",
    "        model_lgbm_seg = None\n",
    "        \n",
    "    # Evaluate LightGBM\n",
    "    evaluate_model(model_lgbm_seg, X_test_seg, y_test_seg_original, y_test_seg_original, f\"Tuned LightGBM ({segment_label})\", X_train_cols=X_train_seg.columns)\n",
    "    \n",
    "    print(f\"\\n{'='*20} Finished Segment: {segment_label} {'='*20}\")\n",
    "    return model_ridge_seg, model_xgb_seg, model_lgbm_seg # Return all trained models\n",
    "\n",
    "# Ensure segmented variables are initialized to None if segmentation didn't run\n",
    "if 'X_train_scorers' not in locals():\n",
    "     X_train_scorers, y_train_scorers, X_test_scorers, y_test_scorers, y_test_scorers_original = [None]*5\n",
    "     X_train_role, y_train_role, X_test_role, y_test_role, y_test_role_original = [None]*5\n",
    "     test_scorer_mask_global = None\n",
    "     test_role_mask_global = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " === BASELINE MODEL (ALL DATA) ===\n",
      "Tuning Ridge Regression Model (Baseline)...\n",
      "Best alpha found for Ridge (Baseline): 0.1\n",
      "Tuned Ridge Regression Model training complete (Baseline).\n",
      "Baseline Ridge model saved.\n"
     ]
    }
   ],
   "source": [
    "# --- Model Building & Tuning (Ridge Regression - Baseline) ---\n",
    "print(\"\\n === BASELINE MODEL (ALL DATA) ===\")\n",
    "model_ridge_baseline = None # Renamed to baseline for clarity\n",
    "if X_train is not None and y_train is not None and not X_train.empty:\n",
    "    print(\"Tuning Ridge Regression Model (Baseline)...\")\n",
    "    \n",
    "    param_grid_ridge = {'alpha': [0.01, 0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 20.0, 50.0, 100.0]}\n",
    "    \n",
    "    ridge_estimator = Ridge()\n",
    "    # Using TimeSeriesSplit for CV\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    grid_search_ridge = GridSearchCV(ridge_estimator, param_grid_ridge, cv=tscv, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "    \n",
    "    try:\n",
    "        grid_search_ridge.fit(X_train, y_train) # y_train is transformed\n",
    "        model_ridge_baseline = grid_search_ridge.best_estimator_\n",
    "        print(f\"Best alpha found for Ridge (Baseline): {grid_search_ridge.best_params_['alpha']}\")\n",
    "        print(\"Tuned Ridge Regression Model training complete (Baseline).\")\n",
    "        joblib.dump(model_ridge_baseline, 'models/ridge_model_baseline.pkl') # Save baseline\n",
    "        print(\"Baseline Ridge model saved.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during Ridge GridSearchCV (Baseline): {e}\")\n",
    "        traceback.print_exc()\n",
    "        model_ridge_baseline = None # Ensure model is None if fitting fails\n",
    "else:\n",
    "    print(\"Skipping Ridge tuning due to lack of training data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tuned Ridge (Baseline) Evaluation ---\n",
      "Mean Absolute Error (MAE): 4.49\n",
      "Root Mean Squared Error (RMSE): 6.21\n",
      "Mean Absolute Percentage Error (MAPE): 50.54% (excluding 124 games with 0 actual points)\n",
      "Accuracy (within +/- 3 points): 47.83%\n",
      "\n",
      "Sample Predictions vs Actual (Tuned Ridge (Baseline)):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "3547   23.676529   20.975582   28.929161   27.826426   15.221966   14.829648   \n",
      "79      6.844662    7.639454   24.766341   25.960291    4.449875    4.987941   \n",
      "4783    4.562500    3.493827    7.656250    5.930041    4.156250    3.385460   \n",
      "4443   19.162092   17.739835   33.952229   32.679759   15.879441   15.440207   \n",
      "4294    4.037598    2.903668    4.578857    4.678529    1.724854    1.471149   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "3547    4.193523    4.430613    0.666544    0.598865  ...   \n",
      "79      0.251961    0.425205    0.696893    0.670662  ...   \n",
      "4783    0.250000    0.222222    0.439741    0.353072  ...   \n",
      "4443    3.960343    3.490642    0.533357    0.511261  ...   \n",
      "4294    2.000977    1.342004    0.424272    0.307699  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "3547               0.724144           114.479344          100.0        2.0   \n",
      "79                 0.262287           110.800000          100.0        3.0   \n",
      "4783               0.658571           115.600000          100.0        3.0   \n",
      "4443               0.539512           112.100000          100.0        2.0   \n",
      "4294               0.314583           111.900000          100.0        2.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "3547                    0        0          20      19.422927   0.577073   \n",
      "79                      0        1           8       5.613845   2.386155   \n",
      "4783                    0        1           5       2.247907   2.752093   \n",
      "4443                    0        1          31      16.397144  14.602856   \n",
      "4294                    0        1           2       1.430573   0.569427   \n",
      "\n",
      "      Abs_Error  \n",
      "3547   0.577073  \n",
      "79     2.386155  \n",
      "4783   2.752093  \n",
      "4443  14.602856  \n",
      "4294   0.569427  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Largest Errors (Top 5):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "3351    5.085567    4.323508   11.885225   10.791931    6.162133    5.180699   \n",
      "3515    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "994    18.803643   18.261414   33.212858   31.483130   15.746948   15.113675   \n",
      "2815   32.652990   32.355369   36.093047   36.210829   23.198967   22.393976   \n",
      "274    17.472570   17.155900   25.289373   24.160526   13.042925   12.562827   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "3351    0.020020    0.092421    0.387462    0.352346  ...   \n",
      "3515    0.000000    0.000000    0.000000    0.000000  ...   \n",
      "994     2.213892    1.948465    0.572000    0.586764  ...   \n",
      "2815    7.648177    8.373909    0.615428    0.619183  ...   \n",
      "274     1.964038    2.494920    0.633671    0.634741  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "3351               0.540601                113.7          100.0        1.0   \n",
      "3515               0.000000                112.1          100.0        2.0   \n",
      "994                0.546760                112.3          100.0        3.0   \n",
      "2815               0.756377                110.8          100.0        2.0   \n",
      "274                0.562173                118.9          100.0        3.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "3351                    1        1          37       3.709875  33.290125   \n",
      "3515                    0        1          36       3.138017  32.861983   \n",
      "994                     0        1          40      15.203363  24.796637   \n",
      "2815                    0        0           6      29.415073 -23.415073   \n",
      "274                     0        0          34      10.675697  23.324303   \n",
      "\n",
      "      Abs_Error  \n",
      "3351  33.290125  \n",
      "3515  32.861983  \n",
      "994   24.796637  \n",
      "2815  23.415073  \n",
      "274   23.324303  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- Model Evaluation (Tuned Ridge Regression - Baseline) ---\n",
    "# Pass X_test (transformed features), y_test_original (original target) for evaluation\n",
    "if 'model_ridge_baseline' in locals() and model_ridge_baseline is not None:\n",
    "    evaluate_model(model_ridge_baseline, X_test, y_test, y_test_original, \"Tuned Ridge (Baseline)\") \n",
    "else:\n",
    "    print(\"Skipping Baseline Ridge evaluation as model was not trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tuning XGBoost Model (Baseline) ---\n",
      "Starting XGBoost GridSearchCV (this may take a while)...\n",
      "Fitting 5 folds for each of 3888 candidates, totalling 19440 fits\n",
      "\n",
      "Best parameters found for XGBoost (Baseline): {'colsample_bytree': 0.8, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100, 'reg_alpha': 0.5, 'reg_lambda': 1.5, 'subsample': 0.8}\n",
      "Best MAE score during CV (Baseline): 0.56\n",
      "Tuned XGBoost Model training complete (Baseline).\n",
      "Baseline XGBoost model saved.\n"
     ]
    }
   ],
   "source": [
    "# --- Model Building & Tuning (XGBoost - Baseline) ---\n",
    "model_xgb_baseline = None # Renamed to baseline\n",
    "if X_train is not None and y_train is not None and not X_train.empty:\n",
    "    print(\"\\n--- Tuning XGBoost Model (Baseline) ---\")\n",
    "    \n",
    "    # Define an expanded parameter grid for more thorough tuning\n",
    "    param_grid_xgb = {\n",
    "        'n_estimators': [100, 200, 300],       # More trees\n",
    "        'max_depth': [3, 5, 7],                # Deeper trees\n",
    "        'learning_rate': [0.01, 0.05, 0.1],    # Smaller learning rates\n",
    "        'subsample': [0.7, 0.8, 0.9, 1.0],          # Vary sample fraction\n",
    "        'colsample_bytree': [0.7, 0.8, 0.9, 1.0],   # Vary feature fraction\n",
    "        'reg_alpha': [0, 0.1, 0.5],            # L1 Regularization\n",
    "        'reg_lambda': [0.5, 1.0, 1.5]          # L2 Regularization\n",
    "    }\n",
    "    \n",
    "    xgb_estimator = XGBRegressor(random_state=42, objective='reg:squarederror', tree_method='hist') \n",
    "    \n",
    "    # Using TimeSeriesSplit for CV\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    grid_search_xgb = GridSearchCV(\n",
    "        estimator=xgb_estimator,\n",
    "        param_grid=param_grid_xgb,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=tscv,\n",
    "        n_jobs=-1,\n",
    "        verbose=1 # Print progress\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        print(\"Starting XGBoost GridSearchCV (this may take a while)...\")\n",
    "        grid_search_xgb.fit(X_train, y_train) # y_train is transformed\n",
    "        model_xgb_baseline = grid_search_xgb.best_estimator_\n",
    "        print(f\"\\nBest parameters found for XGBoost (Baseline): {grid_search_xgb.best_params_}\")\n",
    "        print(f\"Best MAE score during CV (Baseline): {-grid_search_xgb.best_score_:.2f}\") # Score is on transformed scale\n",
    "        print(\"Tuned XGBoost Model training complete (Baseline).\")\n",
    "        joblib.dump(model_xgb_baseline, 'models/xgb_model_baseline.pkl') # Save baseline\n",
    "        print(\"Baseline XGBoost model saved.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during XGBoost GridSearchCV (Baseline): {e}\")\n",
    "        traceback.print_exc()\n",
    "        model_xgb_baseline = None # Ensure model is None if fitting fails\n",
    "else:\n",
    "    print(\"Skipping XGBoost tuning due to lack of training data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tuned XGBoost (Baseline) Evaluation ---\n",
      "Mean Absolute Error (MAE): 4.42\n",
      "Root Mean Squared Error (RMSE): 6.02\n",
      "Mean Absolute Percentage Error (MAPE): 52.50% (excluding 124 games with 0 actual points)\n",
      "Accuracy (within +/- 3 points): 47.16%\n",
      "\n",
      "Sample Predictions vs Actual (Tuned XGBoost (Baseline)):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "3547   23.676529   20.975582   28.929161   27.826426   15.221966   14.829648   \n",
      "79      6.844662    7.639454   24.766341   25.960291    4.449875    4.987941   \n",
      "4783    4.562500    3.493827    7.656250    5.930041    4.156250    3.385460   \n",
      "4443   19.162092   17.739835   33.952229   32.679759   15.879441   15.440207   \n",
      "4294    4.037598    2.903668    4.578857    4.678529    1.724854    1.471149   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "3547    4.193523    4.430613    0.666544    0.598865  ...   \n",
      "79      0.251961    0.425205    0.696893    0.670662  ...   \n",
      "4783    0.250000    0.222222    0.439741    0.353072  ...   \n",
      "4443    3.960343    3.490642    0.533357    0.511261  ...   \n",
      "4294    2.000977    1.342004    0.424272    0.307699  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "3547               0.724144           114.479344          100.0        2.0   \n",
      "79                 0.262287           110.800000          100.0        3.0   \n",
      "4783               0.658571           115.600000          100.0        3.0   \n",
      "4443               0.539512           112.100000          100.0        2.0   \n",
      "4294               0.314583           111.900000          100.0        2.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "3547                    0        0          20      18.989670   1.010330   \n",
      "79                      0        1           8       4.572212   3.427788   \n",
      "4783                    0        1           5       2.510357   2.489643   \n",
      "4443                    0        1          31      17.050234  13.949766   \n",
      "4294                    0        1           2       1.408143   0.591857   \n",
      "\n",
      "      Abs_Error  \n",
      "3547   1.010330  \n",
      "79     3.427788  \n",
      "4783   2.489643  \n",
      "4443  13.949766  \n",
      "4294   0.591857  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Largest Errors (Top 5):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "3351    5.085567    4.323508   11.885225   10.791931    6.162133    5.180699   \n",
      "3515    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "994    18.803643   18.261414   33.212858   31.483130   15.746948   15.113675   \n",
      "3127   11.281489   12.193630   36.496559   36.644491   11.578104   11.825451   \n",
      "3978   11.941515   11.540890   30.229732   28.620777   12.119081   11.360942   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "3351    0.020020    0.092421    0.387462    0.352346  ...   \n",
      "3515    0.000000    0.000000    0.000000    0.000000  ...   \n",
      "994     2.213892    1.948465    0.572000    0.586764  ...   \n",
      "3127    2.579181    2.288440    0.431089    0.464978  ...   \n",
      "3978    2.315082    2.869619    0.406852    0.395331  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "3351               0.540601                113.7          100.0        1.0   \n",
      "3515               0.000000                112.1          100.0        2.0   \n",
      "994                0.546760                112.3          100.0        3.0   \n",
      "3127               0.379016                118.9          100.0        2.0   \n",
      "3978               0.555172                118.1          100.0        1.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "3351                    1        1          37       3.508223  33.491777   \n",
      "3515                    0        1          36       4.064802  31.935198   \n",
      "994                     0        1          40      15.237726  24.762274   \n",
      "3127                    0        1          34      12.055850  21.944150   \n",
      "3978                    1        1          34      12.157906  21.842094   \n",
      "\n",
      "      Abs_Error  \n",
      "3351  33.491777  \n",
      "3515  31.935198  \n",
      "994   24.762274  \n",
      "3127  21.944150  \n",
      "3978  21.842094  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Feature Importances (Tuned XGBoost (Baseline)):\n",
      "                    Feature  Importance\n",
      "5                FGA_EWMA_5    0.337374\n",
      "12           Avg_PTS_Season    0.134136\n",
      "3                MIN_EWMA_5    0.116841\n",
      "4                FGA_EWMA_3    0.112626\n",
      "1                PTS_EWMA_5    0.075748\n",
      "2                MIN_EWMA_3    0.047400\n",
      "10  Player_USG_Proxy_EWMA_3    0.020852\n",
      "11  Player_USG_Proxy_EWMA_5    0.018085\n",
      "0                PTS_EWMA_3    0.015607\n",
      "15    Avg_USG%_Proxy_Season    0.015403\n",
      "7                FTA_EWMA_5    0.014960\n",
      "18                Rest_Days    0.014626\n",
      "13         PTS_Per36_Season    0.012904\n",
      "20                  Is_Home    0.012824\n",
      "8                TS%_EWMA_3    0.011595\n",
      "14           Avg_TS%_Season    0.011437\n",
      "16      Opponent_DEF_RATING    0.009866\n",
      "6                FTA_EWMA_3    0.009282\n",
      "9                TS%_EWMA_5    0.008435\n",
      "17            Opponent_PACE    0.000000\n",
      "19      Is_B2B_Second_Night    0.000000\n"
     ]
    }
   ],
   "source": [
    "# --- Model Evaluation (Tuned XGBoost - Baseline) ---\n",
    "# Pass X_test (transformed features), y_test_original (original target) for evaluation\n",
    "# Pass X_train.columns for feature importance display (features used for training)\n",
    "train_cols = X_train.columns if X_train is not None else None\n",
    "if 'model_xgb_baseline' in locals() and model_xgb_baseline is not None:\n",
    "    evaluate_model(model_xgb_baseline, X_test, y_test, y_test_original, \"Tuned XGBoost (Baseline)\", X_train_cols=train_cols) \n",
    "else:\n",
    "    print(\"Skipping Baseline XGBoost evaluation as model was not trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tuning LightGBM Model (Baseline) ---\n",
      "Starting LightGBM GridSearchCV (this may take a while)...\n",
      "Fitting 5 folds for each of 3888 candidates, totalling 19440 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4145\n",
      "[LightGBM] [Info] Number of data points in the train set: 4154, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 2.102643\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "Best parameters found for LightGBM (Baseline): {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100, 'reg_alpha': 0, 'reg_lambda': 1.5, 'subsample': 0.7}\n",
      "Best MAE score during CV (Baseline): 0.56\n",
      "Tuned LightGBM Model training complete (Baseline).\n",
      "Baseline LightGBM model saved.\n"
     ]
    }
   ],
   "source": [
    "# --- Model Building & Tuning (LightGBM - Baseline) ---\n",
    "model_lgbm_baseline = None\n",
    "if X_train is not None and y_train is not None and not X_train.empty:\n",
    "    print(\"\\n--- Tuning LightGBM Model (Baseline) ---\")\n",
    "    \n",
    "    param_grid_lgbm = {\n",
    "        'n_estimators': [100, 200, 300],       \n",
    "        'max_depth': [3, 5, 7],               \n",
    "        'learning_rate': [0.01, 0.05, 0.1],   \n",
    "        'subsample': [0.7, 0.8, 0.9, 1.0],          \n",
    "        'colsample_bytree': [0.7, 0.8, 0.9, 1.0],   \n",
    "        'reg_alpha': [0, 0.1, 0.5],            \n",
    "        'reg_lambda': [0.5, 1.0, 1.5]          \n",
    "    }\n",
    "    \n",
    "    lgbm_estimator = lgb.LGBMRegressor(random_state=42, objective='regression_l2') \n",
    "    \n",
    "    # Using TimeSeriesSplit for CV\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    grid_search_lgbm = GridSearchCV(\n",
    "        estimator=lgbm_estimator,\n",
    "        param_grid=param_grid_lgbm,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=tscv,\n",
    "        n_jobs=-1,\n",
    "        verbose=1 \n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        print(\"Starting LightGBM GridSearchCV (this may take a while)...\")\n",
    "        grid_search_lgbm.fit(X_train, y_train) # y_train is transformed\n",
    "        model_lgbm_baseline = grid_search_lgbm.best_estimator_\n",
    "        print(f\"\\nBest parameters found for LightGBM (Baseline): {grid_search_lgbm.best_params_}\")\n",
    "        print(f\"Best MAE score during CV (Baseline): {-grid_search_lgbm.best_score_:.2f}\") # Score is on transformed scale\n",
    "        print(\"Tuned LightGBM Model training complete (Baseline).\")\n",
    "        joblib.dump(model_lgbm_baseline, 'models/lgbm_model_baseline.pkl') # Save baseline\n",
    "        print(\"Baseline LightGBM model saved.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during LightGBM GridSearchCV (Baseline): {e}\")\n",
    "        traceback.print_exc()\n",
    "        model_lgbm_baseline = None\n",
    "else:\n",
    "    print(\"Skipping LightGBM tuning due to lack of training data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Tuned LightGBM (Baseline) Evaluation ---\n",
      "Mean Absolute Error (MAE): 4.41\n",
      "Root Mean Squared Error (RMSE): 6.00\n",
      "Mean Absolute Percentage Error (MAPE): 52.05% (excluding 124 games with 0 actual points)\n",
      "Accuracy (within +/- 3 points): 47.06%\n",
      "\n",
      "Sample Predictions vs Actual (Tuned LightGBM (Baseline)):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "3547   23.676529   20.975582   28.929161   27.826426   15.221966   14.829648   \n",
      "79      6.844662    7.639454   24.766341   25.960291    4.449875    4.987941   \n",
      "4783    4.562500    3.493827    7.656250    5.930041    4.156250    3.385460   \n",
      "4443   19.162092   17.739835   33.952229   32.679759   15.879441   15.440207   \n",
      "4294    4.037598    2.903668    4.578857    4.678529    1.724854    1.471149   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "3547    4.193523    4.430613    0.666544    0.598865  ...   \n",
      "79      0.251961    0.425205    0.696893    0.670662  ...   \n",
      "4783    0.250000    0.222222    0.439741    0.353072  ...   \n",
      "4443    3.960343    3.490642    0.533357    0.511261  ...   \n",
      "4294    2.000977    1.342004    0.424272    0.307699  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "3547               0.724144           114.479344          100.0        2.0   \n",
      "79                 0.262287           110.800000          100.0        3.0   \n",
      "4783               0.658571           115.600000          100.0        3.0   \n",
      "4443               0.539512           112.100000          100.0        2.0   \n",
      "4294               0.314583           111.900000          100.0        2.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "3547                    0        0          20      18.142287   1.857713   \n",
      "79                      0        1           8       4.512337   3.487663   \n",
      "4783                    0        1           5       2.791082   2.208918   \n",
      "4443                    0        1          31      17.214147  13.785853   \n",
      "4294                    0        1           2       1.364122   0.635878   \n",
      "\n",
      "      Abs_Error  \n",
      "3547   1.857713  \n",
      "79     3.487663  \n",
      "4783   2.208918  \n",
      "4443  13.785853  \n",
      "4294   0.635878  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Largest Errors (Top 5):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "3351    5.085567    4.323508   11.885225   10.791931    6.162133    5.180699   \n",
      "3515    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "994    18.803643   18.261414   33.212858   31.483130   15.746948   15.113675   \n",
      "3978   11.941515   11.540890   30.229732   28.620777   12.119081   11.360942   \n",
      "3127   11.281489   12.193630   36.496559   36.644491   11.578104   11.825451   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "3351    0.020020    0.092421    0.387462    0.352346  ...   \n",
      "3515    0.000000    0.000000    0.000000    0.000000  ...   \n",
      "994     2.213892    1.948465    0.572000    0.586764  ...   \n",
      "3978    2.315082    2.869619    0.406852    0.395331  ...   \n",
      "3127    2.579181    2.288440    0.431089    0.464978  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "3351               0.540601                113.7          100.0        1.0   \n",
      "3515               0.000000                112.1          100.0        2.0   \n",
      "994                0.546760                112.3          100.0        3.0   \n",
      "3978               0.555172                118.1          100.0        1.0   \n",
      "3127               0.379016                118.9          100.0        2.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "3351                    1        1          37       3.166315  33.833685   \n",
      "3515                    0        1          36       4.127324  31.872676   \n",
      "994                     0        1          40      16.915103  23.084897   \n",
      "3978                    1        1          34      11.926513  22.073487   \n",
      "3127                    0        1          34      12.561488  21.438512   \n",
      "\n",
      "      Abs_Error  \n",
      "3351  33.833685  \n",
      "3515  31.872676  \n",
      "994   23.084897  \n",
      "3978  22.073487  \n",
      "3127  21.438512  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Feature Importances (Tuned LightGBM (Baseline)):\n",
      "                    Feature  Importance\n",
      "12           Avg_PTS_Season          76\n",
      "16      Opponent_DEF_RATING          68\n",
      "15    Avg_USG%_Proxy_Season          56\n",
      "2                MIN_EWMA_3          53\n",
      "7                FTA_EWMA_5          49\n",
      "5                FGA_EWMA_5          46\n",
      "13         PTS_Per36_Season          41\n",
      "3                MIN_EWMA_5          39\n",
      "10  Player_USG_Proxy_EWMA_3          30\n",
      "1                PTS_EWMA_5          26\n",
      "6                FTA_EWMA_3          26\n",
      "18                Rest_Days          25\n",
      "0                PTS_EWMA_3          24\n",
      "11  Player_USG_Proxy_EWMA_5          22\n",
      "9                TS%_EWMA_5          21\n",
      "8                TS%_EWMA_3          21\n",
      "14           Avg_TS%_Season          20\n",
      "4                FGA_EWMA_3          19\n",
      "20                  Is_Home          14\n",
      "17            Opponent_PACE           0\n",
      "19      Is_B2B_Second_Night           0\n"
     ]
    }
   ],
   "source": [
    "# --- Model Evaluation (Tuned LightGBM - Baseline) ---\n",
    "# Pass X_test (transformed features), y_test_original (original target) for evaluation\n",
    "# Pass X_train.columns for feature importance display\n",
    "train_cols = X_train.columns if X_train is not None else None\n",
    "if 'model_lgbm_baseline' in locals() and model_lgbm_baseline is not None:\n",
    "    evaluate_model(model_lgbm_baseline, X_test, y_test, y_test_original, \"Tuned LightGBM (Baseline)\", X_train_cols=train_cols) \n",
    "else:\n",
    "    print(\"Skipping Baseline LightGBM evaluation as model was not trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== Processing Segment: Scorers ====================\n",
      "\n",
      "--- Tuning Ridge Regression Model (Scorers) ---\n",
      "Best alpha found for Ridge (Scorers): 100.0\n",
      "Tuned Ridge Regression Model training complete (Scorers).\n",
      "Ridge model saved for Scorers.\n",
      "\n",
      "--- Tuned Ridge (Scorers) Evaluation ---\n",
      "Mean Absolute Error (MAE): 6.02\n",
      "Root Mean Squared Error (RMSE): 7.65\n",
      "Mean Absolute Percentage Error (MAPE): 42.86% (excluding 2 games with 0 actual points)\n",
      "Accuracy (within +/- 3 points): 30.93%\n",
      "\n",
      "Sample Predictions vs Actual (Tuned Ridge (Scorers)):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "3547   23.676529   20.975582   28.929161   27.826426   15.221966   14.829648   \n",
      "4443   19.162092   17.739835   33.952229   32.679759   15.879441   15.440207   \n",
      "3583   19.500000   17.666667   34.500000   32.333333   14.500000   13.333333   \n",
      "2960   15.188034   14.718699   22.543759   22.627328   10.673752   10.417964   \n",
      "3485   16.521202   18.017241   36.300860   35.849984   11.320828   12.161750   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "3547    4.193523    4.430613    0.666544    0.598865  ...   \n",
      "4443    3.960343    3.490642    0.533357    0.511261  ...   \n",
      "3583    5.000000    4.666667    0.577105    0.567600  ...   \n",
      "2960    2.565282    2.874788    0.618277    0.608687  ...   \n",
      "3485    5.053444    5.229237    0.575277    0.595360  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "3547               0.724144           114.479344          100.0        2.0   \n",
      "4443               0.539512           112.100000          100.0        2.0   \n",
      "3583               0.585507           114.500000          100.0        2.0   \n",
      "2960               0.581435           115.000000          100.0        1.0   \n",
      "3485               0.477335           112.300000          100.0        3.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "3547                    0        0          20      16.657464   3.342536   \n",
      "4443                    0        1          31      16.258893  14.741107   \n",
      "3583                    0        1          19      15.942840   3.057160   \n",
      "2960                    1        0          18      12.455555   5.544445   \n",
      "3485                    0        1          15      16.353198  -1.353198   \n",
      "\n",
      "      Abs_Error  \n",
      "3547   3.342536  \n",
      "4443  14.741107  \n",
      "3583   3.057160  \n",
      "2960   5.544445  \n",
      "3485   1.353198  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Largest Errors (Top 5):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "994    18.803643   18.261414   33.212858   31.483130   15.746948   15.113675   \n",
      "3550   21.459566   20.622395   26.491145   26.467089   14.277746   14.356933   \n",
      "2815   32.652990   32.355369   36.093047   36.210829   23.198967   22.393976   \n",
      "3673   25.731271   25.498551   35.462691   35.212667   20.397667   19.726851   \n",
      "2303   21.167653   22.933702   33.237202   34.959347   16.303345   17.523649   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "994     2.213892    1.948465    0.572000    0.586764  ...   \n",
      "3550    6.524190    5.683145    0.619420    0.602127  ...   \n",
      "2815    7.648177    8.373909    0.615428    0.619183  ...   \n",
      "3673    5.466522    5.563817    0.551376    0.554288  ...   \n",
      "2303    2.880915    3.611971    0.613370    0.606921  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "994                0.546760           112.300000          100.0        3.0   \n",
      "3550               0.728451           112.800000          100.0        2.0   \n",
      "2815               0.756377           110.800000          100.0        2.0   \n",
      "3673               0.722701           115.400000          100.0        3.0   \n",
      "2303               0.663242           114.479344          100.0        2.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "994                     0        1          40      14.987297  25.012703   \n",
      "3550                    0        1          37      16.790087  20.209913   \n",
      "2815                    0        0           6      25.171922 -19.171922   \n",
      "3673                    0        1          41      22.002042  18.997958   \n",
      "2303                    0        1           3      20.932932 -17.932932   \n",
      "\n",
      "      Abs_Error  \n",
      "994   25.012703  \n",
      "3550  20.209913  \n",
      "2815  19.171922  \n",
      "3673  18.997958  \n",
      "2303  17.932932  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "--- Tuning XGBoost Model (Scorers) ---\n",
      "Starting XGBoost GridSearchCV (Scorers)...\n",
      "Best parameters found for XGBoost (Scorers): {'colsample_bytree': 0.7, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 200, 'reg_alpha': 0.1, 'reg_lambda': 1.0, 'subsample': 1.0}\n",
      "Best MAE score during CV (Scorers): 0.35\n",
      "Tuned XGBoost Model training complete (Scorers).\n",
      "XGBoost model saved for Scorers.\n",
      "\n",
      "--- Tuned XGBoost (Scorers) Evaluation ---\n",
      "Mean Absolute Error (MAE): 5.94\n",
      "Root Mean Squared Error (RMSE): 7.54\n",
      "Mean Absolute Percentage Error (MAPE): 42.13% (excluding 2 games with 0 actual points)\n",
      "Accuracy (within +/- 3 points): 34.32%\n",
      "\n",
      "Sample Predictions vs Actual (Tuned XGBoost (Scorers)):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "3547   23.676529   20.975582   28.929161   27.826426   15.221966   14.829648   \n",
      "4443   19.162092   17.739835   33.952229   32.679759   15.879441   15.440207   \n",
      "3583   19.500000   17.666667   34.500000   32.333333   14.500000   13.333333   \n",
      "2960   15.188034   14.718699   22.543759   22.627328   10.673752   10.417964   \n",
      "3485   16.521202   18.017241   36.300860   35.849984   11.320828   12.161750   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "3547    4.193523    4.430613    0.666544    0.598865  ...   \n",
      "4443    3.960343    3.490642    0.533357    0.511261  ...   \n",
      "3583    5.000000    4.666667    0.577105    0.567600  ...   \n",
      "2960    2.565282    2.874788    0.618277    0.608687  ...   \n",
      "3485    5.053444    5.229237    0.575277    0.595360  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "3547               0.724144           114.479344          100.0        2.0   \n",
      "4443               0.539512           112.100000          100.0        2.0   \n",
      "3583               0.585507           114.500000          100.0        2.0   \n",
      "2960               0.581435           115.000000          100.0        1.0   \n",
      "3485               0.477335           112.300000          100.0        3.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "3547                    0        0          20      17.802776   2.197224   \n",
      "4443                    0        1          31      18.505564  12.494436   \n",
      "3583                    0        1          19      19.107841  -0.107841   \n",
      "2960                    1        0          18      13.553561   4.446439   \n",
      "3485                    0        1          15      16.833900  -1.833900   \n",
      "\n",
      "      Abs_Error  \n",
      "3547   2.197224  \n",
      "4443  12.494436  \n",
      "3583   0.107841  \n",
      "2960   4.446439  \n",
      "3485   1.833900  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Largest Errors (Top 5):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "994    18.803643   18.261414   33.212858   31.483130   15.746948   15.113675   \n",
      "426    25.587474   26.594399   39.554577   39.065560   17.250405   17.760595   \n",
      "3539   17.191317   17.397629   23.865325   24.270241   15.823357   15.645786   \n",
      "3673   25.731271   25.498551   35.462691   35.212667   20.397667   19.726851   \n",
      "3550   21.459566   20.622395   26.491145   26.467089   14.277746   14.356933   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "994     2.213892    1.948465    0.572000    0.586764  ...   \n",
      "426     6.008584    6.722472    0.644695    0.642191  ...   \n",
      "3539    5.541908    4.942393    0.469016    0.483667  ...   \n",
      "3673    5.466522    5.563817    0.551376    0.554288  ...   \n",
      "3550    6.524190    5.683145    0.619420    0.602127  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "994                0.546760                112.3          100.0        3.0   \n",
      "426                0.624798                118.1          100.0        2.0   \n",
      "3539               0.745495                111.9          100.0        2.0   \n",
      "3673               0.722701                115.4          100.0        3.0   \n",
      "3550               0.728451                112.8          100.0        2.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "994                     0        1          40      17.067759  22.932241   \n",
      "426                     0        1          41      21.682766  19.317234   \n",
      "3539                    0        0           0      18.859699 -18.859699   \n",
      "3673                    0        1          41      22.239531  18.760469   \n",
      "3550                    0        1          37      18.491428  18.508572   \n",
      "\n",
      "      Abs_Error  \n",
      "994   22.932241  \n",
      "426   19.317234  \n",
      "3539  18.859699  \n",
      "3673  18.760469  \n",
      "3550  18.508572  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Feature Importances (Tuned XGBoost (Scorers)):\n",
      "                    Feature  Importance\n",
      "1                PTS_EWMA_5    0.152980\n",
      "15    Avg_USG%_Proxy_Season    0.076310\n",
      "5                FGA_EWMA_5    0.076267\n",
      "3                MIN_EWMA_5    0.069069\n",
      "11  Player_USG_Proxy_EWMA_5    0.064872\n",
      "13         PTS_Per36_Season    0.061628\n",
      "2                MIN_EWMA_3    0.050698\n",
      "6                FTA_EWMA_3    0.048714\n",
      "8                TS%_EWMA_3    0.048441\n",
      "12           Avg_PTS_Season    0.045894\n",
      "10  Player_USG_Proxy_EWMA_3    0.043565\n",
      "0                PTS_EWMA_3    0.042361\n",
      "9                TS%_EWMA_5    0.041401\n",
      "7                FTA_EWMA_5    0.037215\n",
      "16      Opponent_DEF_RATING    0.034014\n",
      "14           Avg_TS%_Season    0.033613\n",
      "4                FGA_EWMA_3    0.027062\n",
      "18                Rest_Days    0.023836\n",
      "19      Is_B2B_Second_Night    0.022061\n",
      "17            Opponent_PACE    0.000000\n",
      "20                  Is_Home    0.000000\n",
      "\n",
      "--- Tuning LightGBM Model (Scorers) ---\n",
      "Starting LightGBM GridSearchCV (Scorers)...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000324 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4126\n",
      "[LightGBM] [Info] Number of data points in the train set: 942, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 2.932726\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters found for LightGBM (Scorers): {'colsample_bytree': 0.7, 'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 300, 'reg_alpha': 0.5, 'reg_lambda': 1.5, 'subsample': 0.7}\n",
      "Best MAE score during CV (Scorers): 0.35\n",
      "Tuned LightGBM Model training complete (Scorers).\n",
      "LightGBM model saved for Scorers.\n",
      "\n",
      "--- Tuned LightGBM (Scorers) Evaluation ---\n",
      "Mean Absolute Error (MAE): 5.90\n",
      "Root Mean Squared Error (RMSE): 7.52\n",
      "Mean Absolute Percentage Error (MAPE): 41.78% (excluding 2 games with 0 actual points)\n",
      "Accuracy (within +/- 3 points): 32.63%\n",
      "\n",
      "Sample Predictions vs Actual (Tuned LightGBM (Scorers)):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "3547   23.676529   20.975582   28.929161   27.826426   15.221966   14.829648   \n",
      "4443   19.162092   17.739835   33.952229   32.679759   15.879441   15.440207   \n",
      "3583   19.500000   17.666667   34.500000   32.333333   14.500000   13.333333   \n",
      "2960   15.188034   14.718699   22.543759   22.627328   10.673752   10.417964   \n",
      "3485   16.521202   18.017241   36.300860   35.849984   11.320828   12.161750   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "3547    4.193523    4.430613    0.666544    0.598865  ...   \n",
      "4443    3.960343    3.490642    0.533357    0.511261  ...   \n",
      "3583    5.000000    4.666667    0.577105    0.567600  ...   \n",
      "2960    2.565282    2.874788    0.618277    0.608687  ...   \n",
      "3485    5.053444    5.229237    0.575277    0.595360  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "3547               0.724144           114.479344          100.0        2.0   \n",
      "4443               0.539512           112.100000          100.0        2.0   \n",
      "3583               0.585507           114.500000          100.0        2.0   \n",
      "2960               0.581435           115.000000          100.0        1.0   \n",
      "3485               0.477335           112.300000          100.0        3.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "3547                    0        0          20      17.304544   2.695456   \n",
      "4443                    0        1          31      19.223361  11.776639   \n",
      "3583                    0        1          19      18.770084   0.229916   \n",
      "2960                    1        0          18      13.202723   4.797277   \n",
      "3485                    0        1          15      16.352508  -1.352508   \n",
      "\n",
      "      Abs_Error  \n",
      "3547   2.695456  \n",
      "4443  11.776639  \n",
      "3583   0.229916  \n",
      "2960   4.797277  \n",
      "3485   1.352508  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Largest Errors (Top 5):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "994    18.803643   18.261414   33.212858   31.483130   15.746948   15.113675   \n",
      "3539   17.191317   17.397629   23.865325   24.270241   15.823357   15.645786   \n",
      "426    25.587474   26.594399   39.554577   39.065560   17.250405   17.760595   \n",
      "3550   21.459566   20.622395   26.491145   26.467089   14.277746   14.356933   \n",
      "3673   25.731271   25.498551   35.462691   35.212667   20.397667   19.726851   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "994     2.213892    1.948465    0.572000    0.586764  ...   \n",
      "3539    5.541908    4.942393    0.469016    0.483667  ...   \n",
      "426     6.008584    6.722472    0.644695    0.642191  ...   \n",
      "3550    6.524190    5.683145    0.619420    0.602127  ...   \n",
      "3673    5.466522    5.563817    0.551376    0.554288  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "994                0.546760                112.3          100.0        3.0   \n",
      "3539               0.745495                111.9          100.0        2.0   \n",
      "426                0.624798                118.1          100.0        2.0   \n",
      "3550               0.728451                112.8          100.0        2.0   \n",
      "3673               0.722701                115.4          100.0        3.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "994                     0        1          40      17.297800  22.702200   \n",
      "3539                    0        0           0      19.357250 -19.357250   \n",
      "426                     0        1          41      22.021048  18.978952   \n",
      "3550                    0        1          37      18.672923  18.327077   \n",
      "3673                    0        1          41      23.064739  17.935261   \n",
      "\n",
      "      Abs_Error  \n",
      "994   22.702200  \n",
      "3539  19.357250  \n",
      "426   18.978952  \n",
      "3550  18.327077  \n",
      "3673  17.935261  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Feature Importances (Tuned LightGBM (Scorers)):\n",
      "                    Feature  Importance\n",
      "6                FTA_EWMA_3         210\n",
      "3                MIN_EWMA_5         183\n",
      "15    Avg_USG%_Proxy_Season         177\n",
      "11  Player_USG_Proxy_EWMA_5         121\n",
      "12           Avg_PTS_Season         116\n",
      "16      Opponent_DEF_RATING         115\n",
      "0                PTS_EWMA_3         112\n",
      "7                FTA_EWMA_5          94\n",
      "9                TS%_EWMA_5          80\n",
      "13         PTS_Per36_Season          78\n",
      "1                PTS_EWMA_5          71\n",
      "14           Avg_TS%_Season          68\n",
      "5                FGA_EWMA_5          58\n",
      "10  Player_USG_Proxy_EWMA_3          58\n",
      "2                MIN_EWMA_3          51\n",
      "8                TS%_EWMA_3          49\n",
      "4                FGA_EWMA_3          29\n",
      "18                Rest_Days           9\n",
      "19      Is_B2B_Second_Night           2\n",
      "17            Opponent_PACE           0\n",
      "20                  Is_Home           0\n",
      "\n",
      "==================== Finished Segment: Scorers ====================\n",
      "\n",
      "==================== Processing Segment: Role Players ====================\n",
      "\n",
      "--- Tuning Ridge Regression Model (Role Players) ---\n",
      "Best alpha found for Ridge (Role Players): 1.0\n",
      "Tuned Ridge Regression Model training complete (Role Players).\n",
      "Ridge model saved for Role Players.\n",
      "\n",
      "--- Tuned Ridge (Role Players) Evaluation ---\n",
      "Mean Absolute Error (MAE): 3.96\n",
      "Root Mean Squared Error (RMSE): 5.48\n",
      "Mean Absolute Percentage Error (MAPE): 54.03% (excluding 122 games with 0 actual points)\n",
      "Accuracy (within +/- 3 points): 52.43%\n",
      "\n",
      "Sample Predictions vs Actual (Tuned Ridge (Role Players)):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "79      6.844662    7.639454   24.766341   25.960291    4.449875    4.987941   \n",
      "4783    4.562500    3.493827    7.656250    5.930041    4.156250    3.385460   \n",
      "4294    4.037598    2.903668    4.578857    4.678529    1.724854    1.471149   \n",
      "2174   10.383427    9.741404   27.648432   26.637615    8.938101    8.275276   \n",
      "2487    5.500000    6.000000   15.000000   16.000000    4.500000    4.333333   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "79      0.251961    0.425205    0.696893    0.670662  ...   \n",
      "4783    0.250000    0.222222    0.439741    0.353072  ...   \n",
      "4294    2.000977    1.342004    0.424272    0.307699  ...   \n",
      "2174    1.820531    1.868303    0.522298    0.519009  ...   \n",
      "2487    1.000000    1.333333    0.558607    0.611475  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "79                 0.262287                110.8          100.0        3.0   \n",
      "4783               0.658571                115.6          100.0        3.0   \n",
      "4294               0.314583                111.9          100.0        2.0   \n",
      "2174               0.384522                113.7          100.0        2.0   \n",
      "2487               0.362667                114.4          100.0        3.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS     Error  \\\n",
      "79                      0        1           8       4.945547  3.054453   \n",
      "4783                    0        1           5       1.957071  3.042929   \n",
      "4294                    0        1           2       1.448083  0.551917   \n",
      "2174                    0        0           6       5.986171  0.013829   \n",
      "2487                    0        0           0       3.910737 -3.910737   \n",
      "\n",
      "      Abs_Error  \n",
      "79     3.054453  \n",
      "4783   3.042929  \n",
      "4294   0.551917  \n",
      "2174   0.013829  \n",
      "2487   3.910737  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Largest Errors (Top 5):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "3351    5.085567    4.323508   11.885225   10.791931    6.162133    5.180699   \n",
      "3515    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "1946    4.463857    4.594506    9.342535   12.384399    2.844649    3.185671   \n",
      "842    10.395264   10.093203   26.591309   26.592141   12.573486   12.017712   \n",
      "3127   11.281489   12.193630   36.496559   36.644491   11.578104   11.825451   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "3351    0.020020    0.092421    0.387462    0.352346  ...   \n",
      "3515    0.000000    0.000000    0.000000    0.000000  ...   \n",
      "1946    2.276215    1.989588    0.630069    0.619057  ...   \n",
      "842     0.603271    1.221208    0.407098    0.402739  ...   \n",
      "3127    2.579181    2.288440    0.431089    0.464978  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "3351               0.540601                113.7          100.0        1.0   \n",
      "3515               0.000000                112.1          100.0        2.0   \n",
      "1946               0.387512                119.2          100.0        2.0   \n",
      "842                0.536401                111.0          100.0        2.0   \n",
      "3127               0.379016                118.9          100.0        2.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "3351                    1        1          37       4.059448  32.940552   \n",
      "3515                    0        1          36       3.206653  32.793347   \n",
      "1946                    0        1          25       2.831953  22.168047   \n",
      "842                     0        1          31       9.706122  21.293878   \n",
      "3127                    0        1          34      12.880420  21.119580   \n",
      "\n",
      "      Abs_Error  \n",
      "3351  32.940552  \n",
      "3515  32.793347  \n",
      "1946  22.168047  \n",
      "842   21.293878  \n",
      "3127  21.119580  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "--- Tuning XGBoost Model (Role Players) ---\n",
      "Starting XGBoost GridSearchCV (Role Players)...\n",
      "Best parameters found for XGBoost (Role Players): {'colsample_bytree': 0.9, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100, 'reg_alpha': 0.5, 'reg_lambda': 1.0, 'subsample': 0.7}\n",
      "Best MAE score during CV (Role Players): 0.62\n",
      "Tuned XGBoost Model training complete (Role Players).\n",
      "XGBoost model saved for Role Players.\n",
      "\n",
      "--- Tuned XGBoost (Role Players) Evaluation ---\n",
      "Mean Absolute Error (MAE): 3.98\n",
      "Root Mean Squared Error (RMSE): 5.47\n",
      "Mean Absolute Percentage Error (MAPE): 56.60% (excluding 122 games with 0 actual points)\n",
      "Accuracy (within +/- 3 points): 49.94%\n",
      "\n",
      "Sample Predictions vs Actual (Tuned XGBoost (Role Players)):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "79      6.844662    7.639454   24.766341   25.960291    4.449875    4.987941   \n",
      "4783    4.562500    3.493827    7.656250    5.930041    4.156250    3.385460   \n",
      "4294    4.037598    2.903668    4.578857    4.678529    1.724854    1.471149   \n",
      "2174   10.383427    9.741404   27.648432   26.637615    8.938101    8.275276   \n",
      "2487    5.500000    6.000000   15.000000   16.000000    4.500000    4.333333   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "79      0.251961    0.425205    0.696893    0.670662  ...   \n",
      "4783    0.250000    0.222222    0.439741    0.353072  ...   \n",
      "4294    2.000977    1.342004    0.424272    0.307699  ...   \n",
      "2174    1.820531    1.868303    0.522298    0.519009  ...   \n",
      "2487    1.000000    1.333333    0.558607    0.611475  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "79                 0.262287                110.8          100.0        3.0   \n",
      "4783               0.658571                115.6          100.0        3.0   \n",
      "4294               0.314583                111.9          100.0        2.0   \n",
      "2174               0.384522                113.7          100.0        2.0   \n",
      "2487               0.362667                114.4          100.0        3.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS     Error  \\\n",
      "79                      0        1           8       4.726382  3.273618   \n",
      "4783                    0        1           5       2.317195  2.682805   \n",
      "4294                    0        1           2       1.201329  0.798671   \n",
      "2174                    0        0           6       6.759284 -0.759284   \n",
      "2487                    0        0           0       3.969562 -3.969562   \n",
      "\n",
      "      Abs_Error  \n",
      "79     3.273618  \n",
      "4783   2.682805  \n",
      "4294   0.798671  \n",
      "2174   0.759284  \n",
      "2487   3.969562  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Largest Errors (Top 5):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "3351    5.085567    4.323508   11.885225   10.791931    6.162133    5.180699   \n",
      "3515    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "3127   11.281489   12.193630   36.496559   36.644491   11.578104   11.825451   \n",
      "3978   11.941515   11.540890   30.229732   28.620777   12.119081   11.360942   \n",
      "1946    4.463857    4.594506    9.342535   12.384399    2.844649    3.185671   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "3351    0.020020    0.092421    0.387462    0.352346  ...   \n",
      "3515    0.000000    0.000000    0.000000    0.000000  ...   \n",
      "3127    2.579181    2.288440    0.431089    0.464978  ...   \n",
      "3978    2.315082    2.869619    0.406852    0.395331  ...   \n",
      "1946    2.276215    1.989588    0.630069    0.619057  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "3351               0.540601                113.7          100.0        1.0   \n",
      "3515               0.000000                112.1          100.0        2.0   \n",
      "3127               0.379016                118.9          100.0        2.0   \n",
      "3978               0.555172                118.1          100.0        1.0   \n",
      "1946               0.387512                119.2          100.0        2.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "3351                    1        1          37       4.009067  32.990933   \n",
      "3515                    0        1          36       4.056702  31.943298   \n",
      "3127                    0        1          34      11.717569  22.282431   \n",
      "3978                    1        1          34      11.890906  22.109094   \n",
      "1946                    0        1          25       4.213467  20.786533   \n",
      "\n",
      "      Abs_Error  \n",
      "3351  32.990933  \n",
      "3515  31.943298  \n",
      "3127  22.282431  \n",
      "3978  22.109094  \n",
      "1946  20.786533  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Feature Importances (Tuned XGBoost (Role Players)):\n",
      "                    Feature  Importance\n",
      "5                FGA_EWMA_5    0.255182\n",
      "4                FGA_EWMA_3    0.124910\n",
      "3                MIN_EWMA_5    0.114161\n",
      "12           Avg_PTS_Season    0.100308\n",
      "2                MIN_EWMA_3    0.098746\n",
      "11  Player_USG_Proxy_EWMA_5    0.037142\n",
      "10  Player_USG_Proxy_EWMA_3    0.023323\n",
      "7                FTA_EWMA_5    0.022606\n",
      "15    Avg_USG%_Proxy_Season    0.022060\n",
      "19      Is_B2B_Second_Night    0.021297\n",
      "1                PTS_EWMA_5    0.021169\n",
      "0                PTS_EWMA_3    0.019969\n",
      "18                Rest_Days    0.019126\n",
      "8                TS%_EWMA_3    0.018106\n",
      "14           Avg_TS%_Season    0.018102\n",
      "9                TS%_EWMA_5    0.017948\n",
      "13         PTS_Per36_Season    0.017798\n",
      "20                  Is_Home    0.017133\n",
      "6                FTA_EWMA_3    0.016266\n",
      "16      Opponent_DEF_RATING    0.014648\n",
      "17            Opponent_PACE    0.000000\n",
      "\n",
      "--- Tuning LightGBM Model (Role Players) ---\n",
      "Starting LightGBM GridSearchCV (Role Players)...\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000297 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4145\n",
      "[LightGBM] [Info] Number of data points in the train set: 3212, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 1.859200\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Best parameters found for LightGBM (Role Players): {'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100, 'reg_alpha': 0.5, 'reg_lambda': 1.0, 'subsample': 0.7}\n",
      "Best MAE score during CV (Role Players): 0.62\n",
      "Tuned LightGBM Model training complete (Role Players).\n",
      "LightGBM model saved for Role Players.\n",
      "\n",
      "--- Tuned LightGBM (Role Players) Evaluation ---\n",
      "Mean Absolute Error (MAE): 3.99\n",
      "Root Mean Squared Error (RMSE): 5.48\n",
      "Mean Absolute Percentage Error (MAPE): 55.95% (excluding 122 games with 0 actual points)\n",
      "Accuracy (within +/- 3 points): 50.44%\n",
      "\n",
      "Sample Predictions vs Actual (Tuned LightGBM (Role Players)):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "79      6.844662    7.639454   24.766341   25.960291    4.449875    4.987941   \n",
      "4783    4.562500    3.493827    7.656250    5.930041    4.156250    3.385460   \n",
      "4294    4.037598    2.903668    4.578857    4.678529    1.724854    1.471149   \n",
      "2174   10.383427    9.741404   27.648432   26.637615    8.938101    8.275276   \n",
      "2487    5.500000    6.000000   15.000000   16.000000    4.500000    4.333333   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "79      0.251961    0.425205    0.696893    0.670662  ...   \n",
      "4783    0.250000    0.222222    0.439741    0.353072  ...   \n",
      "4294    2.000977    1.342004    0.424272    0.307699  ...   \n",
      "2174    1.820531    1.868303    0.522298    0.519009  ...   \n",
      "2487    1.000000    1.333333    0.558607    0.611475  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "79                 0.262287                110.8          100.0        3.0   \n",
      "4783               0.658571                115.6          100.0        3.0   \n",
      "4294               0.314583                111.9          100.0        2.0   \n",
      "2174               0.384522                113.7          100.0        2.0   \n",
      "2487               0.362667                114.4          100.0        3.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS     Error  \\\n",
      "79                      0        1           8       4.247737  3.752263   \n",
      "4783                    0        1           5       2.610495  2.389505   \n",
      "4294                    0        1           2       1.327250  0.672750   \n",
      "2174                    0        0           6       7.972623 -1.972623   \n",
      "2487                    0        0           0       3.812736 -3.812736   \n",
      "\n",
      "      Abs_Error  \n",
      "79     3.752263  \n",
      "4783   2.389505  \n",
      "4294   0.672750  \n",
      "2174   1.972623  \n",
      "2487   3.812736  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Largest Errors (Top 5):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "3351    5.085567    4.323508   11.885225   10.791931    6.162133    5.180699   \n",
      "3515    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "3127   11.281489   12.193630   36.496559   36.644491   11.578104   11.825451   \n",
      "3978   11.941515   11.540890   30.229732   28.620777   12.119081   11.360942   \n",
      "1946    4.463857    4.594506    9.342535   12.384399    2.844649    3.185671   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "3351    0.020020    0.092421    0.387462    0.352346  ...   \n",
      "3515    0.000000    0.000000    0.000000    0.000000  ...   \n",
      "3127    2.579181    2.288440    0.431089    0.464978  ...   \n",
      "3978    2.315082    2.869619    0.406852    0.395331  ...   \n",
      "1946    2.276215    1.989588    0.630069    0.619057  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "3351               0.540601                113.7          100.0        1.0   \n",
      "3515               0.000000                112.1          100.0        2.0   \n",
      "3127               0.379016                118.9          100.0        2.0   \n",
      "3978               0.555172                118.1          100.0        1.0   \n",
      "1946               0.387512                119.2          100.0        2.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "3351                    1        1          37       3.048067  33.951933   \n",
      "3515                    0        1          36       4.172505  31.827495   \n",
      "3127                    0        1          34      11.625220  22.374780   \n",
      "3978                    1        1          34      11.897542  22.102458   \n",
      "1946                    0        1          25       3.977172  21.022828   \n",
      "\n",
      "      Abs_Error  \n",
      "3351  33.951933  \n",
      "3515  31.827495  \n",
      "3127  22.374780  \n",
      "3978  22.102458  \n",
      "1946  21.022828  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Feature Importances (Tuned LightGBM (Role Players)):\n",
      "                    Feature  Importance\n",
      "16      Opponent_DEF_RATING          64\n",
      "12           Avg_PTS_Season          58\n",
      "2                MIN_EWMA_3          56\n",
      "5                FGA_EWMA_5          50\n",
      "10  Player_USG_Proxy_EWMA_3          46\n",
      "15    Avg_USG%_Proxy_Season          46\n",
      "7                FTA_EWMA_5          42\n",
      "18                Rest_Days          41\n",
      "3                MIN_EWMA_5          34\n",
      "13         PTS_Per36_Season          28\n",
      "4                FGA_EWMA_3          28\n",
      "0                PTS_EWMA_3          28\n",
      "11  Player_USG_Proxy_EWMA_5          28\n",
      "8                TS%_EWMA_3          26\n",
      "9                TS%_EWMA_5          23\n",
      "14           Avg_TS%_Season          21\n",
      "6                FTA_EWMA_3          18\n",
      "1                PTS_EWMA_5          14\n",
      "20                  Is_Home          12\n",
      "19      Is_B2B_Second_Night           3\n",
      "17            Opponent_PACE           0\n",
      "\n",
      "==================== Finished Segment: Role Players ====================\n"
     ]
    }
   ],
   "source": [
    "# --- Train and Evaluate Segmented Models ---\n",
    "\n",
    "# Check if segmentation was successful and data is available for segments\n",
    "if 'X_train_scorers' in locals() and X_train_scorers is not None and not X_train_scorers.empty and \\\n",
    "   'X_train_role' in locals() and X_train_role is not None and not X_train_role.empty:\n",
    "    \n",
    "    # Train/Evaluate Scorers Segment\n",
    "    model_ridge_scorers, model_xgb_scorers, model_lgbm_scorers = train_evaluate_segment(\n",
    "        X_train_scorers, y_train_scorers, X_test_scorers, y_test_scorers_original, \"Scorers\"\n",
    "    )\n",
    "    \n",
    "    # Train/Evaluate Role Players Segment\n",
    "    model_ridge_role, model_xgb_role, model_lgbm_role = train_evaluate_segment(\n",
    "        X_train_role, y_train_role, X_test_role, y_test_role_original, \"Role Players\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    print(\"Skipping segmented model training as segmentation did not run successfully or segments are empty.\")\n",
    "    # Ensure segmented models are None if training is skipped\n",
    "    model_ridge_scorers, model_xgb_scorers, model_lgbm_scorers = [None]*3\n",
    "    model_ridge_role, model_xgb_role, model_lgbm_role = [None]*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating Combined Segmented Ridge Model ---\n",
      "Loading segmented Ridge models...\n",
      "Segmented Ridge models loaded successfully.\n",
      "Generating combined predictions...\n",
      "Test Set Segmentation (using masks): Scorers = 236, Role Players = 803\n",
      "Combined transformed predictions generated.\n",
      "Combined predictions transformed back to original scale.\n",
      "Calculating combined metrics...\n",
      "\n",
      "--- METRICS COMPARISON (vs. Baseline Ridge) ---\n",
      "\n",
      "Combined Segmented Ridge Model:\n",
      "  Mean Absolute Error (MAE): 4.42\n",
      "  Root Mean Squared Error (RMSE): 6.04\n",
      "  Mean Absolute Percentage Error (MAPE): 51.17% (excluding 124 games with 0 actual points)\n",
      "  Accuracy (within +/- 3 points): 47.55%\n",
      "\n",
      "Baseline Ridge Model (Re-evaluated on original scale):\n",
      "\n",
      "--- Baseline Ridge (for comparison) Evaluation ---\n",
      "Mean Absolute Error (MAE): 4.49\n",
      "Root Mean Squared Error (RMSE): 6.21\n",
      "Mean Absolute Percentage Error (MAPE): 50.54% (excluding 124 games with 0 actual points)\n",
      "Accuracy (within +/- 3 points): 47.83%\n",
      "\n",
      "Sample Predictions vs Actual (Baseline Ridge (for comparison)):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "3547   23.676529   20.975582   28.929161   27.826426   15.221966   14.829648   \n",
      "79      6.844662    7.639454   24.766341   25.960291    4.449875    4.987941   \n",
      "4783    4.562500    3.493827    7.656250    5.930041    4.156250    3.385460   \n",
      "4443   19.162092   17.739835   33.952229   32.679759   15.879441   15.440207   \n",
      "4294    4.037598    2.903668    4.578857    4.678529    1.724854    1.471149   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "3547    4.193523    4.430613    0.666544    0.598865  ...   \n",
      "79      0.251961    0.425205    0.696893    0.670662  ...   \n",
      "4783    0.250000    0.222222    0.439741    0.353072  ...   \n",
      "4443    3.960343    3.490642    0.533357    0.511261  ...   \n",
      "4294    2.000977    1.342004    0.424272    0.307699  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "3547               0.724144           114.479344          100.0        2.0   \n",
      "79                 0.262287           110.800000          100.0        3.0   \n",
      "4783               0.658571           115.600000          100.0        3.0   \n",
      "4443               0.539512           112.100000          100.0        2.0   \n",
      "4294               0.314583           111.900000          100.0        2.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "3547                    0        0          20      19.422927   0.577073   \n",
      "79                      0        1           8       5.613845   2.386155   \n",
      "4783                    0        1           5       2.247907   2.752093   \n",
      "4443                    0        1          31      16.397144  14.602856   \n",
      "4294                    0        1           2       1.430573   0.569427   \n",
      "\n",
      "      Abs_Error  \n",
      "3547   0.577073  \n",
      "79     2.386155  \n",
      "4783   2.752093  \n",
      "4443  14.602856  \n",
      "4294   0.569427  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "\n",
      "Largest Errors (Top 5):\n",
      "      PTS_EWMA_3  PTS_EWMA_5  MIN_EWMA_3  MIN_EWMA_5  FGA_EWMA_3  FGA_EWMA_5  \\\n",
      "3351    5.085567    4.323508   11.885225   10.791931    6.162133    5.180699   \n",
      "3515    0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "994    18.803643   18.261414   33.212858   31.483130   15.746948   15.113675   \n",
      "2815   32.652990   32.355369   36.093047   36.210829   23.198967   22.393976   \n",
      "274    17.472570   17.155900   25.289373   24.160526   13.042925   12.562827   \n",
      "\n",
      "      FTA_EWMA_3  FTA_EWMA_5  TS%_EWMA_3  TS%_EWMA_5  ...  \\\n",
      "3351    0.020020    0.092421    0.387462    0.352346  ...   \n",
      "3515    0.000000    0.000000    0.000000    0.000000  ...   \n",
      "994     2.213892    1.948465    0.572000    0.586764  ...   \n",
      "2815    7.648177    8.373909    0.615428    0.619183  ...   \n",
      "274     1.964038    2.494920    0.633671    0.634741  ...   \n",
      "\n",
      "      Avg_USG%_Proxy_Season  Opponent_DEF_RATING  Opponent_PACE  Rest_Days  \\\n",
      "3351               0.540601                113.7          100.0        1.0   \n",
      "3515               0.000000                112.1          100.0        2.0   \n",
      "994                0.546760                112.3          100.0        3.0   \n",
      "2815               0.756377                110.8          100.0        2.0   \n",
      "274                0.562173                118.9          100.0        3.0   \n",
      "\n",
      "      Is_B2B_Second_Night  Is_Home  Actual_PTS  Predicted_PTS      Error  \\\n",
      "3351                    1        1          37       3.709875  33.290125   \n",
      "3515                    0        1          36       3.138017  32.861983   \n",
      "994                     0        1          40      15.203363  24.796637   \n",
      "2815                    0        0           6      29.415073 -23.415073   \n",
      "274                     0        0          34      10.675697  23.324303   \n",
      "\n",
      "      Abs_Error  \n",
      "3351  33.290125  \n",
      "3515  32.861983  \n",
      "994   24.796637  \n",
      "2815  23.415073  \n",
      "274   23.324303  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- Combined Segmented Model Evaluation (Focus on Ridge for Comparison first) ---\n",
    "\n",
    "print(\"\\n--- Evaluating Combined Segmented Ridge Model ---\")\n",
    "\n",
    "# Ensure necessary variables exist from previous cells\n",
    "if 'X_test' not in locals() or X_test is None or X_test.empty or \\\n",
    "   'y_test_original' not in locals() or y_test_original is None or y_test_original.empty or \\\n",
    "   'test_scorer_mask_global' not in locals() or test_scorer_mask_global is None:\n",
    "\n",
    "    print(\"Error: Essential test data or segmentation masks not found. Please ensure previous cells have run successfully.\")\n",
    "\n",
    "else:\n",
    "    try:\n",
    "        # --- Load the saved Segmented Ridge models ---\n",
    "        print(\"Loading segmented Ridge models...\")\n",
    "        # It's safer to load even if train_evaluate_segment was run, in case you ran cells out of order\n",
    "        model_ridge_scorers_loaded = joblib.load('models/ridge_model_scorers.pkl')\n",
    "        model_ridge_role_loaded = joblib.load('models/ridge_model_role_players.pkl')\n",
    "        print(\"Segmented Ridge models loaded successfully.\")\n",
    "\n",
    "        # --- Generate Combined Predictions ---\n",
    "        print(\"Generating combined predictions...\")\n",
    "        \n",
    "        # Use the masks created during segmentation (Cell 9)\n",
    "        scorer_mask = test_scorer_mask_global\n",
    "        role_mask = test_role_mask_global\n",
    "        \n",
    "        n_scorers_test = scorer_mask.sum()\n",
    "        n_role_test = role_mask.sum()\n",
    "        print(f\"Test Set Segmentation (using masks): Scorers = {n_scorers_test}, Role Players = {n_role_test}\")\n",
    "\n",
    "        if n_scorers_test == 0 and n_role_test == 0:\n",
    "             print(\"Error: Both test segments are empty based on the mask. Cannot proceed.\")\n",
    "        else:\n",
    "            # Initialize prediction series with the same index as y_test_original\n",
    "            y_pred_combined_transformed = pd.Series(np.zeros(len(y_test_original), dtype=float), index=y_test_original.index)\n",
    "            \n",
    "            # Predict for scorers segment using the loaded model\n",
    "            if n_scorers_test > 0:\n",
    "                 X_test_scorers_segment = X_test[scorer_mask]\n",
    "                 # Predict on the transformed scale\n",
    "                 y_pred_combined_transformed[scorer_mask] = model_ridge_scorers_loaded.predict(X_test_scorers_segment)\n",
    "\n",
    "            # Predict for role players segment using the loaded model\n",
    "            if n_role_test > 0:\n",
    "                 X_test_role_segment = X_test[role_mask]\n",
    "                 # Predict on the transformed scale\n",
    "                 y_pred_combined_transformed[role_mask] = model_ridge_role_loaded.predict(X_test_role_segment)\n",
    "            \n",
    "            print(\"Combined transformed predictions generated.\")\n",
    "\n",
    "            # --- Transform Combined Predictions Back to Original Scale ---\n",
    "            y_pred_combined_original = np.expm1(y_pred_combined_transformed)\n",
    "            # Handle potential negative predictions after inverse transform\n",
    "            y_pred_combined_original[y_pred_combined_original < 0] = 0\n",
    "            print(\"Combined predictions transformed back to original scale.\")\n",
    "\n",
    "            # --- Calculate Combined Metrics Directly (using original scale) ---\n",
    "            print(\"Calculating combined metrics...\")\n",
    "            \n",
    "            combined_mae = mean_absolute_error(y_test_original, y_pred_combined_original)\n",
    "            combined_mse = mean_squared_error(y_test_original, y_pred_combined_original)\n",
    "            combined_rmse = np.sqrt(combined_mse)\n",
    "            \n",
    "            # Filter out zero actual values for MAPE calculation\n",
    "            non_zero_mask_combined = y_test_original != 0\n",
    "            if np.any(non_zero_mask_combined):\n",
    "                combined_mape = mean_absolute_percentage_error(y_test_original[non_zero_mask_combined], y_pred_combined_original[non_zero_mask_combined])\n",
    "                combined_mape_note = f\"(excluding {(~non_zero_mask_combined).sum()} games with 0 actual points)\"\n",
    "            else:\n",
    "                combined_mape = np.nan \n",
    "                combined_mape_note = \"(MAPE not calculable)\"\n",
    "            \n",
    "            # Calculate % within +/- 3 points\n",
    "            combined_within_3_pts_accuracy = (np.abs(y_test_original - y_pred_combined_original) <= 3).mean() * 100\n",
    "            \n",
    "            # --- Print Comparison ---\n",
    "            print(\"\\n--- METRICS COMPARISON (vs. Baseline Ridge) ---\")\n",
    "            print(\"\\nCombined Segmented Ridge Model:\")\n",
    "            print(f\"  Mean Absolute Error (MAE): {combined_mae:.2f}\")\n",
    "            print(f\"  Root Mean Squared Error (RMSE): {combined_rmse:.2f}\")\n",
    "            print(f\"  Mean Absolute Percentage Error (MAPE): {combined_mape:.2%} {combined_mape_note}\")\n",
    "            print(f\"  Accuracy (within +/- 3 points): {combined_within_3_pts_accuracy:.2f}%\")\n",
    "\n",
    "            # Re-evaluate Baseline Ridge Model for direct comparison using the evaluate_model function\n",
    "            print(\"\\nBaseline Ridge Model (Re-evaluated on original scale):\") \n",
    "            if 'model_ridge_baseline' in locals() and model_ridge_baseline is not None:\n",
    "                 # Pass y_test (transformed) and y_test_original\n",
    "                 evaluate_model(model_ridge_baseline, X_test, y_test, y_test_original, \"Baseline Ridge (for comparison)\")\n",
    "            else:\n",
    "                 print(\"  Baseline Ridge model ('model_ridge_baseline') not found in memory. Cannot re-evaluate.\")\n",
    "                 # Add fallback load if needed:\n",
    "                 # try:\n",
    "                 #    model_ridge_baseline_loaded = joblib.load('ridge_model_baseline.pkl') \n",
    "                 #    evaluate_model(model_ridge_baseline_loaded, X_test, y_test, y_test_original, \"Baseline Ridge (Loaded for comparison)\")\n",
    "                 # except FileNotFoundError:\n",
    "                 #    print(\"  Could not load 'ridge_model_baseline.pkl' for comparison.\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error loading segmented Ridge model: {e}. Please ensure the model files exist ('ridge_model_scorers.pkl', 'ridge_model_role_players.pkl').\")\n",
    "        traceback.print_exc()\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred during combined evaluation: {e}\")\n",
    "        traceback.print_exc()\n",
    "        \n",
    "\n",
    "# --- Optional: Combined Segmented LightGBM Evaluation (Run separately if desired) ---\n",
    "# print(\"\\n--- Evaluating Combined Segmented LightGBM Model ---\")\n",
    "# try:\n",
    "#     print(\"Loading segmented LightGBM models...\")\n",
    "#     model_lgbm_scorers_loaded = joblib.load('lgbm_model_scorers.pkl')\n",
    "#     model_lgbm_role_loaded = joblib.load('lgbm_model_role_players.pkl')\n",
    "#     print(\"Segmented LightGBM models loaded successfully.\")\n",
    "# \n",
    "#     # ... (Repeat prediction and evaluation logic similar to Ridge combined evaluation) ...\n",
    "#     # Make sure to use model_lgbm_scorers_loaded.predict and model_lgbm_role_loaded.predict\n",
    "#     # and transform back using np.expm1 before calculating metrics on y_test_original\n",
    "# \n",
    "#     # Example prediction snippet:\n",
    "#     # y_pred_combined_lgbm_transformed = pd.Series(np.zeros(len(y_test_original), dtype=float), index=y_test_original.index)\n",
    "#     # if n_scorers_test > 0:\n",
    "#     #     y_pred_combined_lgbm_transformed[scorer_mask] = model_lgbm_scorers_loaded.predict(X_test[scorer_mask])\n",
    "#     # if n_role_test > 0:\n",
    "#     #     y_pred_combined_lgbm_transformed[role_mask] = model_lgbm_role_loaded.predict(X_test[role_mask])\n",
    "#     # y_pred_combined_lgbm_original = np.expm1(y_pred_combined_lgbm_transformed)\n",
    "#     # y_pred_combined_lgbm_original[y_pred_combined_lgbm_original < 0] = 0\n",
    "# \n",
    "#     # Calculate and print metrics for the combined LGBM model\n",
    "#     # ... (Calculation and print code using y_test_original and y_pred_combined_lgbm_original)\n",
    "# \n",
    "# except FileNotFoundError as e:\n",
    "#     print(f\"Error loading segmented LightGBM model: {e}\")\n",
    "#     traceback.print_exc()\n",
    "# except Exception as e:\n",
    "#     print(f\"An unexpected error occurred during combined LGBM evaluation: {e}\")\n",
    "#     traceback.print_exc()\n",
    "\n",
    "\n",
    "# --- Optional: Combined Segmented XGBoost Evaluation (Run separately if desired) ---\n",
    "# print(\"\\n--- Evaluating Combined Segmented XGBoost Model ---\")\n",
    "# try:\n",
    "#     print(\"Loading segmented XGBoost models...\")\n",
    "#     model_xgb_scorers_loaded = joblib.load('xgb_model_scorers.pkl')\n",
    "#     model_xgb_role_loaded = joblib.load('xgb_model_role_players.pkl')\n",
    "#     print(\"Segmented XGBoost models loaded successfully.\")\n",
    "# \n",
    "#     # ... (Repeat prediction and evaluation logic similar to Ridge/LGBM combined evaluation) ...\n",
    "#     # Make sure to use model_xgb_scorers_loaded.predict and model_xgb_role_loaded.predict\n",
    "#     # and transform back using np.expm1 before calculating metrics on y_test_original\n",
    "# \n",
    "#     # Example prediction snippet:\n",
    "# (\n",
    "#     # y_pred_combined_xgb_transformed = pd.Series(np.zeros(len(y_test_original), dtype=float), index=y_test_original.index)\n",
    "#     # if n_scorers_test > 0:\n",
    "#     #     y_pred_combined_xgb_transformed[scorer_mask] = model_xgb_scorers_loaded.predict(X_test[scorer_mask])\n",
    "#     # if n_role_test > 0:\n",
    "#     #     y_pred_combined_xgb_transformed[role_mask] = model_xgb_role_loaded.predict(X_test[role_mask])\n",
    "#     # y_pred_combined_xgb_original = np.expm1(y_pred_combined_xgb_transformed)\n",
    "#     # y_pred_combined_xgb_original[y_pred_combined_xgb_original < 0] = 0\n",
    "# \n",
    "#     # Calculate and print metrics for the combined XGBoost model\n",
    "#     # ... (Calculation and print code using y_test_original and y_pred_combined_xgb_original)\n",
    "# \n",
    "# except FileNotFoundError as e:\n",
    "#     print(f\"Error loading segmented XGBoost model: {e}\")\n",
    "#     traceback.print_exc()\n",
    "# except Exception as e:\n",
    "#     print(f\"An unexpected error occurred during combined XGBoost evaluation: {e}\")\n",
    "#     traceback.print_exc()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba_prop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
